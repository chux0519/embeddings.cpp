{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:20171\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:20171\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongsheng/miniconda3/envs/potasms/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from embeddings_cpp import Tokenizer, Embedding, POOLING_METHOD_CLS, POOLING_METHOD_MEAN\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def test_tokenizer_alignment(tokenizer_json, repo_name):\n",
    "\n",
    "    tok_cpp = Tokenizer(tokenizer_json)\n",
    "    auto_tok = AutoTokenizer.from_pretrained(repo_name)\n",
    "\n",
    "    sentences = [\"你好，今天天气怎么样？\", \"What's the weather like today?\"]\n",
    "    output_py = auto_tok(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    ouput_cpp = tok_cpp.encode_batch(sentences, True)\n",
    "\n",
    "    \n",
    "    auto_tok_output_input_ids = output_py[\"input_ids\"]\n",
    "    auto_tok_output_attention_mask = output_py[\"attention_mask\"]\n",
    "    for i in range(len(sentences)):\n",
    "        print(f\"text: {sentences[i]}\")\n",
    "        transformers_id = auto_tok_output_input_ids[i].numpy()\n",
    "        transformers_attention_mask = auto_tok_output_attention_mask[i].numpy()\n",
    "\n",
    "\n",
    "        embedings_cpp_id = np.array(ouput_cpp[i].ids)\n",
    "        embedings_cpp_attention_mask = np.array(ouput_cpp[i].attention_mask)\n",
    "\n",
    "        ids_mse = np.mean((transformers_id - embedings_cpp_id) ** 2)\n",
    "        attetion_mask_mse = np.mean((transformers_attention_mask - embedings_cpp_attention_mask) ** 2)\n",
    "\n",
    "        print(f\"transformers ids: {transformers_id}\")\n",
    "        print(f\"embeddings.cpp ids: {embedings_cpp_id}\")\n",
    "        print(f\"ids mse: {ids_mse}\")\n",
    "\n",
    "        print(f\"transformers attention mask: {transformers_attention_mask}\")\n",
    "        print(f\"embeddings.cpp attention mask: {embedings_cpp_attention_mask}\")\n",
    "        print(f\"attention mask mse: {attetion_mask_mse}\")\n",
    "\n",
    "def test_embedding_alignment(tokenizer_json, gguf_model, repo_name, pooling_method):\n",
    "    def mean_pooling(hidden_state, mask):\n",
    "        s = torch.sum(hidden_state * mask.unsqueeze(-1).float(), dim=1)\n",
    "        d = mask.sum(axis=1, keepdim=True).float()\n",
    "        return s / d\n",
    "    def cls_pooling(hidden_state, mask):\n",
    "        return hidden_state[:, 0]\n",
    "\n",
    "    tok_py = AutoTokenizer.from_pretrained(repo_name)\n",
    "    model_py = AutoModel.from_pretrained(repo_name)\n",
    "    # print(type(tok_py))\n",
    "    # print(type(model_py))\n",
    "\n",
    "    model_sp = SentenceTransformer(repo_name)\n",
    "\n",
    "    sentences = [\"你好，今天天气怎么样？\", \"What's the weather like today?\"]\n",
    "    output_py = tok_py(sentences, padding=True, truncation=True, return_tensors='pt', max_length=8192)\n",
    "    # print(f\"output_py: {output_py}\")\n",
    "    res_py = model_py(**output_py, return_dict=True)\n",
    "    # print(f\"res_py: {res_py}\")\n",
    "    last_hidden_state = res_py.last_hidden_state\n",
    "    # print(f\"last_hidden_state: {last_hidden_state}\")\n",
    "    pooling_fn = cls_pooling if pooling_method == POOLING_METHOD_CLS else mean_pooling\n",
    "    res_py = pooling_fn(last_hidden_state, output_py['attention_mask'])\n",
    "    # print(f\"pooling: {res_py}\")\n",
    "    res_py = torch.nn.functional.normalize(res_py, dim=-1)\n",
    "    res_py = res_py.cpu().detach().numpy()\n",
    "\n",
    "    model_cpp = Embedding(tokenizer_json, gguf_model)\n",
    "    res_cpp = model_cpp.batch_encode(sentences, normalize=True, pooling_method=pooling_method)\n",
    "\n",
    "    res_sp = model_sp.encode(sentences, normalize_embeddings=True)\n",
    "\n",
    "    return res_py, res_cpp, res_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = [\"../models/bge-m3.tokenizer.json\", \"../models/bge-base-zh-v1.5.tokenizer.json\", \"../models/text2vec-base-multilingual.tokenizer.json\"]\n",
    "ggufs = [\"../models/bge-m3.fp32.gguf\", \"../models/bge-base-zh-v1.5.fp32.gguf\", \"../models/text2vec-base-multilingual.fp32.gguf\"]\n",
    "repos = [\"BAAI/bge-m3\", \"BAAI/bge-base-zh-v1.5\", \"shibing624/text2vec-base-multilingual\"]\n",
    "pooling_methods = [POOLING_METHOD_CLS, POOLING_METHOD_CLS, POOLING_METHOD_MEAN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========testing: BAAI/bge-m3===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "BertEncoder: GGUF\n",
      "BertEncoder: model name:   BAAI/bge-m3\n",
      "BertEncoder: architecture:   XLMRobertaModel\n",
      "BertEncoder: description:  gguf model for embeddings.cpp\n",
      "BertEncoder: GGUF version: 3\n",
      "BertEncoder: alignment:    32\n",
      "BertEncoder: n_tensors:    391\n",
      "BertEncoder: n_kv:         12\n",
      "BertEncoder: ftype:        f32\n",
      "\n",
      "BertEncoder: MODEL\n",
      "BertEncoder: n_vocab        = 250002\n",
      "BertEncoder: n_max_tokens   = 8194\n",
      "BertEncoder: n_embd         = 1024\n",
      "BertEncoder: n_intermediate = 4096\n",
      "BertEncoder: n_head         = 16\n",
      "BertEncoder: n_layer        = 24\n",
      "BertEncoder: layer_norm_eps = 1e-05\n",
      "\n",
      "BertEncoder: using CPU backend\n",
      "BertEncoder: tensor[0]: type = f32, n_dims = 2, name = embeddings.word_embeddings.weight, offset=0, type=0\n",
      "BertEncoder: tensor[1]: type = f32, n_dims = 2, name = embeddings.position_embeddings.weight, offset=1024008192, type=0\n",
      "BertEncoder: tensor[2]: type = f32, n_dims = 1, name = embeddings.token_type_embeddings.weight, offset=1057570816, type=0\n",
      "BertEncoder: tensor[3]: type = f32, n_dims = 1, name = embeddings.LayerNorm.weight, offset=1057574912, type=0\n",
      "BertEncoder: tensor[4]: type = f32, n_dims = 1, name = embeddings.LayerNorm.bias, offset=1057579008, type=0\n",
      "BertEncoder: tensor[5]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.query.weight, offset=1057583104, type=0\n",
      "BertEncoder: tensor[6]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.query.bias, offset=1061777408, type=0\n",
      "BertEncoder: tensor[7]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.key.weight, offset=1061781504, type=0\n",
      "BertEncoder: tensor[8]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.key.bias, offset=1065975808, type=0\n",
      "BertEncoder: tensor[9]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.value.weight, offset=1065979904, type=0\n",
      "BertEncoder: tensor[10]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.value.bias, offset=1070174208, type=0\n",
      "BertEncoder: tensor[11]: type = f32, n_dims = 2, name = encoder.layer.0.attention.output.dense.weight, offset=1070178304, type=0\n",
      "BertEncoder: tensor[12]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.dense.bias, offset=1074372608, type=0\n",
      "BertEncoder: tensor[13]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.LayerNorm.weight, offset=1074376704, type=0\n",
      "BertEncoder: tensor[14]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.LayerNorm.bias, offset=1074380800, type=0\n",
      "BertEncoder: tensor[15]: type = f32, n_dims = 2, name = encoder.layer.0.intermediate.dense.weight, offset=1074384896, type=0\n",
      "BertEncoder: tensor[16]: type = f32, n_dims = 1, name = encoder.layer.0.intermediate.dense.bias, offset=1091162112, type=0\n",
      "BertEncoder: tensor[17]: type = f32, n_dims = 2, name = encoder.layer.0.output.dense.weight, offset=1091178496, type=0\n",
      "BertEncoder: tensor[18]: type = f32, n_dims = 1, name = encoder.layer.0.output.dense.bias, offset=1107955712, type=0\n",
      "BertEncoder: tensor[19]: type = f32, n_dims = 1, name = encoder.layer.0.output.LayerNorm.weight, offset=1107959808, type=0\n",
      "BertEncoder: tensor[20]: type = f32, n_dims = 1, name = encoder.layer.0.output.LayerNorm.bias, offset=1107963904, type=0\n",
      "BertEncoder: tensor[21]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.query.weight, offset=1107968000, type=0\n",
      "BertEncoder: tensor[22]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.query.bias, offset=1112162304, type=0\n",
      "BertEncoder: tensor[23]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.key.weight, offset=1112166400, type=0\n",
      "BertEncoder: tensor[24]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.key.bias, offset=1116360704, type=0\n",
      "BertEncoder: tensor[25]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.value.weight, offset=1116364800, type=0\n",
      "BertEncoder: tensor[26]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.value.bias, offset=1120559104, type=0\n",
      "BertEncoder: tensor[27]: type = f32, n_dims = 2, name = encoder.layer.1.attention.output.dense.weight, offset=1120563200, type=0\n",
      "BertEncoder: tensor[28]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.dense.bias, offset=1124757504, type=0\n",
      "BertEncoder: tensor[29]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.LayerNorm.weight, offset=1124761600, type=0\n",
      "BertEncoder: tensor[30]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.LayerNorm.bias, offset=1124765696, type=0\n",
      "BertEncoder: tensor[31]: type = f32, n_dims = 2, name = encoder.layer.1.intermediate.dense.weight, offset=1124769792, type=0\n",
      "BertEncoder: tensor[32]: type = f32, n_dims = 1, name = encoder.layer.1.intermediate.dense.bias, offset=1141547008, type=0\n",
      "BertEncoder: tensor[33]: type = f32, n_dims = 2, name = encoder.layer.1.output.dense.weight, offset=1141563392, type=0\n",
      "BertEncoder: tensor[34]: type = f32, n_dims = 1, name = encoder.layer.1.output.dense.bias, offset=1158340608, type=0\n",
      "BertEncoder: tensor[35]: type = f32, n_dims = 1, name = encoder.layer.1.output.LayerNorm.weight, offset=1158344704, type=0\n",
      "BertEncoder: tensor[36]: type = f32, n_dims = 1, name = encoder.layer.1.output.LayerNorm.bias, offset=1158348800, type=0\n",
      "BertEncoder: tensor[37]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.query.weight, offset=1158352896, type=0\n",
      "BertEncoder: tensor[38]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.query.bias, offset=1162547200, type=0\n",
      "BertEncoder: tensor[39]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.key.weight, offset=1162551296, type=0\n",
      "BertEncoder: tensor[40]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.key.bias, offset=1166745600, type=0\n",
      "BertEncoder: tensor[41]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.value.weight, offset=1166749696, type=0\n",
      "BertEncoder: tensor[42]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.value.bias, offset=1170944000, type=0\n",
      "BertEncoder: tensor[43]: type = f32, n_dims = 2, name = encoder.layer.2.attention.output.dense.weight, offset=1170948096, type=0\n",
      "BertEncoder: tensor[44]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.dense.bias, offset=1175142400, type=0\n",
      "BertEncoder: tensor[45]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.LayerNorm.weight, offset=1175146496, type=0\n",
      "BertEncoder: tensor[46]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.LayerNorm.bias, offset=1175150592, type=0\n",
      "BertEncoder: tensor[47]: type = f32, n_dims = 2, name = encoder.layer.2.intermediate.dense.weight, offset=1175154688, type=0\n",
      "BertEncoder: tensor[48]: type = f32, n_dims = 1, name = encoder.layer.2.intermediate.dense.bias, offset=1191931904, type=0\n",
      "BertEncoder: tensor[49]: type = f32, n_dims = 2, name = encoder.layer.2.output.dense.weight, offset=1191948288, type=0\n",
      "BertEncoder: tensor[50]: type = f32, n_dims = 1, name = encoder.layer.2.output.dense.bias, offset=1208725504, type=0\n",
      "BertEncoder: tensor[51]: type = f32, n_dims = 1, name = encoder.layer.2.output.LayerNorm.weight, offset=1208729600, type=0\n",
      "BertEncoder: tensor[52]: type = f32, n_dims = 1, name = encoder.layer.2.output.LayerNorm.bias, offset=1208733696, type=0\n",
      "BertEncoder: tensor[53]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.query.weight, offset=1208737792, type=0\n",
      "BertEncoder: tensor[54]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.query.bias, offset=1212932096, type=0\n",
      "BertEncoder: tensor[55]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.key.weight, offset=1212936192, type=0\n",
      "BertEncoder: tensor[56]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.key.bias, offset=1217130496, type=0\n",
      "BertEncoder: tensor[57]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.value.weight, offset=1217134592, type=0\n",
      "BertEncoder: tensor[58]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.value.bias, offset=1221328896, type=0\n",
      "BertEncoder: tensor[59]: type = f32, n_dims = 2, name = encoder.layer.3.attention.output.dense.weight, offset=1221332992, type=0\n",
      "BertEncoder: tensor[60]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.dense.bias, offset=1225527296, type=0\n",
      "BertEncoder: tensor[61]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.LayerNorm.weight, offset=1225531392, type=0\n",
      "BertEncoder: tensor[62]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.LayerNorm.bias, offset=1225535488, type=0\n",
      "BertEncoder: tensor[63]: type = f32, n_dims = 2, name = encoder.layer.3.intermediate.dense.weight, offset=1225539584, type=0\n",
      "BertEncoder: tensor[64]: type = f32, n_dims = 1, name = encoder.layer.3.intermediate.dense.bias, offset=1242316800, type=0\n",
      "BertEncoder: tensor[65]: type = f32, n_dims = 2, name = encoder.layer.3.output.dense.weight, offset=1242333184, type=0\n",
      "BertEncoder: tensor[66]: type = f32, n_dims = 1, name = encoder.layer.3.output.dense.bias, offset=1259110400, type=0\n",
      "BertEncoder: tensor[67]: type = f32, n_dims = 1, name = encoder.layer.3.output.LayerNorm.weight, offset=1259114496, type=0\n",
      "BertEncoder: tensor[68]: type = f32, n_dims = 1, name = encoder.layer.3.output.LayerNorm.bias, offset=1259118592, type=0\n",
      "BertEncoder: tensor[69]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.query.weight, offset=1259122688, type=0\n",
      "BertEncoder: tensor[70]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.query.bias, offset=1263316992, type=0\n",
      "BertEncoder: tensor[71]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.key.weight, offset=1263321088, type=0\n",
      "BertEncoder: tensor[72]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.key.bias, offset=1267515392, type=0\n",
      "BertEncoder: tensor[73]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.value.weight, offset=1267519488, type=0\n",
      "BertEncoder: tensor[74]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.value.bias, offset=1271713792, type=0\n",
      "BertEncoder: tensor[75]: type = f32, n_dims = 2, name = encoder.layer.4.attention.output.dense.weight, offset=1271717888, type=0\n",
      "BertEncoder: tensor[76]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.dense.bias, offset=1275912192, type=0\n",
      "BertEncoder: tensor[77]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.LayerNorm.weight, offset=1275916288, type=0\n",
      "BertEncoder: tensor[78]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.LayerNorm.bias, offset=1275920384, type=0\n",
      "BertEncoder: tensor[79]: type = f32, n_dims = 2, name = encoder.layer.4.intermediate.dense.weight, offset=1275924480, type=0\n",
      "BertEncoder: tensor[80]: type = f32, n_dims = 1, name = encoder.layer.4.intermediate.dense.bias, offset=1292701696, type=0\n",
      "BertEncoder: tensor[81]: type = f32, n_dims = 2, name = encoder.layer.4.output.dense.weight, offset=1292718080, type=0\n",
      "BertEncoder: tensor[82]: type = f32, n_dims = 1, name = encoder.layer.4.output.dense.bias, offset=1309495296, type=0\n",
      "BertEncoder: tensor[83]: type = f32, n_dims = 1, name = encoder.layer.4.output.LayerNorm.weight, offset=1309499392, type=0\n",
      "BertEncoder: tensor[84]: type = f32, n_dims = 1, name = encoder.layer.4.output.LayerNorm.bias, offset=1309503488, type=0\n",
      "BertEncoder: tensor[85]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.query.weight, offset=1309507584, type=0\n",
      "BertEncoder: tensor[86]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.query.bias, offset=1313701888, type=0\n",
      "BertEncoder: tensor[87]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.key.weight, offset=1313705984, type=0\n",
      "BertEncoder: tensor[88]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.key.bias, offset=1317900288, type=0\n",
      "BertEncoder: tensor[89]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.value.weight, offset=1317904384, type=0\n",
      "BertEncoder: tensor[90]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.value.bias, offset=1322098688, type=0\n",
      "BertEncoder: tensor[91]: type = f32, n_dims = 2, name = encoder.layer.5.attention.output.dense.weight, offset=1322102784, type=0\n",
      "BertEncoder: tensor[92]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.dense.bias, offset=1326297088, type=0\n",
      "BertEncoder: tensor[93]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.LayerNorm.weight, offset=1326301184, type=0\n",
      "BertEncoder: tensor[94]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.LayerNorm.bias, offset=1326305280, type=0\n",
      "BertEncoder: tensor[95]: type = f32, n_dims = 2, name = encoder.layer.5.intermediate.dense.weight, offset=1326309376, type=0\n",
      "BertEncoder: tensor[96]: type = f32, n_dims = 1, name = encoder.layer.5.intermediate.dense.bias, offset=1343086592, type=0\n",
      "BertEncoder: tensor[97]: type = f32, n_dims = 2, name = encoder.layer.5.output.dense.weight, offset=1343102976, type=0\n",
      "BertEncoder: tensor[98]: type = f32, n_dims = 1, name = encoder.layer.5.output.dense.bias, offset=1359880192, type=0\n",
      "BertEncoder: tensor[99]: type = f32, n_dims = 1, name = encoder.layer.5.output.LayerNorm.weight, offset=1359884288, type=0\n",
      "BertEncoder: tensor[100]: type = f32, n_dims = 1, name = encoder.layer.5.output.LayerNorm.bias, offset=1359888384, type=0\n",
      "BertEncoder: tensor[101]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.query.weight, offset=1359892480, type=0\n",
      "BertEncoder: tensor[102]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.query.bias, offset=1364086784, type=0\n",
      "BertEncoder: tensor[103]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.key.weight, offset=1364090880, type=0\n",
      "BertEncoder: tensor[104]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.key.bias, offset=1368285184, type=0\n",
      "BertEncoder: tensor[105]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.value.weight, offset=1368289280, type=0\n",
      "BertEncoder: tensor[106]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.value.bias, offset=1372483584, type=0\n",
      "BertEncoder: tensor[107]: type = f32, n_dims = 2, name = encoder.layer.6.attention.output.dense.weight, offset=1372487680, type=0\n",
      "BertEncoder: tensor[108]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.dense.bias, offset=1376681984, type=0\n",
      "BertEncoder: tensor[109]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.LayerNorm.weight, offset=1376686080, type=0\n",
      "BertEncoder: tensor[110]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.LayerNorm.bias, offset=1376690176, type=0\n",
      "BertEncoder: tensor[111]: type = f32, n_dims = 2, name = encoder.layer.6.intermediate.dense.weight, offset=1376694272, type=0\n",
      "BertEncoder: tensor[112]: type = f32, n_dims = 1, name = encoder.layer.6.intermediate.dense.bias, offset=1393471488, type=0\n",
      "BertEncoder: tensor[113]: type = f32, n_dims = 2, name = encoder.layer.6.output.dense.weight, offset=1393487872, type=0\n",
      "BertEncoder: tensor[114]: type = f32, n_dims = 1, name = encoder.layer.6.output.dense.bias, offset=1410265088, type=0\n",
      "BertEncoder: tensor[115]: type = f32, n_dims = 1, name = encoder.layer.6.output.LayerNorm.weight, offset=1410269184, type=0\n",
      "BertEncoder: tensor[116]: type = f32, n_dims = 1, name = encoder.layer.6.output.LayerNorm.bias, offset=1410273280, type=0\n",
      "BertEncoder: tensor[117]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.query.weight, offset=1410277376, type=0\n",
      "BertEncoder: tensor[118]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.query.bias, offset=1414471680, type=0\n",
      "BertEncoder: tensor[119]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.key.weight, offset=1414475776, type=0\n",
      "BertEncoder: tensor[120]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.key.bias, offset=1418670080, type=0\n",
      "BertEncoder: tensor[121]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.value.weight, offset=1418674176, type=0\n",
      "BertEncoder: tensor[122]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.value.bias, offset=1422868480, type=0\n",
      "BertEncoder: tensor[123]: type = f32, n_dims = 2, name = encoder.layer.7.attention.output.dense.weight, offset=1422872576, type=0\n",
      "BertEncoder: tensor[124]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.dense.bias, offset=1427066880, type=0\n",
      "BertEncoder: tensor[125]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.LayerNorm.weight, offset=1427070976, type=0\n",
      "BertEncoder: tensor[126]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.LayerNorm.bias, offset=1427075072, type=0\n",
      "BertEncoder: tensor[127]: type = f32, n_dims = 2, name = encoder.layer.7.intermediate.dense.weight, offset=1427079168, type=0\n",
      "BertEncoder: tensor[128]: type = f32, n_dims = 1, name = encoder.layer.7.intermediate.dense.bias, offset=1443856384, type=0\n",
      "BertEncoder: tensor[129]: type = f32, n_dims = 2, name = encoder.layer.7.output.dense.weight, offset=1443872768, type=0\n",
      "BertEncoder: tensor[130]: type = f32, n_dims = 1, name = encoder.layer.7.output.dense.bias, offset=1460649984, type=0\n",
      "BertEncoder: tensor[131]: type = f32, n_dims = 1, name = encoder.layer.7.output.LayerNorm.weight, offset=1460654080, type=0\n",
      "BertEncoder: tensor[132]: type = f32, n_dims = 1, name = encoder.layer.7.output.LayerNorm.bias, offset=1460658176, type=0\n",
      "BertEncoder: tensor[133]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.query.weight, offset=1460662272, type=0\n",
      "BertEncoder: tensor[134]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.query.bias, offset=1464856576, type=0\n",
      "BertEncoder: tensor[135]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.key.weight, offset=1464860672, type=0\n",
      "BertEncoder: tensor[136]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.key.bias, offset=1469054976, type=0\n",
      "BertEncoder: tensor[137]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.value.weight, offset=1469059072, type=0\n",
      "BertEncoder: tensor[138]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.value.bias, offset=1473253376, type=0\n",
      "BertEncoder: tensor[139]: type = f32, n_dims = 2, name = encoder.layer.8.attention.output.dense.weight, offset=1473257472, type=0\n",
      "BertEncoder: tensor[140]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.dense.bias, offset=1477451776, type=0\n",
      "BertEncoder: tensor[141]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.LayerNorm.weight, offset=1477455872, type=0\n",
      "BertEncoder: tensor[142]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.LayerNorm.bias, offset=1477459968, type=0\n",
      "BertEncoder: tensor[143]: type = f32, n_dims = 2, name = encoder.layer.8.intermediate.dense.weight, offset=1477464064, type=0\n",
      "BertEncoder: tensor[144]: type = f32, n_dims = 1, name = encoder.layer.8.intermediate.dense.bias, offset=1494241280, type=0\n",
      "BertEncoder: tensor[145]: type = f32, n_dims = 2, name = encoder.layer.8.output.dense.weight, offset=1494257664, type=0\n",
      "BertEncoder: tensor[146]: type = f32, n_dims = 1, name = encoder.layer.8.output.dense.bias, offset=1511034880, type=0\n",
      "BertEncoder: tensor[147]: type = f32, n_dims = 1, name = encoder.layer.8.output.LayerNorm.weight, offset=1511038976, type=0\n",
      "BertEncoder: tensor[148]: type = f32, n_dims = 1, name = encoder.layer.8.output.LayerNorm.bias, offset=1511043072, type=0\n",
      "BertEncoder: tensor[149]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.query.weight, offset=1511047168, type=0\n",
      "BertEncoder: tensor[150]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.query.bias, offset=1515241472, type=0\n",
      "BertEncoder: tensor[151]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.key.weight, offset=1515245568, type=0\n",
      "BertEncoder: tensor[152]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.key.bias, offset=1519439872, type=0\n",
      "BertEncoder: tensor[153]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.value.weight, offset=1519443968, type=0\n",
      "BertEncoder: tensor[154]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.value.bias, offset=1523638272, type=0\n",
      "BertEncoder: tensor[155]: type = f32, n_dims = 2, name = encoder.layer.9.attention.output.dense.weight, offset=1523642368, type=0\n",
      "BertEncoder: tensor[156]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.dense.bias, offset=1527836672, type=0\n",
      "BertEncoder: tensor[157]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.LayerNorm.weight, offset=1527840768, type=0\n",
      "BertEncoder: tensor[158]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.LayerNorm.bias, offset=1527844864, type=0\n",
      "BertEncoder: tensor[159]: type = f32, n_dims = 2, name = encoder.layer.9.intermediate.dense.weight, offset=1527848960, type=0\n",
      "BertEncoder: tensor[160]: type = f32, n_dims = 1, name = encoder.layer.9.intermediate.dense.bias, offset=1544626176, type=0\n",
      "BertEncoder: tensor[161]: type = f32, n_dims = 2, name = encoder.layer.9.output.dense.weight, offset=1544642560, type=0\n",
      "BertEncoder: tensor[162]: type = f32, n_dims = 1, name = encoder.layer.9.output.dense.bias, offset=1561419776, type=0\n",
      "BertEncoder: tensor[163]: type = f32, n_dims = 1, name = encoder.layer.9.output.LayerNorm.weight, offset=1561423872, type=0\n",
      "BertEncoder: tensor[164]: type = f32, n_dims = 1, name = encoder.layer.9.output.LayerNorm.bias, offset=1561427968, type=0\n",
      "BertEncoder: tensor[165]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.query.weight, offset=1561432064, type=0\n",
      "BertEncoder: tensor[166]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.query.bias, offset=1565626368, type=0\n",
      "BertEncoder: tensor[167]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.key.weight, offset=1565630464, type=0\n",
      "BertEncoder: tensor[168]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.key.bias, offset=1569824768, type=0\n",
      "BertEncoder: tensor[169]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.value.weight, offset=1569828864, type=0\n",
      "BertEncoder: tensor[170]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.value.bias, offset=1574023168, type=0\n",
      "BertEncoder: tensor[171]: type = f32, n_dims = 2, name = encoder.layer.10.attention.output.dense.weight, offset=1574027264, type=0\n",
      "BertEncoder: tensor[172]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.dense.bias, offset=1578221568, type=0\n",
      "BertEncoder: tensor[173]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.LayerNorm.weight, offset=1578225664, type=0\n",
      "BertEncoder: tensor[174]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.LayerNorm.bias, offset=1578229760, type=0\n",
      "BertEncoder: tensor[175]: type = f32, n_dims = 2, name = encoder.layer.10.intermediate.dense.weight, offset=1578233856, type=0\n",
      "BertEncoder: tensor[176]: type = f32, n_dims = 1, name = encoder.layer.10.intermediate.dense.bias, offset=1595011072, type=0\n",
      "BertEncoder: tensor[177]: type = f32, n_dims = 2, name = encoder.layer.10.output.dense.weight, offset=1595027456, type=0\n",
      "BertEncoder: tensor[178]: type = f32, n_dims = 1, name = encoder.layer.10.output.dense.bias, offset=1611804672, type=0\n",
      "BertEncoder: tensor[179]: type = f32, n_dims = 1, name = encoder.layer.10.output.LayerNorm.weight, offset=1611808768, type=0\n",
      "BertEncoder: tensor[180]: type = f32, n_dims = 1, name = encoder.layer.10.output.LayerNorm.bias, offset=1611812864, type=0\n",
      "BertEncoder: tensor[181]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.query.weight, offset=1611816960, type=0\n",
      "BertEncoder: tensor[182]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.query.bias, offset=1616011264, type=0\n",
      "BertEncoder: tensor[183]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.key.weight, offset=1616015360, type=0\n",
      "BertEncoder: tensor[184]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.key.bias, offset=1620209664, type=0\n",
      "BertEncoder: tensor[185]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.value.weight, offset=1620213760, type=0\n",
      "BertEncoder: tensor[186]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.value.bias, offset=1624408064, type=0\n",
      "BertEncoder: tensor[187]: type = f32, n_dims = 2, name = encoder.layer.11.attention.output.dense.weight, offset=1624412160, type=0\n",
      "BertEncoder: tensor[188]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.dense.bias, offset=1628606464, type=0\n",
      "BertEncoder: tensor[189]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.LayerNorm.weight, offset=1628610560, type=0\n",
      "BertEncoder: tensor[190]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.LayerNorm.bias, offset=1628614656, type=0\n",
      "BertEncoder: tensor[191]: type = f32, n_dims = 2, name = encoder.layer.11.intermediate.dense.weight, offset=1628618752, type=0\n",
      "BertEncoder: tensor[192]: type = f32, n_dims = 1, name = encoder.layer.11.intermediate.dense.bias, offset=1645395968, type=0\n",
      "BertEncoder: tensor[193]: type = f32, n_dims = 2, name = encoder.layer.11.output.dense.weight, offset=1645412352, type=0\n",
      "BertEncoder: tensor[194]: type = f32, n_dims = 1, name = encoder.layer.11.output.dense.bias, offset=1662189568, type=0\n",
      "BertEncoder: tensor[195]: type = f32, n_dims = 1, name = encoder.layer.11.output.LayerNorm.weight, offset=1662193664, type=0\n",
      "BertEncoder: tensor[196]: type = f32, n_dims = 1, name = encoder.layer.11.output.LayerNorm.bias, offset=1662197760, type=0\n",
      "BertEncoder: tensor[197]: type = f32, n_dims = 2, name = encoder.layer.12.attention.self.query.weight, offset=1662201856, type=0\n",
      "BertEncoder: tensor[198]: type = f32, n_dims = 1, name = encoder.layer.12.attention.self.query.bias, offset=1666396160, type=0\n",
      "BertEncoder: tensor[199]: type = f32, n_dims = 2, name = encoder.layer.12.attention.self.key.weight, offset=1666400256, type=0\n",
      "BertEncoder: tensor[200]: type = f32, n_dims = 1, name = encoder.layer.12.attention.self.key.bias, offset=1670594560, type=0\n",
      "BertEncoder: tensor[201]: type = f32, n_dims = 2, name = encoder.layer.12.attention.self.value.weight, offset=1670598656, type=0\n",
      "BertEncoder: tensor[202]: type = f32, n_dims = 1, name = encoder.layer.12.attention.self.value.bias, offset=1674792960, type=0\n",
      "BertEncoder: tensor[203]: type = f32, n_dims = 2, name = encoder.layer.12.attention.output.dense.weight, offset=1674797056, type=0\n",
      "BertEncoder: tensor[204]: type = f32, n_dims = 1, name = encoder.layer.12.attention.output.dense.bias, offset=1678991360, type=0\n",
      "BertEncoder: tensor[205]: type = f32, n_dims = 1, name = encoder.layer.12.attention.output.LayerNorm.weight, offset=1678995456, type=0\n",
      "BertEncoder: tensor[206]: type = f32, n_dims = 1, name = encoder.layer.12.attention.output.LayerNorm.bias, offset=1678999552, type=0\n",
      "BertEncoder: tensor[207]: type = f32, n_dims = 2, name = encoder.layer.12.intermediate.dense.weight, offset=1679003648, type=0\n",
      "BertEncoder: tensor[208]: type = f32, n_dims = 1, name = encoder.layer.12.intermediate.dense.bias, offset=1695780864, type=0\n",
      "BertEncoder: tensor[209]: type = f32, n_dims = 2, name = encoder.layer.12.output.dense.weight, offset=1695797248, type=0\n",
      "BertEncoder: tensor[210]: type = f32, n_dims = 1, name = encoder.layer.12.output.dense.bias, offset=1712574464, type=0\n",
      "BertEncoder: tensor[211]: type = f32, n_dims = 1, name = encoder.layer.12.output.LayerNorm.weight, offset=1712578560, type=0\n",
      "BertEncoder: tensor[212]: type = f32, n_dims = 1, name = encoder.layer.12.output.LayerNorm.bias, offset=1712582656, type=0\n",
      "BertEncoder: tensor[213]: type = f32, n_dims = 2, name = encoder.layer.13.attention.self.query.weight, offset=1712586752, type=0\n",
      "BertEncoder: tensor[214]: type = f32, n_dims = 1, name = encoder.layer.13.attention.self.query.bias, offset=1716781056, type=0\n",
      "BertEncoder: tensor[215]: type = f32, n_dims = 2, name = encoder.layer.13.attention.self.key.weight, offset=1716785152, type=0\n",
      "BertEncoder: tensor[216]: type = f32, n_dims = 1, name = encoder.layer.13.attention.self.key.bias, offset=1720979456, type=0\n",
      "BertEncoder: tensor[217]: type = f32, n_dims = 2, name = encoder.layer.13.attention.self.value.weight, offset=1720983552, type=0\n",
      "BertEncoder: tensor[218]: type = f32, n_dims = 1, name = encoder.layer.13.attention.self.value.bias, offset=1725177856, type=0\n",
      "BertEncoder: tensor[219]: type = f32, n_dims = 2, name = encoder.layer.13.attention.output.dense.weight, offset=1725181952, type=0\n",
      "BertEncoder: tensor[220]: type = f32, n_dims = 1, name = encoder.layer.13.attention.output.dense.bias, offset=1729376256, type=0\n",
      "BertEncoder: tensor[221]: type = f32, n_dims = 1, name = encoder.layer.13.attention.output.LayerNorm.weight, offset=1729380352, type=0\n",
      "BertEncoder: tensor[222]: type = f32, n_dims = 1, name = encoder.layer.13.attention.output.LayerNorm.bias, offset=1729384448, type=0\n",
      "BertEncoder: tensor[223]: type = f32, n_dims = 2, name = encoder.layer.13.intermediate.dense.weight, offset=1729388544, type=0\n",
      "BertEncoder: tensor[224]: type = f32, n_dims = 1, name = encoder.layer.13.intermediate.dense.bias, offset=1746165760, type=0\n",
      "BertEncoder: tensor[225]: type = f32, n_dims = 2, name = encoder.layer.13.output.dense.weight, offset=1746182144, type=0\n",
      "BertEncoder: tensor[226]: type = f32, n_dims = 1, name = encoder.layer.13.output.dense.bias, offset=1762959360, type=0\n",
      "BertEncoder: tensor[227]: type = f32, n_dims = 1, name = encoder.layer.13.output.LayerNorm.weight, offset=1762963456, type=0\n",
      "BertEncoder: tensor[228]: type = f32, n_dims = 1, name = encoder.layer.13.output.LayerNorm.bias, offset=1762967552, type=0\n",
      "BertEncoder: tensor[229]: type = f32, n_dims = 2, name = encoder.layer.14.attention.self.query.weight, offset=1762971648, type=0\n",
      "BertEncoder: tensor[230]: type = f32, n_dims = 1, name = encoder.layer.14.attention.self.query.bias, offset=1767165952, type=0\n",
      "BertEncoder: tensor[231]: type = f32, n_dims = 2, name = encoder.layer.14.attention.self.key.weight, offset=1767170048, type=0\n",
      "BertEncoder: tensor[232]: type = f32, n_dims = 1, name = encoder.layer.14.attention.self.key.bias, offset=1771364352, type=0\n",
      "BertEncoder: tensor[233]: type = f32, n_dims = 2, name = encoder.layer.14.attention.self.value.weight, offset=1771368448, type=0\n",
      "BertEncoder: tensor[234]: type = f32, n_dims = 1, name = encoder.layer.14.attention.self.value.bias, offset=1775562752, type=0\n",
      "BertEncoder: tensor[235]: type = f32, n_dims = 2, name = encoder.layer.14.attention.output.dense.weight, offset=1775566848, type=0\n",
      "BertEncoder: tensor[236]: type = f32, n_dims = 1, name = encoder.layer.14.attention.output.dense.bias, offset=1779761152, type=0\n",
      "BertEncoder: tensor[237]: type = f32, n_dims = 1, name = encoder.layer.14.attention.output.LayerNorm.weight, offset=1779765248, type=0\n",
      "BertEncoder: tensor[238]: type = f32, n_dims = 1, name = encoder.layer.14.attention.output.LayerNorm.bias, offset=1779769344, type=0\n",
      "BertEncoder: tensor[239]: type = f32, n_dims = 2, name = encoder.layer.14.intermediate.dense.weight, offset=1779773440, type=0\n",
      "BertEncoder: tensor[240]: type = f32, n_dims = 1, name = encoder.layer.14.intermediate.dense.bias, offset=1796550656, type=0\n",
      "BertEncoder: tensor[241]: type = f32, n_dims = 2, name = encoder.layer.14.output.dense.weight, offset=1796567040, type=0\n",
      "BertEncoder: tensor[242]: type = f32, n_dims = 1, name = encoder.layer.14.output.dense.bias, offset=1813344256, type=0\n",
      "BertEncoder: tensor[243]: type = f32, n_dims = 1, name = encoder.layer.14.output.LayerNorm.weight, offset=1813348352, type=0\n",
      "BertEncoder: tensor[244]: type = f32, n_dims = 1, name = encoder.layer.14.output.LayerNorm.bias, offset=1813352448, type=0\n",
      "BertEncoder: tensor[245]: type = f32, n_dims = 2, name = encoder.layer.15.attention.self.query.weight, offset=1813356544, type=0\n",
      "BertEncoder: tensor[246]: type = f32, n_dims = 1, name = encoder.layer.15.attention.self.query.bias, offset=1817550848, type=0\n",
      "BertEncoder: tensor[247]: type = f32, n_dims = 2, name = encoder.layer.15.attention.self.key.weight, offset=1817554944, type=0\n",
      "BertEncoder: tensor[248]: type = f32, n_dims = 1, name = encoder.layer.15.attention.self.key.bias, offset=1821749248, type=0\n",
      "BertEncoder: tensor[249]: type = f32, n_dims = 2, name = encoder.layer.15.attention.self.value.weight, offset=1821753344, type=0\n",
      "BertEncoder: tensor[250]: type = f32, n_dims = 1, name = encoder.layer.15.attention.self.value.bias, offset=1825947648, type=0\n",
      "BertEncoder: tensor[251]: type = f32, n_dims = 2, name = encoder.layer.15.attention.output.dense.weight, offset=1825951744, type=0\n",
      "BertEncoder: tensor[252]: type = f32, n_dims = 1, name = encoder.layer.15.attention.output.dense.bias, offset=1830146048, type=0\n",
      "BertEncoder: tensor[253]: type = f32, n_dims = 1, name = encoder.layer.15.attention.output.LayerNorm.weight, offset=1830150144, type=0\n",
      "BertEncoder: tensor[254]: type = f32, n_dims = 1, name = encoder.layer.15.attention.output.LayerNorm.bias, offset=1830154240, type=0\n",
      "BertEncoder: tensor[255]: type = f32, n_dims = 2, name = encoder.layer.15.intermediate.dense.weight, offset=1830158336, type=0\n",
      "BertEncoder: tensor[256]: type = f32, n_dims = 1, name = encoder.layer.15.intermediate.dense.bias, offset=1846935552, type=0\n",
      "BertEncoder: tensor[257]: type = f32, n_dims = 2, name = encoder.layer.15.output.dense.weight, offset=1846951936, type=0\n",
      "BertEncoder: tensor[258]: type = f32, n_dims = 1, name = encoder.layer.15.output.dense.bias, offset=1863729152, type=0\n",
      "BertEncoder: tensor[259]: type = f32, n_dims = 1, name = encoder.layer.15.output.LayerNorm.weight, offset=1863733248, type=0\n",
      "BertEncoder: tensor[260]: type = f32, n_dims = 1, name = encoder.layer.15.output.LayerNorm.bias, offset=1863737344, type=0\n",
      "BertEncoder: tensor[261]: type = f32, n_dims = 2, name = encoder.layer.16.attention.self.query.weight, offset=1863741440, type=0\n",
      "BertEncoder: tensor[262]: type = f32, n_dims = 1, name = encoder.layer.16.attention.self.query.bias, offset=1867935744, type=0\n",
      "BertEncoder: tensor[263]: type = f32, n_dims = 2, name = encoder.layer.16.attention.self.key.weight, offset=1867939840, type=0\n",
      "BertEncoder: tensor[264]: type = f32, n_dims = 1, name = encoder.layer.16.attention.self.key.bias, offset=1872134144, type=0\n",
      "BertEncoder: tensor[265]: type = f32, n_dims = 2, name = encoder.layer.16.attention.self.value.weight, offset=1872138240, type=0\n",
      "BertEncoder: tensor[266]: type = f32, n_dims = 1, name = encoder.layer.16.attention.self.value.bias, offset=1876332544, type=0\n",
      "BertEncoder: tensor[267]: type = f32, n_dims = 2, name = encoder.layer.16.attention.output.dense.weight, offset=1876336640, type=0\n",
      "BertEncoder: tensor[268]: type = f32, n_dims = 1, name = encoder.layer.16.attention.output.dense.bias, offset=1880530944, type=0\n",
      "BertEncoder: tensor[269]: type = f32, n_dims = 1, name = encoder.layer.16.attention.output.LayerNorm.weight, offset=1880535040, type=0\n",
      "BertEncoder: tensor[270]: type = f32, n_dims = 1, name = encoder.layer.16.attention.output.LayerNorm.bias, offset=1880539136, type=0\n",
      "BertEncoder: tensor[271]: type = f32, n_dims = 2, name = encoder.layer.16.intermediate.dense.weight, offset=1880543232, type=0\n",
      "BertEncoder: tensor[272]: type = f32, n_dims = 1, name = encoder.layer.16.intermediate.dense.bias, offset=1897320448, type=0\n",
      "BertEncoder: tensor[273]: type = f32, n_dims = 2, name = encoder.layer.16.output.dense.weight, offset=1897336832, type=0\n",
      "BertEncoder: tensor[274]: type = f32, n_dims = 1, name = encoder.layer.16.output.dense.bias, offset=1914114048, type=0\n",
      "BertEncoder: tensor[275]: type = f32, n_dims = 1, name = encoder.layer.16.output.LayerNorm.weight, offset=1914118144, type=0\n",
      "BertEncoder: tensor[276]: type = f32, n_dims = 1, name = encoder.layer.16.output.LayerNorm.bias, offset=1914122240, type=0\n",
      "BertEncoder: tensor[277]: type = f32, n_dims = 2, name = encoder.layer.17.attention.self.query.weight, offset=1914126336, type=0\n",
      "BertEncoder: tensor[278]: type = f32, n_dims = 1, name = encoder.layer.17.attention.self.query.bias, offset=1918320640, type=0\n",
      "BertEncoder: tensor[279]: type = f32, n_dims = 2, name = encoder.layer.17.attention.self.key.weight, offset=1918324736, type=0\n",
      "BertEncoder: tensor[280]: type = f32, n_dims = 1, name = encoder.layer.17.attention.self.key.bias, offset=1922519040, type=0\n",
      "BertEncoder: tensor[281]: type = f32, n_dims = 2, name = encoder.layer.17.attention.self.value.weight, offset=1922523136, type=0\n",
      "BertEncoder: tensor[282]: type = f32, n_dims = 1, name = encoder.layer.17.attention.self.value.bias, offset=1926717440, type=0\n",
      "BertEncoder: tensor[283]: type = f32, n_dims = 2, name = encoder.layer.17.attention.output.dense.weight, offset=1926721536, type=0\n",
      "BertEncoder: tensor[284]: type = f32, n_dims = 1, name = encoder.layer.17.attention.output.dense.bias, offset=1930915840, type=0\n",
      "BertEncoder: tensor[285]: type = f32, n_dims = 1, name = encoder.layer.17.attention.output.LayerNorm.weight, offset=1930919936, type=0\n",
      "BertEncoder: tensor[286]: type = f32, n_dims = 1, name = encoder.layer.17.attention.output.LayerNorm.bias, offset=1930924032, type=0\n",
      "BertEncoder: tensor[287]: type = f32, n_dims = 2, name = encoder.layer.17.intermediate.dense.weight, offset=1930928128, type=0\n",
      "BertEncoder: tensor[288]: type = f32, n_dims = 1, name = encoder.layer.17.intermediate.dense.bias, offset=1947705344, type=0\n",
      "BertEncoder: tensor[289]: type = f32, n_dims = 2, name = encoder.layer.17.output.dense.weight, offset=1947721728, type=0\n",
      "BertEncoder: tensor[290]: type = f32, n_dims = 1, name = encoder.layer.17.output.dense.bias, offset=1964498944, type=0\n",
      "BertEncoder: tensor[291]: type = f32, n_dims = 1, name = encoder.layer.17.output.LayerNorm.weight, offset=1964503040, type=0\n",
      "BertEncoder: tensor[292]: type = f32, n_dims = 1, name = encoder.layer.17.output.LayerNorm.bias, offset=1964507136, type=0\n",
      "BertEncoder: tensor[293]: type = f32, n_dims = 2, name = encoder.layer.18.attention.self.query.weight, offset=1964511232, type=0\n",
      "BertEncoder: tensor[294]: type = f32, n_dims = 1, name = encoder.layer.18.attention.self.query.bias, offset=1968705536, type=0\n",
      "BertEncoder: tensor[295]: type = f32, n_dims = 2, name = encoder.layer.18.attention.self.key.weight, offset=1968709632, type=0\n",
      "BertEncoder: tensor[296]: type = f32, n_dims = 1, name = encoder.layer.18.attention.self.key.bias, offset=1972903936, type=0\n",
      "BertEncoder: tensor[297]: type = f32, n_dims = 2, name = encoder.layer.18.attention.self.value.weight, offset=1972908032, type=0\n",
      "BertEncoder: tensor[298]: type = f32, n_dims = 1, name = encoder.layer.18.attention.self.value.bias, offset=1977102336, type=0\n",
      "BertEncoder: tensor[299]: type = f32, n_dims = 2, name = encoder.layer.18.attention.output.dense.weight, offset=1977106432, type=0\n",
      "BertEncoder: tensor[300]: type = f32, n_dims = 1, name = encoder.layer.18.attention.output.dense.bias, offset=1981300736, type=0\n",
      "BertEncoder: tensor[301]: type = f32, n_dims = 1, name = encoder.layer.18.attention.output.LayerNorm.weight, offset=1981304832, type=0\n",
      "BertEncoder: tensor[302]: type = f32, n_dims = 1, name = encoder.layer.18.attention.output.LayerNorm.bias, offset=1981308928, type=0\n",
      "BertEncoder: tensor[303]: type = f32, n_dims = 2, name = encoder.layer.18.intermediate.dense.weight, offset=1981313024, type=0\n",
      "BertEncoder: tensor[304]: type = f32, n_dims = 1, name = encoder.layer.18.intermediate.dense.bias, offset=1998090240, type=0\n",
      "BertEncoder: tensor[305]: type = f32, n_dims = 2, name = encoder.layer.18.output.dense.weight, offset=1998106624, type=0\n",
      "BertEncoder: tensor[306]: type = f32, n_dims = 1, name = encoder.layer.18.output.dense.bias, offset=2014883840, type=0\n",
      "BertEncoder: tensor[307]: type = f32, n_dims = 1, name = encoder.layer.18.output.LayerNorm.weight, offset=2014887936, type=0\n",
      "BertEncoder: tensor[308]: type = f32, n_dims = 1, name = encoder.layer.18.output.LayerNorm.bias, offset=2014892032, type=0\n",
      "BertEncoder: tensor[309]: type = f32, n_dims = 2, name = encoder.layer.19.attention.self.query.weight, offset=2014896128, type=0\n",
      "BertEncoder: tensor[310]: type = f32, n_dims = 1, name = encoder.layer.19.attention.self.query.bias, offset=2019090432, type=0\n",
      "BertEncoder: tensor[311]: type = f32, n_dims = 2, name = encoder.layer.19.attention.self.key.weight, offset=2019094528, type=0\n",
      "BertEncoder: tensor[312]: type = f32, n_dims = 1, name = encoder.layer.19.attention.self.key.bias, offset=2023288832, type=0\n",
      "BertEncoder: tensor[313]: type = f32, n_dims = 2, name = encoder.layer.19.attention.self.value.weight, offset=2023292928, type=0\n",
      "BertEncoder: tensor[314]: type = f32, n_dims = 1, name = encoder.layer.19.attention.self.value.bias, offset=2027487232, type=0\n",
      "BertEncoder: tensor[315]: type = f32, n_dims = 2, name = encoder.layer.19.attention.output.dense.weight, offset=2027491328, type=0\n",
      "BertEncoder: tensor[316]: type = f32, n_dims = 1, name = encoder.layer.19.attention.output.dense.bias, offset=2031685632, type=0\n",
      "BertEncoder: tensor[317]: type = f32, n_dims = 1, name = encoder.layer.19.attention.output.LayerNorm.weight, offset=2031689728, type=0\n",
      "BertEncoder: tensor[318]: type = f32, n_dims = 1, name = encoder.layer.19.attention.output.LayerNorm.bias, offset=2031693824, type=0\n",
      "BertEncoder: tensor[319]: type = f32, n_dims = 2, name = encoder.layer.19.intermediate.dense.weight, offset=2031697920, type=0\n",
      "BertEncoder: tensor[320]: type = f32, n_dims = 1, name = encoder.layer.19.intermediate.dense.bias, offset=2048475136, type=0\n",
      "BertEncoder: tensor[321]: type = f32, n_dims = 2, name = encoder.layer.19.output.dense.weight, offset=2048491520, type=0\n",
      "BertEncoder: tensor[322]: type = f32, n_dims = 1, name = encoder.layer.19.output.dense.bias, offset=2065268736, type=0\n",
      "BertEncoder: tensor[323]: type = f32, n_dims = 1, name = encoder.layer.19.output.LayerNorm.weight, offset=2065272832, type=0\n",
      "BertEncoder: tensor[324]: type = f32, n_dims = 1, name = encoder.layer.19.output.LayerNorm.bias, offset=2065276928, type=0\n",
      "BertEncoder: tensor[325]: type = f32, n_dims = 2, name = encoder.layer.20.attention.self.query.weight, offset=2065281024, type=0\n",
      "BertEncoder: tensor[326]: type = f32, n_dims = 1, name = encoder.layer.20.attention.self.query.bias, offset=2069475328, type=0\n",
      "BertEncoder: tensor[327]: type = f32, n_dims = 2, name = encoder.layer.20.attention.self.key.weight, offset=2069479424, type=0\n",
      "BertEncoder: tensor[328]: type = f32, n_dims = 1, name = encoder.layer.20.attention.self.key.bias, offset=2073673728, type=0\n",
      "BertEncoder: tensor[329]: type = f32, n_dims = 2, name = encoder.layer.20.attention.self.value.weight, offset=2073677824, type=0\n",
      "BertEncoder: tensor[330]: type = f32, n_dims = 1, name = encoder.layer.20.attention.self.value.bias, offset=2077872128, type=0\n",
      "BertEncoder: tensor[331]: type = f32, n_dims = 2, name = encoder.layer.20.attention.output.dense.weight, offset=2077876224, type=0\n",
      "BertEncoder: tensor[332]: type = f32, n_dims = 1, name = encoder.layer.20.attention.output.dense.bias, offset=2082070528, type=0\n",
      "BertEncoder: tensor[333]: type = f32, n_dims = 1, name = encoder.layer.20.attention.output.LayerNorm.weight, offset=2082074624, type=0\n",
      "BertEncoder: tensor[334]: type = f32, n_dims = 1, name = encoder.layer.20.attention.output.LayerNorm.bias, offset=2082078720, type=0\n",
      "BertEncoder: tensor[335]: type = f32, n_dims = 2, name = encoder.layer.20.intermediate.dense.weight, offset=2082082816, type=0\n",
      "BertEncoder: tensor[336]: type = f32, n_dims = 1, name = encoder.layer.20.intermediate.dense.bias, offset=2098860032, type=0\n",
      "BertEncoder: tensor[337]: type = f32, n_dims = 2, name = encoder.layer.20.output.dense.weight, offset=2098876416, type=0\n",
      "BertEncoder: tensor[338]: type = f32, n_dims = 1, name = encoder.layer.20.output.dense.bias, offset=2115653632, type=0\n",
      "BertEncoder: tensor[339]: type = f32, n_dims = 1, name = encoder.layer.20.output.LayerNorm.weight, offset=2115657728, type=0\n",
      "BertEncoder: tensor[340]: type = f32, n_dims = 1, name = encoder.layer.20.output.LayerNorm.bias, offset=2115661824, type=0\n",
      "BertEncoder: tensor[341]: type = f32, n_dims = 2, name = encoder.layer.21.attention.self.query.weight, offset=2115665920, type=0\n",
      "BertEncoder: tensor[342]: type = f32, n_dims = 1, name = encoder.layer.21.attention.self.query.bias, offset=2119860224, type=0\n",
      "BertEncoder: tensor[343]: type = f32, n_dims = 2, name = encoder.layer.21.attention.self.key.weight, offset=2119864320, type=0\n",
      "BertEncoder: tensor[344]: type = f32, n_dims = 1, name = encoder.layer.21.attention.self.key.bias, offset=2124058624, type=0\n",
      "BertEncoder: tensor[345]: type = f32, n_dims = 2, name = encoder.layer.21.attention.self.value.weight, offset=2124062720, type=0\n",
      "BertEncoder: tensor[346]: type = f32, n_dims = 1, name = encoder.layer.21.attention.self.value.bias, offset=2128257024, type=0\n",
      "BertEncoder: tensor[347]: type = f32, n_dims = 2, name = encoder.layer.21.attention.output.dense.weight, offset=2128261120, type=0\n",
      "BertEncoder: tensor[348]: type = f32, n_dims = 1, name = encoder.layer.21.attention.output.dense.bias, offset=2132455424, type=0\n",
      "BertEncoder: tensor[349]: type = f32, n_dims = 1, name = encoder.layer.21.attention.output.LayerNorm.weight, offset=2132459520, type=0\n",
      "BertEncoder: tensor[350]: type = f32, n_dims = 1, name = encoder.layer.21.attention.output.LayerNorm.bias, offset=2132463616, type=0\n",
      "BertEncoder: tensor[351]: type = f32, n_dims = 2, name = encoder.layer.21.intermediate.dense.weight, offset=2132467712, type=0\n",
      "BertEncoder: tensor[352]: type = f32, n_dims = 1, name = encoder.layer.21.intermediate.dense.bias, offset=2149244928, type=0\n",
      "BertEncoder: tensor[353]: type = f32, n_dims = 2, name = encoder.layer.21.output.dense.weight, offset=2149261312, type=0\n",
      "BertEncoder: tensor[354]: type = f32, n_dims = 1, name = encoder.layer.21.output.dense.bias, offset=2166038528, type=0\n",
      "BertEncoder: tensor[355]: type = f32, n_dims = 1, name = encoder.layer.21.output.LayerNorm.weight, offset=2166042624, type=0\n",
      "BertEncoder: tensor[356]: type = f32, n_dims = 1, name = encoder.layer.21.output.LayerNorm.bias, offset=2166046720, type=0\n",
      "BertEncoder: tensor[357]: type = f32, n_dims = 2, name = encoder.layer.22.attention.self.query.weight, offset=2166050816, type=0\n",
      "BertEncoder: tensor[358]: type = f32, n_dims = 1, name = encoder.layer.22.attention.self.query.bias, offset=2170245120, type=0\n",
      "BertEncoder: tensor[359]: type = f32, n_dims = 2, name = encoder.layer.22.attention.self.key.weight, offset=2170249216, type=0\n",
      "BertEncoder: tensor[360]: type = f32, n_dims = 1, name = encoder.layer.22.attention.self.key.bias, offset=2174443520, type=0\n",
      "BertEncoder: tensor[361]: type = f32, n_dims = 2, name = encoder.layer.22.attention.self.value.weight, offset=2174447616, type=0\n",
      "BertEncoder: tensor[362]: type = f32, n_dims = 1, name = encoder.layer.22.attention.self.value.bias, offset=2178641920, type=0\n",
      "BertEncoder: tensor[363]: type = f32, n_dims = 2, name = encoder.layer.22.attention.output.dense.weight, offset=2178646016, type=0\n",
      "BertEncoder: tensor[364]: type = f32, n_dims = 1, name = encoder.layer.22.attention.output.dense.bias, offset=2182840320, type=0\n",
      "BertEncoder: tensor[365]: type = f32, n_dims = 1, name = encoder.layer.22.attention.output.LayerNorm.weight, offset=2182844416, type=0\n",
      "BertEncoder: tensor[366]: type = f32, n_dims = 1, name = encoder.layer.22.attention.output.LayerNorm.bias, offset=2182848512, type=0\n",
      "BertEncoder: tensor[367]: type = f32, n_dims = 2, name = encoder.layer.22.intermediate.dense.weight, offset=2182852608, type=0\n",
      "BertEncoder: tensor[368]: type = f32, n_dims = 1, name = encoder.layer.22.intermediate.dense.bias, offset=2199629824, type=0\n",
      "BertEncoder: tensor[369]: type = f32, n_dims = 2, name = encoder.layer.22.output.dense.weight, offset=2199646208, type=0\n",
      "BertEncoder: tensor[370]: type = f32, n_dims = 1, name = encoder.layer.22.output.dense.bias, offset=2216423424, type=0\n",
      "BertEncoder: tensor[371]: type = f32, n_dims = 1, name = encoder.layer.22.output.LayerNorm.weight, offset=2216427520, type=0\n",
      "BertEncoder: tensor[372]: type = f32, n_dims = 1, name = encoder.layer.22.output.LayerNorm.bias, offset=2216431616, type=0\n",
      "BertEncoder: tensor[373]: type = f32, n_dims = 2, name = encoder.layer.23.attention.self.query.weight, offset=2216435712, type=0\n",
      "BertEncoder: tensor[374]: type = f32, n_dims = 1, name = encoder.layer.23.attention.self.query.bias, offset=2220630016, type=0\n",
      "BertEncoder: tensor[375]: type = f32, n_dims = 2, name = encoder.layer.23.attention.self.key.weight, offset=2220634112, type=0\n",
      "BertEncoder: tensor[376]: type = f32, n_dims = 1, name = encoder.layer.23.attention.self.key.bias, offset=2224828416, type=0\n",
      "BertEncoder: tensor[377]: type = f32, n_dims = 2, name = encoder.layer.23.attention.self.value.weight, offset=2224832512, type=0\n",
      "BertEncoder: tensor[378]: type = f32, n_dims = 1, name = encoder.layer.23.attention.self.value.bias, offset=2229026816, type=0\n",
      "BertEncoder: tensor[379]: type = f32, n_dims = 2, name = encoder.layer.23.attention.output.dense.weight, offset=2229030912, type=0\n",
      "BertEncoder: tensor[380]: type = f32, n_dims = 1, name = encoder.layer.23.attention.output.dense.bias, offset=2233225216, type=0\n",
      "BertEncoder: tensor[381]: type = f32, n_dims = 1, name = encoder.layer.23.attention.output.LayerNorm.weight, offset=2233229312, type=0\n",
      "BertEncoder: tensor[382]: type = f32, n_dims = 1, name = encoder.layer.23.attention.output.LayerNorm.bias, offset=2233233408, type=0\n",
      "BertEncoder: tensor[383]: type = f32, n_dims = 2, name = encoder.layer.23.intermediate.dense.weight, offset=2233237504, type=0\n",
      "BertEncoder: tensor[384]: type = f32, n_dims = 1, name = encoder.layer.23.intermediate.dense.bias, offset=2250014720, type=0\n",
      "BertEncoder: tensor[385]: type = f32, n_dims = 2, name = encoder.layer.23.output.dense.weight, offset=2250031104, type=0\n",
      "BertEncoder: tensor[386]: type = f32, n_dims = 1, name = encoder.layer.23.output.dense.bias, offset=2266808320, type=0\n",
      "BertEncoder: tensor[387]: type = f32, n_dims = 1, name = encoder.layer.23.output.LayerNorm.weight, offset=2266812416, type=0\n",
      "BertEncoder: tensor[388]: type = f32, n_dims = 1, name = encoder.layer.23.output.LayerNorm.bias, offset=2266816512, type=0\n",
      "BertEncoder: tensor[389]: type = f32, n_dims = 2, name = pooler.dense.weight, offset=2266820608, type=0\n",
      "BertEncoder: tensor[390]: type = f32, n_dims = 1, name = pooler.dense.bias, offset=2271014912, type=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute buffer size: 0.48 MB\n",
      "===========testing: BAAI/bge-base-zh-v1.5===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "BertEncoder: GGUF\n",
      "BertEncoder: model name:   BAAI/bge-base-zh-v1.5\n",
      "BertEncoder: architecture:   BertModel\n",
      "BertEncoder: description:  gguf model for embeddings.cpp\n",
      "BertEncoder: GGUF version: 3\n",
      "BertEncoder: alignment:    32\n",
      "BertEncoder: n_tensors:    199\n",
      "BertEncoder: n_kv:         12\n",
      "BertEncoder: ftype:        f32\n",
      "\n",
      "BertEncoder: MODEL\n",
      "BertEncoder: n_vocab        = 21128\n",
      "BertEncoder: n_max_tokens   = 512\n",
      "BertEncoder: n_embd         = 768\n",
      "BertEncoder: n_intermediate = 3072\n",
      "BertEncoder: n_head         = 12\n",
      "BertEncoder: n_layer        = 12\n",
      "BertEncoder: layer_norm_eps = 1e-12\n",
      "\n",
      "BertEncoder: using CPU backend\n",
      "BertEncoder: tensor[0]: type = f32, n_dims = 2, name = embeddings.word_embeddings.weight, offset=0, type=0\n",
      "BertEncoder: tensor[1]: type = f32, n_dims = 2, name = embeddings.position_embeddings.weight, offset=64905216, type=0\n",
      "BertEncoder: tensor[2]: type = f32, n_dims = 2, name = embeddings.token_type_embeddings.weight, offset=66478080, type=0\n",
      "BertEncoder: tensor[3]: type = f32, n_dims = 1, name = embeddings.LayerNorm.weight, offset=66484224, type=0\n",
      "BertEncoder: tensor[4]: type = f32, n_dims = 1, name = embeddings.LayerNorm.bias, offset=66487296, type=0\n",
      "BertEncoder: tensor[5]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.query.weight, offset=66490368, type=0\n",
      "BertEncoder: tensor[6]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.query.bias, offset=68849664, type=0\n",
      "BertEncoder: tensor[7]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.key.weight, offset=68852736, type=0\n",
      "BertEncoder: tensor[8]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.key.bias, offset=71212032, type=0\n",
      "BertEncoder: tensor[9]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.value.weight, offset=71215104, type=0\n",
      "BertEncoder: tensor[10]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.value.bias, offset=73574400, type=0\n",
      "BertEncoder: tensor[11]: type = f32, n_dims = 2, name = encoder.layer.0.attention.output.dense.weight, offset=73577472, type=0\n",
      "BertEncoder: tensor[12]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.dense.bias, offset=75936768, type=0\n",
      "BertEncoder: tensor[13]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.LayerNorm.weight, offset=75939840, type=0\n",
      "BertEncoder: tensor[14]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.LayerNorm.bias, offset=75942912, type=0\n",
      "BertEncoder: tensor[15]: type = f32, n_dims = 2, name = encoder.layer.0.intermediate.dense.weight, offset=75945984, type=0\n",
      "BertEncoder: tensor[16]: type = f32, n_dims = 1, name = encoder.layer.0.intermediate.dense.bias, offset=85383168, type=0\n",
      "BertEncoder: tensor[17]: type = f32, n_dims = 2, name = encoder.layer.0.output.dense.weight, offset=85395456, type=0\n",
      "BertEncoder: tensor[18]: type = f32, n_dims = 1, name = encoder.layer.0.output.dense.bias, offset=94832640, type=0\n",
      "BertEncoder: tensor[19]: type = f32, n_dims = 1, name = encoder.layer.0.output.LayerNorm.weight, offset=94835712, type=0\n",
      "BertEncoder: tensor[20]: type = f32, n_dims = 1, name = encoder.layer.0.output.LayerNorm.bias, offset=94838784, type=0\n",
      "BertEncoder: tensor[21]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.query.weight, offset=94841856, type=0\n",
      "BertEncoder: tensor[22]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.query.bias, offset=97201152, type=0\n",
      "BertEncoder: tensor[23]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.key.weight, offset=97204224, type=0\n",
      "BertEncoder: tensor[24]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.key.bias, offset=99563520, type=0\n",
      "BertEncoder: tensor[25]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.value.weight, offset=99566592, type=0\n",
      "BertEncoder: tensor[26]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.value.bias, offset=101925888, type=0\n",
      "BertEncoder: tensor[27]: type = f32, n_dims = 2, name = encoder.layer.1.attention.output.dense.weight, offset=101928960, type=0\n",
      "BertEncoder: tensor[28]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.dense.bias, offset=104288256, type=0\n",
      "BertEncoder: tensor[29]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.LayerNorm.weight, offset=104291328, type=0\n",
      "BertEncoder: tensor[30]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.LayerNorm.bias, offset=104294400, type=0\n",
      "BertEncoder: tensor[31]: type = f32, n_dims = 2, name = encoder.layer.1.intermediate.dense.weight, offset=104297472, type=0\n",
      "BertEncoder: tensor[32]: type = f32, n_dims = 1, name = encoder.layer.1.intermediate.dense.bias, offset=113734656, type=0\n",
      "BertEncoder: tensor[33]: type = f32, n_dims = 2, name = encoder.layer.1.output.dense.weight, offset=113746944, type=0\n",
      "BertEncoder: tensor[34]: type = f32, n_dims = 1, name = encoder.layer.1.output.dense.bias, offset=123184128, type=0\n",
      "BertEncoder: tensor[35]: type = f32, n_dims = 1, name = encoder.layer.1.output.LayerNorm.weight, offset=123187200, type=0\n",
      "BertEncoder: tensor[36]: type = f32, n_dims = 1, name = encoder.layer.1.output.LayerNorm.bias, offset=123190272, type=0\n",
      "BertEncoder: tensor[37]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.query.weight, offset=123193344, type=0\n",
      "BertEncoder: tensor[38]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.query.bias, offset=125552640, type=0\n",
      "BertEncoder: tensor[39]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.key.weight, offset=125555712, type=0\n",
      "BertEncoder: tensor[40]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.key.bias, offset=127915008, type=0\n",
      "BertEncoder: tensor[41]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.value.weight, offset=127918080, type=0\n",
      "BertEncoder: tensor[42]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.value.bias, offset=130277376, type=0\n",
      "BertEncoder: tensor[43]: type = f32, n_dims = 2, name = encoder.layer.2.attention.output.dense.weight, offset=130280448, type=0\n",
      "BertEncoder: tensor[44]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.dense.bias, offset=132639744, type=0\n",
      "BertEncoder: tensor[45]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.LayerNorm.weight, offset=132642816, type=0\n",
      "BertEncoder: tensor[46]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.LayerNorm.bias, offset=132645888, type=0\n",
      "BertEncoder: tensor[47]: type = f32, n_dims = 2, name = encoder.layer.2.intermediate.dense.weight, offset=132648960, type=0\n",
      "BertEncoder: tensor[48]: type = f32, n_dims = 1, name = encoder.layer.2.intermediate.dense.bias, offset=142086144, type=0\n",
      "BertEncoder: tensor[49]: type = f32, n_dims = 2, name = encoder.layer.2.output.dense.weight, offset=142098432, type=0\n",
      "BertEncoder: tensor[50]: type = f32, n_dims = 1, name = encoder.layer.2.output.dense.bias, offset=151535616, type=0\n",
      "BertEncoder: tensor[51]: type = f32, n_dims = 1, name = encoder.layer.2.output.LayerNorm.weight, offset=151538688, type=0\n",
      "BertEncoder: tensor[52]: type = f32, n_dims = 1, name = encoder.layer.2.output.LayerNorm.bias, offset=151541760, type=0\n",
      "BertEncoder: tensor[53]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.query.weight, offset=151544832, type=0\n",
      "BertEncoder: tensor[54]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.query.bias, offset=153904128, type=0\n",
      "BertEncoder: tensor[55]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.key.weight, offset=153907200, type=0\n",
      "BertEncoder: tensor[56]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.key.bias, offset=156266496, type=0\n",
      "BertEncoder: tensor[57]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.value.weight, offset=156269568, type=0\n",
      "BertEncoder: tensor[58]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.value.bias, offset=158628864, type=0\n",
      "BertEncoder: tensor[59]: type = f32, n_dims = 2, name = encoder.layer.3.attention.output.dense.weight, offset=158631936, type=0\n",
      "BertEncoder: tensor[60]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.dense.bias, offset=160991232, type=0\n",
      "BertEncoder: tensor[61]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.LayerNorm.weight, offset=160994304, type=0\n",
      "BertEncoder: tensor[62]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.LayerNorm.bias, offset=160997376, type=0\n",
      "BertEncoder: tensor[63]: type = f32, n_dims = 2, name = encoder.layer.3.intermediate.dense.weight, offset=161000448, type=0\n",
      "BertEncoder: tensor[64]: type = f32, n_dims = 1, name = encoder.layer.3.intermediate.dense.bias, offset=170437632, type=0\n",
      "BertEncoder: tensor[65]: type = f32, n_dims = 2, name = encoder.layer.3.output.dense.weight, offset=170449920, type=0\n",
      "BertEncoder: tensor[66]: type = f32, n_dims = 1, name = encoder.layer.3.output.dense.bias, offset=179887104, type=0\n",
      "BertEncoder: tensor[67]: type = f32, n_dims = 1, name = encoder.layer.3.output.LayerNorm.weight, offset=179890176, type=0\n",
      "BertEncoder: tensor[68]: type = f32, n_dims = 1, name = encoder.layer.3.output.LayerNorm.bias, offset=179893248, type=0\n",
      "BertEncoder: tensor[69]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.query.weight, offset=179896320, type=0\n",
      "BertEncoder: tensor[70]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.query.bias, offset=182255616, type=0\n",
      "BertEncoder: tensor[71]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.key.weight, offset=182258688, type=0\n",
      "BertEncoder: tensor[72]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.key.bias, offset=184617984, type=0\n",
      "BertEncoder: tensor[73]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.value.weight, offset=184621056, type=0\n",
      "BertEncoder: tensor[74]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.value.bias, offset=186980352, type=0\n",
      "BertEncoder: tensor[75]: type = f32, n_dims = 2, name = encoder.layer.4.attention.output.dense.weight, offset=186983424, type=0\n",
      "BertEncoder: tensor[76]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.dense.bias, offset=189342720, type=0\n",
      "BertEncoder: tensor[77]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.LayerNorm.weight, offset=189345792, type=0\n",
      "BertEncoder: tensor[78]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.LayerNorm.bias, offset=189348864, type=0\n",
      "BertEncoder: tensor[79]: type = f32, n_dims = 2, name = encoder.layer.4.intermediate.dense.weight, offset=189351936, type=0\n",
      "BertEncoder: tensor[80]: type = f32, n_dims = 1, name = encoder.layer.4.intermediate.dense.bias, offset=198789120, type=0\n",
      "BertEncoder: tensor[81]: type = f32, n_dims = 2, name = encoder.layer.4.output.dense.weight, offset=198801408, type=0\n",
      "BertEncoder: tensor[82]: type = f32, n_dims = 1, name = encoder.layer.4.output.dense.bias, offset=208238592, type=0\n",
      "BertEncoder: tensor[83]: type = f32, n_dims = 1, name = encoder.layer.4.output.LayerNorm.weight, offset=208241664, type=0\n",
      "BertEncoder: tensor[84]: type = f32, n_dims = 1, name = encoder.layer.4.output.LayerNorm.bias, offset=208244736, type=0\n",
      "BertEncoder: tensor[85]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.query.weight, offset=208247808, type=0\n",
      "BertEncoder: tensor[86]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.query.bias, offset=210607104, type=0\n",
      "BertEncoder: tensor[87]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.key.weight, offset=210610176, type=0\n",
      "BertEncoder: tensor[88]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.key.bias, offset=212969472, type=0\n",
      "BertEncoder: tensor[89]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.value.weight, offset=212972544, type=0\n",
      "BertEncoder: tensor[90]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.value.bias, offset=215331840, type=0\n",
      "BertEncoder: tensor[91]: type = f32, n_dims = 2, name = encoder.layer.5.attention.output.dense.weight, offset=215334912, type=0\n",
      "BertEncoder: tensor[92]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.dense.bias, offset=217694208, type=0\n",
      "BertEncoder: tensor[93]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.LayerNorm.weight, offset=217697280, type=0\n",
      "BertEncoder: tensor[94]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.LayerNorm.bias, offset=217700352, type=0\n",
      "BertEncoder: tensor[95]: type = f32, n_dims = 2, name = encoder.layer.5.intermediate.dense.weight, offset=217703424, type=0\n",
      "BertEncoder: tensor[96]: type = f32, n_dims = 1, name = encoder.layer.5.intermediate.dense.bias, offset=227140608, type=0\n",
      "BertEncoder: tensor[97]: type = f32, n_dims = 2, name = encoder.layer.5.output.dense.weight, offset=227152896, type=0\n",
      "BertEncoder: tensor[98]: type = f32, n_dims = 1, name = encoder.layer.5.output.dense.bias, offset=236590080, type=0\n",
      "BertEncoder: tensor[99]: type = f32, n_dims = 1, name = encoder.layer.5.output.LayerNorm.weight, offset=236593152, type=0\n",
      "BertEncoder: tensor[100]: type = f32, n_dims = 1, name = encoder.layer.5.output.LayerNorm.bias, offset=236596224, type=0\n",
      "BertEncoder: tensor[101]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.query.weight, offset=236599296, type=0\n",
      "BertEncoder: tensor[102]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.query.bias, offset=238958592, type=0\n",
      "BertEncoder: tensor[103]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.key.weight, offset=238961664, type=0\n",
      "BertEncoder: tensor[104]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.key.bias, offset=241320960, type=0\n",
      "BertEncoder: tensor[105]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.value.weight, offset=241324032, type=0\n",
      "BertEncoder: tensor[106]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.value.bias, offset=243683328, type=0\n",
      "BertEncoder: tensor[107]: type = f32, n_dims = 2, name = encoder.layer.6.attention.output.dense.weight, offset=243686400, type=0\n",
      "BertEncoder: tensor[108]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.dense.bias, offset=246045696, type=0\n",
      "BertEncoder: tensor[109]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.LayerNorm.weight, offset=246048768, type=0\n",
      "BertEncoder: tensor[110]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.LayerNorm.bias, offset=246051840, type=0\n",
      "BertEncoder: tensor[111]: type = f32, n_dims = 2, name = encoder.layer.6.intermediate.dense.weight, offset=246054912, type=0\n",
      "BertEncoder: tensor[112]: type = f32, n_dims = 1, name = encoder.layer.6.intermediate.dense.bias, offset=255492096, type=0\n",
      "BertEncoder: tensor[113]: type = f32, n_dims = 2, name = encoder.layer.6.output.dense.weight, offset=255504384, type=0\n",
      "BertEncoder: tensor[114]: type = f32, n_dims = 1, name = encoder.layer.6.output.dense.bias, offset=264941568, type=0\n",
      "BertEncoder: tensor[115]: type = f32, n_dims = 1, name = encoder.layer.6.output.LayerNorm.weight, offset=264944640, type=0\n",
      "BertEncoder: tensor[116]: type = f32, n_dims = 1, name = encoder.layer.6.output.LayerNorm.bias, offset=264947712, type=0\n",
      "BertEncoder: tensor[117]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.query.weight, offset=264950784, type=0\n",
      "BertEncoder: tensor[118]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.query.bias, offset=267310080, type=0\n",
      "BertEncoder: tensor[119]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.key.weight, offset=267313152, type=0\n",
      "BertEncoder: tensor[120]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.key.bias, offset=269672448, type=0\n",
      "BertEncoder: tensor[121]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.value.weight, offset=269675520, type=0\n",
      "BertEncoder: tensor[122]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.value.bias, offset=272034816, type=0\n",
      "BertEncoder: tensor[123]: type = f32, n_dims = 2, name = encoder.layer.7.attention.output.dense.weight, offset=272037888, type=0\n",
      "BertEncoder: tensor[124]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.dense.bias, offset=274397184, type=0\n",
      "BertEncoder: tensor[125]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.LayerNorm.weight, offset=274400256, type=0\n",
      "BertEncoder: tensor[126]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.LayerNorm.bias, offset=274403328, type=0\n",
      "BertEncoder: tensor[127]: type = f32, n_dims = 2, name = encoder.layer.7.intermediate.dense.weight, offset=274406400, type=0\n",
      "BertEncoder: tensor[128]: type = f32, n_dims = 1, name = encoder.layer.7.intermediate.dense.bias, offset=283843584, type=0\n",
      "BertEncoder: tensor[129]: type = f32, n_dims = 2, name = encoder.layer.7.output.dense.weight, offset=283855872, type=0\n",
      "BertEncoder: tensor[130]: type = f32, n_dims = 1, name = encoder.layer.7.output.dense.bias, offset=293293056, type=0\n",
      "BertEncoder: tensor[131]: type = f32, n_dims = 1, name = encoder.layer.7.output.LayerNorm.weight, offset=293296128, type=0\n",
      "BertEncoder: tensor[132]: type = f32, n_dims = 1, name = encoder.layer.7.output.LayerNorm.bias, offset=293299200, type=0\n",
      "BertEncoder: tensor[133]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.query.weight, offset=293302272, type=0\n",
      "BertEncoder: tensor[134]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.query.bias, offset=295661568, type=0\n",
      "BertEncoder: tensor[135]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.key.weight, offset=295664640, type=0\n",
      "BertEncoder: tensor[136]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.key.bias, offset=298023936, type=0\n",
      "BertEncoder: tensor[137]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.value.weight, offset=298027008, type=0\n",
      "BertEncoder: tensor[138]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.value.bias, offset=300386304, type=0\n",
      "BertEncoder: tensor[139]: type = f32, n_dims = 2, name = encoder.layer.8.attention.output.dense.weight, offset=300389376, type=0\n",
      "BertEncoder: tensor[140]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.dense.bias, offset=302748672, type=0\n",
      "BertEncoder: tensor[141]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.LayerNorm.weight, offset=302751744, type=0\n",
      "BertEncoder: tensor[142]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.LayerNorm.bias, offset=302754816, type=0\n",
      "BertEncoder: tensor[143]: type = f32, n_dims = 2, name = encoder.layer.8.intermediate.dense.weight, offset=302757888, type=0\n",
      "BertEncoder: tensor[144]: type = f32, n_dims = 1, name = encoder.layer.8.intermediate.dense.bias, offset=312195072, type=0\n",
      "BertEncoder: tensor[145]: type = f32, n_dims = 2, name = encoder.layer.8.output.dense.weight, offset=312207360, type=0\n",
      "BertEncoder: tensor[146]: type = f32, n_dims = 1, name = encoder.layer.8.output.dense.bias, offset=321644544, type=0\n",
      "BertEncoder: tensor[147]: type = f32, n_dims = 1, name = encoder.layer.8.output.LayerNorm.weight, offset=321647616, type=0\n",
      "BertEncoder: tensor[148]: type = f32, n_dims = 1, name = encoder.layer.8.output.LayerNorm.bias, offset=321650688, type=0\n",
      "BertEncoder: tensor[149]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.query.weight, offset=321653760, type=0\n",
      "BertEncoder: tensor[150]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.query.bias, offset=324013056, type=0\n",
      "BertEncoder: tensor[151]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.key.weight, offset=324016128, type=0\n",
      "BertEncoder: tensor[152]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.key.bias, offset=326375424, type=0\n",
      "BertEncoder: tensor[153]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.value.weight, offset=326378496, type=0\n",
      "BertEncoder: tensor[154]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.value.bias, offset=328737792, type=0\n",
      "BertEncoder: tensor[155]: type = f32, n_dims = 2, name = encoder.layer.9.attention.output.dense.weight, offset=328740864, type=0\n",
      "BertEncoder: tensor[156]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.dense.bias, offset=331100160, type=0\n",
      "BertEncoder: tensor[157]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.LayerNorm.weight, offset=331103232, type=0\n",
      "BertEncoder: tensor[158]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.LayerNorm.bias, offset=331106304, type=0\n",
      "BertEncoder: tensor[159]: type = f32, n_dims = 2, name = encoder.layer.9.intermediate.dense.weight, offset=331109376, type=0\n",
      "BertEncoder: tensor[160]: type = f32, n_dims = 1, name = encoder.layer.9.intermediate.dense.bias, offset=340546560, type=0\n",
      "BertEncoder: tensor[161]: type = f32, n_dims = 2, name = encoder.layer.9.output.dense.weight, offset=340558848, type=0\n",
      "BertEncoder: tensor[162]: type = f32, n_dims = 1, name = encoder.layer.9.output.dense.bias, offset=349996032, type=0\n",
      "BertEncoder: tensor[163]: type = f32, n_dims = 1, name = encoder.layer.9.output.LayerNorm.weight, offset=349999104, type=0\n",
      "BertEncoder: tensor[164]: type = f32, n_dims = 1, name = encoder.layer.9.output.LayerNorm.bias, offset=350002176, type=0\n",
      "BertEncoder: tensor[165]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.query.weight, offset=350005248, type=0\n",
      "BertEncoder: tensor[166]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.query.bias, offset=352364544, type=0\n",
      "BertEncoder: tensor[167]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.key.weight, offset=352367616, type=0\n",
      "BertEncoder: tensor[168]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.key.bias, offset=354726912, type=0\n",
      "BertEncoder: tensor[169]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.value.weight, offset=354729984, type=0\n",
      "BertEncoder: tensor[170]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.value.bias, offset=357089280, type=0\n",
      "BertEncoder: tensor[171]: type = f32, n_dims = 2, name = encoder.layer.10.attention.output.dense.weight, offset=357092352, type=0\n",
      "BertEncoder: tensor[172]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.dense.bias, offset=359451648, type=0\n",
      "BertEncoder: tensor[173]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.LayerNorm.weight, offset=359454720, type=0\n",
      "BertEncoder: tensor[174]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.LayerNorm.bias, offset=359457792, type=0\n",
      "BertEncoder: tensor[175]: type = f32, n_dims = 2, name = encoder.layer.10.intermediate.dense.weight, offset=359460864, type=0\n",
      "BertEncoder: tensor[176]: type = f32, n_dims = 1, name = encoder.layer.10.intermediate.dense.bias, offset=368898048, type=0\n",
      "BertEncoder: tensor[177]: type = f32, n_dims = 2, name = encoder.layer.10.output.dense.weight, offset=368910336, type=0\n",
      "BertEncoder: tensor[178]: type = f32, n_dims = 1, name = encoder.layer.10.output.dense.bias, offset=378347520, type=0\n",
      "BertEncoder: tensor[179]: type = f32, n_dims = 1, name = encoder.layer.10.output.LayerNorm.weight, offset=378350592, type=0\n",
      "BertEncoder: tensor[180]: type = f32, n_dims = 1, name = encoder.layer.10.output.LayerNorm.bias, offset=378353664, type=0\n",
      "BertEncoder: tensor[181]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.query.weight, offset=378356736, type=0\n",
      "BertEncoder: tensor[182]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.query.bias, offset=380716032, type=0\n",
      "BertEncoder: tensor[183]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.key.weight, offset=380719104, type=0\n",
      "BertEncoder: tensor[184]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.key.bias, offset=383078400, type=0\n",
      "BertEncoder: tensor[185]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.value.weight, offset=383081472, type=0\n",
      "BertEncoder: tensor[186]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.value.bias, offset=385440768, type=0\n",
      "BertEncoder: tensor[187]: type = f32, n_dims = 2, name = encoder.layer.11.attention.output.dense.weight, offset=385443840, type=0\n",
      "BertEncoder: tensor[188]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.dense.bias, offset=387803136, type=0\n",
      "BertEncoder: tensor[189]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.LayerNorm.weight, offset=387806208, type=0\n",
      "BertEncoder: tensor[190]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.LayerNorm.bias, offset=387809280, type=0\n",
      "BertEncoder: tensor[191]: type = f32, n_dims = 2, name = encoder.layer.11.intermediate.dense.weight, offset=387812352, type=0\n",
      "BertEncoder: tensor[192]: type = f32, n_dims = 1, name = encoder.layer.11.intermediate.dense.bias, offset=397249536, type=0\n",
      "BertEncoder: tensor[193]: type = f32, n_dims = 2, name = encoder.layer.11.output.dense.weight, offset=397261824, type=0\n",
      "BertEncoder: tensor[194]: type = f32, n_dims = 1, name = encoder.layer.11.output.dense.bias, offset=406699008, type=0\n",
      "BertEncoder: tensor[195]: type = f32, n_dims = 1, name = encoder.layer.11.output.LayerNorm.weight, offset=406702080, type=0\n",
      "BertEncoder: tensor[196]: type = f32, n_dims = 1, name = encoder.layer.11.output.LayerNorm.bias, offset=406705152, type=0\n",
      "BertEncoder: tensor[197]: type = f32, n_dims = 2, name = pooler.dense.weight, offset=406708224, type=0\n",
      "BertEncoder: tensor[198]: type = f32, n_dims = 1, name = pooler.dense.bias, offset=409067520, type=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute buffer size: 0.47 MB\n",
      "===========testing: shibing624/text2vec-base-multilingual===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "BertEncoder: GGUF\n",
      "BertEncoder: model name:   shibing624/text2vec-base-multilingual\n",
      "BertEncoder: architecture:   BertModel\n",
      "BertEncoder: description:  gguf model for embeddings.cpp\n",
      "BertEncoder: GGUF version: 3\n",
      "BertEncoder: alignment:    32\n",
      "BertEncoder: n_tensors:    199\n",
      "BertEncoder: n_kv:         12\n",
      "BertEncoder: ftype:        f32\n",
      "\n",
      "BertEncoder: MODEL\n",
      "BertEncoder: n_vocab        = 250037\n",
      "BertEncoder: n_max_tokens   = 512\n",
      "BertEncoder: n_embd         = 384\n",
      "BertEncoder: n_intermediate = 1536\n",
      "BertEncoder: n_head         = 12\n",
      "BertEncoder: n_layer        = 12\n",
      "BertEncoder: layer_norm_eps = 1e-12\n",
      "\n",
      "BertEncoder: using CPU backend\n",
      "BertEncoder: tensor[0]: type = f32, n_dims = 2, name = embeddings.word_embeddings.weight, offset=0, type=0\n",
      "BertEncoder: tensor[1]: type = f32, n_dims = 2, name = embeddings.position_embeddings.weight, offset=384056832, type=0\n",
      "BertEncoder: tensor[2]: type = f32, n_dims = 2, name = embeddings.token_type_embeddings.weight, offset=384843264, type=0\n",
      "BertEncoder: tensor[3]: type = f32, n_dims = 1, name = embeddings.LayerNorm.weight, offset=384846336, type=0\n",
      "BertEncoder: tensor[4]: type = f32, n_dims = 1, name = embeddings.LayerNorm.bias, offset=384847872, type=0\n",
      "BertEncoder: tensor[5]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.query.weight, offset=384849408, type=0\n",
      "BertEncoder: tensor[6]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.query.bias, offset=385439232, type=0\n",
      "BertEncoder: tensor[7]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.key.weight, offset=385440768, type=0\n",
      "BertEncoder: tensor[8]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.key.bias, offset=386030592, type=0\n",
      "BertEncoder: tensor[9]: type = f32, n_dims = 2, name = encoder.layer.0.attention.self.value.weight, offset=386032128, type=0\n",
      "BertEncoder: tensor[10]: type = f32, n_dims = 1, name = encoder.layer.0.attention.self.value.bias, offset=386621952, type=0\n",
      "BertEncoder: tensor[11]: type = f32, n_dims = 2, name = encoder.layer.0.attention.output.dense.weight, offset=386623488, type=0\n",
      "BertEncoder: tensor[12]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.dense.bias, offset=387213312, type=0\n",
      "BertEncoder: tensor[13]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.LayerNorm.weight, offset=387214848, type=0\n",
      "BertEncoder: tensor[14]: type = f32, n_dims = 1, name = encoder.layer.0.attention.output.LayerNorm.bias, offset=387216384, type=0\n",
      "BertEncoder: tensor[15]: type = f32, n_dims = 2, name = encoder.layer.0.intermediate.dense.weight, offset=387217920, type=0\n",
      "BertEncoder: tensor[16]: type = f32, n_dims = 1, name = encoder.layer.0.intermediate.dense.bias, offset=389577216, type=0\n",
      "BertEncoder: tensor[17]: type = f32, n_dims = 2, name = encoder.layer.0.output.dense.weight, offset=389583360, type=0\n",
      "BertEncoder: tensor[18]: type = f32, n_dims = 1, name = encoder.layer.0.output.dense.bias, offset=391942656, type=0\n",
      "BertEncoder: tensor[19]: type = f32, n_dims = 1, name = encoder.layer.0.output.LayerNorm.weight, offset=391944192, type=0\n",
      "BertEncoder: tensor[20]: type = f32, n_dims = 1, name = encoder.layer.0.output.LayerNorm.bias, offset=391945728, type=0\n",
      "BertEncoder: tensor[21]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.query.weight, offset=391947264, type=0\n",
      "BertEncoder: tensor[22]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.query.bias, offset=392537088, type=0\n",
      "BertEncoder: tensor[23]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.key.weight, offset=392538624, type=0\n",
      "BertEncoder: tensor[24]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.key.bias, offset=393128448, type=0\n",
      "BertEncoder: tensor[25]: type = f32, n_dims = 2, name = encoder.layer.1.attention.self.value.weight, offset=393129984, type=0\n",
      "BertEncoder: tensor[26]: type = f32, n_dims = 1, name = encoder.layer.1.attention.self.value.bias, offset=393719808, type=0\n",
      "BertEncoder: tensor[27]: type = f32, n_dims = 2, name = encoder.layer.1.attention.output.dense.weight, offset=393721344, type=0\n",
      "BertEncoder: tensor[28]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.dense.bias, offset=394311168, type=0\n",
      "BertEncoder: tensor[29]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.LayerNorm.weight, offset=394312704, type=0\n",
      "BertEncoder: tensor[30]: type = f32, n_dims = 1, name = encoder.layer.1.attention.output.LayerNorm.bias, offset=394314240, type=0\n",
      "BertEncoder: tensor[31]: type = f32, n_dims = 2, name = encoder.layer.1.intermediate.dense.weight, offset=394315776, type=0\n",
      "BertEncoder: tensor[32]: type = f32, n_dims = 1, name = encoder.layer.1.intermediate.dense.bias, offset=396675072, type=0\n",
      "BertEncoder: tensor[33]: type = f32, n_dims = 2, name = encoder.layer.1.output.dense.weight, offset=396681216, type=0\n",
      "BertEncoder: tensor[34]: type = f32, n_dims = 1, name = encoder.layer.1.output.dense.bias, offset=399040512, type=0\n",
      "BertEncoder: tensor[35]: type = f32, n_dims = 1, name = encoder.layer.1.output.LayerNorm.weight, offset=399042048, type=0\n",
      "BertEncoder: tensor[36]: type = f32, n_dims = 1, name = encoder.layer.1.output.LayerNorm.bias, offset=399043584, type=0\n",
      "BertEncoder: tensor[37]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.query.weight, offset=399045120, type=0\n",
      "BertEncoder: tensor[38]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.query.bias, offset=399634944, type=0\n",
      "BertEncoder: tensor[39]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.key.weight, offset=399636480, type=0\n",
      "BertEncoder: tensor[40]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.key.bias, offset=400226304, type=0\n",
      "BertEncoder: tensor[41]: type = f32, n_dims = 2, name = encoder.layer.2.attention.self.value.weight, offset=400227840, type=0\n",
      "BertEncoder: tensor[42]: type = f32, n_dims = 1, name = encoder.layer.2.attention.self.value.bias, offset=400817664, type=0\n",
      "BertEncoder: tensor[43]: type = f32, n_dims = 2, name = encoder.layer.2.attention.output.dense.weight, offset=400819200, type=0\n",
      "BertEncoder: tensor[44]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.dense.bias, offset=401409024, type=0\n",
      "BertEncoder: tensor[45]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.LayerNorm.weight, offset=401410560, type=0\n",
      "BertEncoder: tensor[46]: type = f32, n_dims = 1, name = encoder.layer.2.attention.output.LayerNorm.bias, offset=401412096, type=0\n",
      "BertEncoder: tensor[47]: type = f32, n_dims = 2, name = encoder.layer.2.intermediate.dense.weight, offset=401413632, type=0\n",
      "BertEncoder: tensor[48]: type = f32, n_dims = 1, name = encoder.layer.2.intermediate.dense.bias, offset=403772928, type=0\n",
      "BertEncoder: tensor[49]: type = f32, n_dims = 2, name = encoder.layer.2.output.dense.weight, offset=403779072, type=0\n",
      "BertEncoder: tensor[50]: type = f32, n_dims = 1, name = encoder.layer.2.output.dense.bias, offset=406138368, type=0\n",
      "BertEncoder: tensor[51]: type = f32, n_dims = 1, name = encoder.layer.2.output.LayerNorm.weight, offset=406139904, type=0\n",
      "BertEncoder: tensor[52]: type = f32, n_dims = 1, name = encoder.layer.2.output.LayerNorm.bias, offset=406141440, type=0\n",
      "BertEncoder: tensor[53]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.query.weight, offset=406142976, type=0\n",
      "BertEncoder: tensor[54]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.query.bias, offset=406732800, type=0\n",
      "BertEncoder: tensor[55]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.key.weight, offset=406734336, type=0\n",
      "BertEncoder: tensor[56]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.key.bias, offset=407324160, type=0\n",
      "BertEncoder: tensor[57]: type = f32, n_dims = 2, name = encoder.layer.3.attention.self.value.weight, offset=407325696, type=0\n",
      "BertEncoder: tensor[58]: type = f32, n_dims = 1, name = encoder.layer.3.attention.self.value.bias, offset=407915520, type=0\n",
      "BertEncoder: tensor[59]: type = f32, n_dims = 2, name = encoder.layer.3.attention.output.dense.weight, offset=407917056, type=0\n",
      "BertEncoder: tensor[60]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.dense.bias, offset=408506880, type=0\n",
      "BertEncoder: tensor[61]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.LayerNorm.weight, offset=408508416, type=0\n",
      "BertEncoder: tensor[62]: type = f32, n_dims = 1, name = encoder.layer.3.attention.output.LayerNorm.bias, offset=408509952, type=0\n",
      "BertEncoder: tensor[63]: type = f32, n_dims = 2, name = encoder.layer.3.intermediate.dense.weight, offset=408511488, type=0\n",
      "BertEncoder: tensor[64]: type = f32, n_dims = 1, name = encoder.layer.3.intermediate.dense.bias, offset=410870784, type=0\n",
      "BertEncoder: tensor[65]: type = f32, n_dims = 2, name = encoder.layer.3.output.dense.weight, offset=410876928, type=0\n",
      "BertEncoder: tensor[66]: type = f32, n_dims = 1, name = encoder.layer.3.output.dense.bias, offset=413236224, type=0\n",
      "BertEncoder: tensor[67]: type = f32, n_dims = 1, name = encoder.layer.3.output.LayerNorm.weight, offset=413237760, type=0\n",
      "BertEncoder: tensor[68]: type = f32, n_dims = 1, name = encoder.layer.3.output.LayerNorm.bias, offset=413239296, type=0\n",
      "BertEncoder: tensor[69]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.query.weight, offset=413240832, type=0\n",
      "BertEncoder: tensor[70]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.query.bias, offset=413830656, type=0\n",
      "BertEncoder: tensor[71]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.key.weight, offset=413832192, type=0\n",
      "BertEncoder: tensor[72]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.key.bias, offset=414422016, type=0\n",
      "BertEncoder: tensor[73]: type = f32, n_dims = 2, name = encoder.layer.4.attention.self.value.weight, offset=414423552, type=0\n",
      "BertEncoder: tensor[74]: type = f32, n_dims = 1, name = encoder.layer.4.attention.self.value.bias, offset=415013376, type=0\n",
      "BertEncoder: tensor[75]: type = f32, n_dims = 2, name = encoder.layer.4.attention.output.dense.weight, offset=415014912, type=0\n",
      "BertEncoder: tensor[76]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.dense.bias, offset=415604736, type=0\n",
      "BertEncoder: tensor[77]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.LayerNorm.weight, offset=415606272, type=0\n",
      "BertEncoder: tensor[78]: type = f32, n_dims = 1, name = encoder.layer.4.attention.output.LayerNorm.bias, offset=415607808, type=0\n",
      "BertEncoder: tensor[79]: type = f32, n_dims = 2, name = encoder.layer.4.intermediate.dense.weight, offset=415609344, type=0\n",
      "BertEncoder: tensor[80]: type = f32, n_dims = 1, name = encoder.layer.4.intermediate.dense.bias, offset=417968640, type=0\n",
      "BertEncoder: tensor[81]: type = f32, n_dims = 2, name = encoder.layer.4.output.dense.weight, offset=417974784, type=0\n",
      "BertEncoder: tensor[82]: type = f32, n_dims = 1, name = encoder.layer.4.output.dense.bias, offset=420334080, type=0\n",
      "BertEncoder: tensor[83]: type = f32, n_dims = 1, name = encoder.layer.4.output.LayerNorm.weight, offset=420335616, type=0\n",
      "BertEncoder: tensor[84]: type = f32, n_dims = 1, name = encoder.layer.4.output.LayerNorm.bias, offset=420337152, type=0\n",
      "BertEncoder: tensor[85]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.query.weight, offset=420338688, type=0\n",
      "BertEncoder: tensor[86]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.query.bias, offset=420928512, type=0\n",
      "BertEncoder: tensor[87]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.key.weight, offset=420930048, type=0\n",
      "BertEncoder: tensor[88]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.key.bias, offset=421519872, type=0\n",
      "BertEncoder: tensor[89]: type = f32, n_dims = 2, name = encoder.layer.5.attention.self.value.weight, offset=421521408, type=0\n",
      "BertEncoder: tensor[90]: type = f32, n_dims = 1, name = encoder.layer.5.attention.self.value.bias, offset=422111232, type=0\n",
      "BertEncoder: tensor[91]: type = f32, n_dims = 2, name = encoder.layer.5.attention.output.dense.weight, offset=422112768, type=0\n",
      "BertEncoder: tensor[92]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.dense.bias, offset=422702592, type=0\n",
      "BertEncoder: tensor[93]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.LayerNorm.weight, offset=422704128, type=0\n",
      "BertEncoder: tensor[94]: type = f32, n_dims = 1, name = encoder.layer.5.attention.output.LayerNorm.bias, offset=422705664, type=0\n",
      "BertEncoder: tensor[95]: type = f32, n_dims = 2, name = encoder.layer.5.intermediate.dense.weight, offset=422707200, type=0\n",
      "BertEncoder: tensor[96]: type = f32, n_dims = 1, name = encoder.layer.5.intermediate.dense.bias, offset=425066496, type=0\n",
      "BertEncoder: tensor[97]: type = f32, n_dims = 2, name = encoder.layer.5.output.dense.weight, offset=425072640, type=0\n",
      "BertEncoder: tensor[98]: type = f32, n_dims = 1, name = encoder.layer.5.output.dense.bias, offset=427431936, type=0\n",
      "BertEncoder: tensor[99]: type = f32, n_dims = 1, name = encoder.layer.5.output.LayerNorm.weight, offset=427433472, type=0\n",
      "BertEncoder: tensor[100]: type = f32, n_dims = 1, name = encoder.layer.5.output.LayerNorm.bias, offset=427435008, type=0\n",
      "BertEncoder: tensor[101]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.query.weight, offset=427436544, type=0\n",
      "BertEncoder: tensor[102]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.query.bias, offset=428026368, type=0\n",
      "BertEncoder: tensor[103]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.key.weight, offset=428027904, type=0\n",
      "BertEncoder: tensor[104]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.key.bias, offset=428617728, type=0\n",
      "BertEncoder: tensor[105]: type = f32, n_dims = 2, name = encoder.layer.6.attention.self.value.weight, offset=428619264, type=0\n",
      "BertEncoder: tensor[106]: type = f32, n_dims = 1, name = encoder.layer.6.attention.self.value.bias, offset=429209088, type=0\n",
      "BertEncoder: tensor[107]: type = f32, n_dims = 2, name = encoder.layer.6.attention.output.dense.weight, offset=429210624, type=0\n",
      "BertEncoder: tensor[108]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.dense.bias, offset=429800448, type=0\n",
      "BertEncoder: tensor[109]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.LayerNorm.weight, offset=429801984, type=0\n",
      "BertEncoder: tensor[110]: type = f32, n_dims = 1, name = encoder.layer.6.attention.output.LayerNorm.bias, offset=429803520, type=0\n",
      "BertEncoder: tensor[111]: type = f32, n_dims = 2, name = encoder.layer.6.intermediate.dense.weight, offset=429805056, type=0\n",
      "BertEncoder: tensor[112]: type = f32, n_dims = 1, name = encoder.layer.6.intermediate.dense.bias, offset=432164352, type=0\n",
      "BertEncoder: tensor[113]: type = f32, n_dims = 2, name = encoder.layer.6.output.dense.weight, offset=432170496, type=0\n",
      "BertEncoder: tensor[114]: type = f32, n_dims = 1, name = encoder.layer.6.output.dense.bias, offset=434529792, type=0\n",
      "BertEncoder: tensor[115]: type = f32, n_dims = 1, name = encoder.layer.6.output.LayerNorm.weight, offset=434531328, type=0\n",
      "BertEncoder: tensor[116]: type = f32, n_dims = 1, name = encoder.layer.6.output.LayerNorm.bias, offset=434532864, type=0\n",
      "BertEncoder: tensor[117]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.query.weight, offset=434534400, type=0\n",
      "BertEncoder: tensor[118]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.query.bias, offset=435124224, type=0\n",
      "BertEncoder: tensor[119]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.key.weight, offset=435125760, type=0\n",
      "BertEncoder: tensor[120]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.key.bias, offset=435715584, type=0\n",
      "BertEncoder: tensor[121]: type = f32, n_dims = 2, name = encoder.layer.7.attention.self.value.weight, offset=435717120, type=0\n",
      "BertEncoder: tensor[122]: type = f32, n_dims = 1, name = encoder.layer.7.attention.self.value.bias, offset=436306944, type=0\n",
      "BertEncoder: tensor[123]: type = f32, n_dims = 2, name = encoder.layer.7.attention.output.dense.weight, offset=436308480, type=0\n",
      "BertEncoder: tensor[124]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.dense.bias, offset=436898304, type=0\n",
      "BertEncoder: tensor[125]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.LayerNorm.weight, offset=436899840, type=0\n",
      "BertEncoder: tensor[126]: type = f32, n_dims = 1, name = encoder.layer.7.attention.output.LayerNorm.bias, offset=436901376, type=0\n",
      "BertEncoder: tensor[127]: type = f32, n_dims = 2, name = encoder.layer.7.intermediate.dense.weight, offset=436902912, type=0\n",
      "BertEncoder: tensor[128]: type = f32, n_dims = 1, name = encoder.layer.7.intermediate.dense.bias, offset=439262208, type=0\n",
      "BertEncoder: tensor[129]: type = f32, n_dims = 2, name = encoder.layer.7.output.dense.weight, offset=439268352, type=0\n",
      "BertEncoder: tensor[130]: type = f32, n_dims = 1, name = encoder.layer.7.output.dense.bias, offset=441627648, type=0\n",
      "BertEncoder: tensor[131]: type = f32, n_dims = 1, name = encoder.layer.7.output.LayerNorm.weight, offset=441629184, type=0\n",
      "BertEncoder: tensor[132]: type = f32, n_dims = 1, name = encoder.layer.7.output.LayerNorm.bias, offset=441630720, type=0\n",
      "BertEncoder: tensor[133]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.query.weight, offset=441632256, type=0\n",
      "BertEncoder: tensor[134]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.query.bias, offset=442222080, type=0\n",
      "BertEncoder: tensor[135]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.key.weight, offset=442223616, type=0\n",
      "BertEncoder: tensor[136]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.key.bias, offset=442813440, type=0\n",
      "BertEncoder: tensor[137]: type = f32, n_dims = 2, name = encoder.layer.8.attention.self.value.weight, offset=442814976, type=0\n",
      "BertEncoder: tensor[138]: type = f32, n_dims = 1, name = encoder.layer.8.attention.self.value.bias, offset=443404800, type=0\n",
      "BertEncoder: tensor[139]: type = f32, n_dims = 2, name = encoder.layer.8.attention.output.dense.weight, offset=443406336, type=0\n",
      "BertEncoder: tensor[140]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.dense.bias, offset=443996160, type=0\n",
      "BertEncoder: tensor[141]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.LayerNorm.weight, offset=443997696, type=0\n",
      "BertEncoder: tensor[142]: type = f32, n_dims = 1, name = encoder.layer.8.attention.output.LayerNorm.bias, offset=443999232, type=0\n",
      "BertEncoder: tensor[143]: type = f32, n_dims = 2, name = encoder.layer.8.intermediate.dense.weight, offset=444000768, type=0\n",
      "BertEncoder: tensor[144]: type = f32, n_dims = 1, name = encoder.layer.8.intermediate.dense.bias, offset=446360064, type=0\n",
      "BertEncoder: tensor[145]: type = f32, n_dims = 2, name = encoder.layer.8.output.dense.weight, offset=446366208, type=0\n",
      "BertEncoder: tensor[146]: type = f32, n_dims = 1, name = encoder.layer.8.output.dense.bias, offset=448725504, type=0\n",
      "BertEncoder: tensor[147]: type = f32, n_dims = 1, name = encoder.layer.8.output.LayerNorm.weight, offset=448727040, type=0\n",
      "BertEncoder: tensor[148]: type = f32, n_dims = 1, name = encoder.layer.8.output.LayerNorm.bias, offset=448728576, type=0\n",
      "BertEncoder: tensor[149]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.query.weight, offset=448730112, type=0\n",
      "BertEncoder: tensor[150]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.query.bias, offset=449319936, type=0\n",
      "BertEncoder: tensor[151]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.key.weight, offset=449321472, type=0\n",
      "BertEncoder: tensor[152]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.key.bias, offset=449911296, type=0\n",
      "BertEncoder: tensor[153]: type = f32, n_dims = 2, name = encoder.layer.9.attention.self.value.weight, offset=449912832, type=0\n",
      "BertEncoder: tensor[154]: type = f32, n_dims = 1, name = encoder.layer.9.attention.self.value.bias, offset=450502656, type=0\n",
      "BertEncoder: tensor[155]: type = f32, n_dims = 2, name = encoder.layer.9.attention.output.dense.weight, offset=450504192, type=0\n",
      "BertEncoder: tensor[156]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.dense.bias, offset=451094016, type=0\n",
      "BertEncoder: tensor[157]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.LayerNorm.weight, offset=451095552, type=0\n",
      "BertEncoder: tensor[158]: type = f32, n_dims = 1, name = encoder.layer.9.attention.output.LayerNorm.bias, offset=451097088, type=0\n",
      "BertEncoder: tensor[159]: type = f32, n_dims = 2, name = encoder.layer.9.intermediate.dense.weight, offset=451098624, type=0\n",
      "BertEncoder: tensor[160]: type = f32, n_dims = 1, name = encoder.layer.9.intermediate.dense.bias, offset=453457920, type=0\n",
      "BertEncoder: tensor[161]: type = f32, n_dims = 2, name = encoder.layer.9.output.dense.weight, offset=453464064, type=0\n",
      "BertEncoder: tensor[162]: type = f32, n_dims = 1, name = encoder.layer.9.output.dense.bias, offset=455823360, type=0\n",
      "BertEncoder: tensor[163]: type = f32, n_dims = 1, name = encoder.layer.9.output.LayerNorm.weight, offset=455824896, type=0\n",
      "BertEncoder: tensor[164]: type = f32, n_dims = 1, name = encoder.layer.9.output.LayerNorm.bias, offset=455826432, type=0\n",
      "BertEncoder: tensor[165]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.query.weight, offset=455827968, type=0\n",
      "BertEncoder: tensor[166]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.query.bias, offset=456417792, type=0\n",
      "BertEncoder: tensor[167]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.key.weight, offset=456419328, type=0\n",
      "BertEncoder: tensor[168]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.key.bias, offset=457009152, type=0\n",
      "BertEncoder: tensor[169]: type = f32, n_dims = 2, name = encoder.layer.10.attention.self.value.weight, offset=457010688, type=0\n",
      "BertEncoder: tensor[170]: type = f32, n_dims = 1, name = encoder.layer.10.attention.self.value.bias, offset=457600512, type=0\n",
      "BertEncoder: tensor[171]: type = f32, n_dims = 2, name = encoder.layer.10.attention.output.dense.weight, offset=457602048, type=0\n",
      "BertEncoder: tensor[172]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.dense.bias, offset=458191872, type=0\n",
      "BertEncoder: tensor[173]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.LayerNorm.weight, offset=458193408, type=0\n",
      "BertEncoder: tensor[174]: type = f32, n_dims = 1, name = encoder.layer.10.attention.output.LayerNorm.bias, offset=458194944, type=0\n",
      "BertEncoder: tensor[175]: type = f32, n_dims = 2, name = encoder.layer.10.intermediate.dense.weight, offset=458196480, type=0\n",
      "BertEncoder: tensor[176]: type = f32, n_dims = 1, name = encoder.layer.10.intermediate.dense.bias, offset=460555776, type=0\n",
      "BertEncoder: tensor[177]: type = f32, n_dims = 2, name = encoder.layer.10.output.dense.weight, offset=460561920, type=0\n",
      "BertEncoder: tensor[178]: type = f32, n_dims = 1, name = encoder.layer.10.output.dense.bias, offset=462921216, type=0\n",
      "BertEncoder: tensor[179]: type = f32, n_dims = 1, name = encoder.layer.10.output.LayerNorm.weight, offset=462922752, type=0\n",
      "BertEncoder: tensor[180]: type = f32, n_dims = 1, name = encoder.layer.10.output.LayerNorm.bias, offset=462924288, type=0\n",
      "BertEncoder: tensor[181]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.query.weight, offset=462925824, type=0\n",
      "BertEncoder: tensor[182]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.query.bias, offset=463515648, type=0\n",
      "BertEncoder: tensor[183]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.key.weight, offset=463517184, type=0\n",
      "BertEncoder: tensor[184]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.key.bias, offset=464107008, type=0\n",
      "BertEncoder: tensor[185]: type = f32, n_dims = 2, name = encoder.layer.11.attention.self.value.weight, offset=464108544, type=0\n",
      "BertEncoder: tensor[186]: type = f32, n_dims = 1, name = encoder.layer.11.attention.self.value.bias, offset=464698368, type=0\n",
      "BertEncoder: tensor[187]: type = f32, n_dims = 2, name = encoder.layer.11.attention.output.dense.weight, offset=464699904, type=0\n",
      "BertEncoder: tensor[188]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.dense.bias, offset=465289728, type=0\n",
      "BertEncoder: tensor[189]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.LayerNorm.weight, offset=465291264, type=0\n",
      "BertEncoder: tensor[190]: type = f32, n_dims = 1, name = encoder.layer.11.attention.output.LayerNorm.bias, offset=465292800, type=0\n",
      "BertEncoder: tensor[191]: type = f32, n_dims = 2, name = encoder.layer.11.intermediate.dense.weight, offset=465294336, type=0\n",
      "BertEncoder: tensor[192]: type = f32, n_dims = 1, name = encoder.layer.11.intermediate.dense.bias, offset=467653632, type=0\n",
      "BertEncoder: tensor[193]: type = f32, n_dims = 2, name = encoder.layer.11.output.dense.weight, offset=467659776, type=0\n",
      "BertEncoder: tensor[194]: type = f32, n_dims = 1, name = encoder.layer.11.output.dense.bias, offset=470019072, type=0\n",
      "BertEncoder: tensor[195]: type = f32, n_dims = 1, name = encoder.layer.11.output.LayerNorm.weight, offset=470020608, type=0\n",
      "BertEncoder: tensor[196]: type = f32, n_dims = 1, name = encoder.layer.11.output.LayerNorm.bias, offset=470022144, type=0\n",
      "BertEncoder: tensor[197]: type = f32, n_dims = 2, name = pooler.dense.weight, offset=470023680, type=0\n",
      "BertEncoder: tensor[198]: type = f32, n_dims = 1, name = pooler.dense.bias, offset=470613504, type=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute buffer size: 0.19 MB\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(jsons)):\n",
    "    print(f\"===========testing: {repos[i]}===========\")\n",
    "    res_py, res_cpp, res_sp = test_embedding_alignment(jsons[i], ggufs[i], repos[i], pooling_methods[i])\n",
    "    results.append((res_py, res_cpp, res_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       MSE (transformers)  \\\n",
      "BAAI/bge-m3                                  7.856230e-09   \n",
      "BAAI/bge-base-zh-v1.5                        8.836764e-09   \n",
      "shibing624/text2vec-base-multilingual        8.778699e-10   \n",
      "\n",
      "                                       MSE (sentence_transformers)  \n",
      "BAAI/bge-m3                                           7.851480e-09  \n",
      "BAAI/bge-base-zh-v1.5                                 8.833642e-09  \n",
      "shibing624/text2vec-base-multilingual                 8.776497e-10  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9kAAAJOCAYAAACjoMSlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACG4klEQVR4nOzdeXgNd///8dch+yZCiCUS+06tLWktRSO1a+1uS0rVXkVRW1C01FJUKZW4W2vtN6VUq/Z9rX0PLaX2WIJkfn/45XwdSchhIsLzcV25LmfmMzPvOTkz8Trzmc9YDMMwBAAAAAAAnlmalC4AAAAAAICXBSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAgCQKCwuTxWJJ6TJeOLwvLz+LxaKwsLCULgMAUgVCNgC8ACIiImSxWGSxWLR+/fp48w3DkL+/vywWi2rWrGkzLyoqSgMHDlSRIkXk7u6uDBky6LXXXlPXrl31999/W9vFBaHEfs6fP//EOmNiYhQeHq5KlSrJx8dHzs7OCgwMVOvWrbV9+/ZnfyOABMycOVNjx461a5nU9Fl9+Pi3WCxycHBQtmzZ1KpVK/31118pXV6CNm7cqLCwMF29ejWlSwGAF45DShcAAPg/Li4umjlzpt58802b6X/88YfOnj0rZ2dnm+n37t1ThQoVdOjQIbVs2VKdO3dWVFSU9u/fr5kzZ6pevXrKmjWrzTLffvutPDw84m3b29v7sbXdvn1b9evX14oVK1ShQgV99tln8vHx0alTpzR37lxNnz5dkZGRyp49+9PtfCrQr18/9e7dO6XLeOEk9/syc+ZM/fnnn/r444+T1D61flYHDx6snDlz6s6dO9q8ebMiIiK0fv16/fnnn3JxcUnp8mxs3LhRgwYNUqtWrZ547gCAVw0hGwBeIO+++65++uknjRs3Tg4O/3eKnjlzpkqVKqV///3Xpv2iRYu0a9cuzZgxQ02bNrWZd+fOHd29ezfeNt5//31lzJjR7tp69uypFStWaMyYMfHCzsCBAzVmzBi715la3Lx5U+7u7nJwcLD5veCBF+19edbPaqVKlRQYGKiIiAi7thsYGKhWrVo9dbfqkJAQlS5dWpLUpk0bZcyYUV9++aWWLFmihg0bPtU6AQDPH93FAeAF0qRJE126dEmrVq2yTrt7967mzZsXL0RL0vHjxyVJQUFB8ea5uLjIy8vLlLrOnj2ryZMnq1q1agleTUybNq169Ohhc2Vw165dCgkJkZeXlzw8PFSlShVt3rzZZrm4brLr169Xly5d5OvrK29vb7Vr1053797V1atX1aJFC6VPn17p06fXp59+KsMwrMufOnVKFotFX331lcaMGaOAgAC5urqqYsWK+vPPP222tXfvXrVq1Uq5cuWSi4uL/Pz8FBoaqkuXLtm0i+tWf+DAATVt2lTp06e39ixI6N7jVatW6c0335S3t7c8PDyUP39+ffbZZzZtLly4oA8++ECZM2eWi4uLihcvrunTp9u0eXhfvvvuO+XOnVvOzs4qU6aMtm3b9oTfkHT58mX16NFDRYsWlYeHh7y8vBQSEqI9e/bEa3v69GnVrl1b7u7uypQpk7p166ZffvlFFotFa9assbZbt26dGjRooBw5csjZ2Vn+/v7q1q2bbt++neB79jCLxaJOnTpp0aJFKlKkiJydnVW4cGGtWLHCpt2NGzf08ccfKzAwUM7OzsqUKZOqVaumnTt3SnoQeJctW6bTp09bu1MHBgYm+j48zWf1RfXWW29J+r/jPM6hQ4f0/vvvy8fHRy4uLipdurSWLFli0+bevXsaNGiQ8ubNKxcXF2XIkEFvvvmmzbmlUqVKqlSpUrzttmrV6rHvcVhYmHr27ClJypkzp/X3curUKUlJOyYA4GX24nztDABQYGCgypUrp1mzZikkJESStHz5cl27dk2NGzfWuHHjbNoHBARIkv773/+qX79+SRp86vLly/GmOTg4PLbL5/Lly3X//n395z//SdJ+7N+/X2+99Za8vLz06aefytHRUZMnT1alSpX0xx9/6PXXX7dp37lzZ/n5+WnQoEHavHmzvvvuO3l7e2vjxo3KkSOHhg0bpp9//lkjR45UkSJF1KJFC5vl//vf/+rGjRvq2LGj7ty5o6+//lpvv/229u3bp8yZM0t68B//EydOqHXr1vLz89P+/fv13Xffaf/+/dq8eXO8965BgwbKmzevhg0bZhPsH93PmjVrqlixYho8eLCcnZ117Ngxbdiwwdrm9u3bqlSpko4dO6ZOnTopZ86c+umnn9SqVStdvXpVXbt2tVnnzJkzdePGDbVr104Wi0UjRoxQ/fr1deLECTk6Oib6np84cUKLFi1SgwYNlDNnTv3zzz+aPHmyKlasqAMHDlhvG7h586befvttnTt3Tl27dpWfn59mzpyp33//Pd46f/rpJ926dUvt27dXhgwZtHXrVo0fP15nz57VTz/9lGgtcdavX68FCxaoQ4cO8vT01Lhx4/Tee+8pMjJSGTJkkCR99NFHmjdvnjp16qRChQrp0qVLWr9+vQ4ePKiSJUuqb9++unbtms6ePWu9Ap3Q7Q5x7P2svsjiQmv69Omt0/bv36+goCBly5ZNvXv3lru7u+bOnau6detq/vz5qlevnqQHQXj48OFq06aNypYtq+vXr2v79u3auXOnqlWr9kx11a9fX0eOHNGsWbM0ZswYa88YX1/fJB0TAPDSMwAAKS48PNyQZGzbts2YMGGC4enpady6dcswDMNo0KCBUblyZcMwDCMgIMCoUaOGdblbt24Z+fPnNyQZAQEBRqtWrYzvv//e+Oeff+JtY+DAgYakBH/y58//2Pq6detmSDJ27dqVpP2pW7eu4eTkZBw/ftw67e+//zY8PT2NChUqxNvv4OBgIzY21jq9XLlyhsViMT766CPrtPv37xvZs2c3KlasaJ128uRJQ5Lh6upqnD171jp9y5YthiSjW7duNu/Vo2bNmmVIMtauXWudFvc+NWnSJF77uHlxxowZY0gyLl68mOh7MXbsWEOS8eOPP1qn3b171yhXrpzh4eFhXL9+3WZfMmTIYFy+fNnadvHixYYk43//+1+i2zAMw7hz544RExNjM+3kyZOGs7OzMXjwYOu0UaNGGZKMRYsWWafdvn3bKFCggCHJ+P33363TE3rPhg8fblgsFuP06dPWaY++L4ZhGJIMJycn49ixY9Zpe/bsMSQZ48ePt05Lly6d0bFjx8fuW40aNYyAgIDHtolj72c1IRUrVjRatmxp93IBAQHGwIED7V4u7jj49ddfjYsXLxpnzpwx5s2bZ/j6+hrOzs7GmTNnrG2rVKliFC1a1Lhz5451WmxsrFG+fHkjb9681mnFixe3OVckpGLFijbHU5yWLVvGe78l2ezbyJEjDUnGyZMnbdol5ZgAgJcd3cUB4AXTsGFD3b59W0uXLtWNGze0dOnSBLuKS5Krq6u2bNli7boZERGhDz74QFmyZFHnzp0VHR0db5n58+dr1apVNj/h4eGPren69euSJE9PzyfWHxMTo5UrV6pu3brKlSuXdXqWLFnUtGlTrV+/3rq+OB988IHNleTXX39dhmHogw8+sE5LmzatSpcurRMnTsTbZt26dZUtWzbr67Jly+r111/Xzz//bJ3m6upq/fedO3f077//6o033pAka9fkh3300UdP3Ne4q/+LFy9WbGxsgm1+/vln+fn5qUmTJtZpjo6O6tKli6KiovTHH3/YtG/UqJHNlcu4LsMJ7ffDnJ2dlSbNgz/rMTExunTpkrWr7sP7t2LFCmXLlk21a9e2TnNxcVHbtm3jrfPh9+zmzZv6999/Vb58eRmGoV27dj22HkmqWrWqcufObX1drFgxeXl52eyLt7e3tmzZYjMS/rOw57MqPehW/e+//9r83Lt3T9HR0fGmP/w7Tmz+rVu34k1PqqpVq8rX11f+/v56//335e7uriVLlli7tl++fFm//fabGjZsqBs3bljXf+nSJQUHB+vo0aPW0ci9vb21f/9+HT16NMnbN0NSjgkAeNm9NCF77dq1qlWrlrJmzSqLxaJFixYl6/bi7iGLu/+vfPnySbpnDgCexNfXV1WrVtXMmTO1YMECxcTE6P3330+0fbp06TRixAidOnVKp06d0vfff6/8+fNrwoQJGjJkSLz2FSpUUNWqVW1+ypUr99ia4u7tvnHjxhPrv3jxom7duqX8+fPHm1ewYEHFxsbqzJkzNtNz5MgRb58kyd/fP970K1euxFtv3rx5403Lly+ftbut9CCgdO3aVZkzZ5arq6t8fX2VM2dOSdK1a9fiLR8373EaNWqkoKAgtWnTRpkzZ1bjxo01d+5cm3Bx+vRp5c2b1xqA4xQsWNA6/2GPvhdxgTuh/X5YbGysxowZo7x588rZ2VkZM2aUr6+v9u7da7N/p0+fVu7cueN1j8+TJ0+8dUZGRqpVq1by8fGRh4eHfH19VbFiRUkJv2ePenRf4vbn4X0ZMWKE/vzzT/n7+6ts2bIKCwt74hcKj2PPZ1WSNmzYIF9fX5ufjRs3avbs2fGmR0ZGWpebNWtWvPlnzpzRyJEj401Pqm+++UarVq3SvHnz9O677+rff/+1eaLAsWPHZBiG+vfvH28bAwcOlPTg/n/pwUjlV69eVb58+VS0aFH17NlTe/fuTXItTyspxwQAvOxemnuyb968qeLFiys0NFT169dP9u21adNGf/75p3744QdlzZpVP/74o6pWraoDBw7YXE0BgKfRtGlTtW3bVufPn1dISEiSH5ETEBCg0NBQ1atXT7ly5dKMGTP0+eefP3M9BQoUkCTt27dPr7322jOv71Fp06ZN8nQjkfujn6Rhw4bauHGjevbsqddee00eHh6KjY1V9erVEwwAD1/FTYyrq6vWrl2r33//XcuWLdOKFSs0Z84cvf3221q5cmWi+/U4iS3zpP0eNmyY+vfvr9DQUA0ZMkQ+Pj5KkyaNPv7446cKODExMapWrZouX76sXr16qUCBAnJ3d9dff/2lVq1aJWmdSdmXhg0b6q233tLChQu1cuVKjRw5Ul9++aUWLFhgHZfAHvZ+VosXL24zGJgkde/eXX5+ftYeInH8/Pys/w4ODo63XPPmzfXOO+/EGzMgqcqWLWsdXbxu3bp688031bRpUx0+fNj6eZWkHj16KDg4OMF1xH1ZUqFCBR0/flyLFy/WypUrNXXqVI0ZM0aTJk1SmzZtJD0YnC6hz1VMTMxT1S8lzzEBAKnNSxOyQ0JCHvvHODo6Wn379tWsWbN09epVFSlSRF9++WWCo2o+ye3btzV//nwtXrxYFSpUkPRggJH//e9/+vbbb035Dy2AV1u9evXUrl07bd68WXPmzLF7+fTp0yt37tzxRth+WiEhIUqbNq1+/PHHJw4o5evrKzc3Nx0+fDjevEOHDilNmjTxrlA/q4S6xB45csQ6QvKVK1e0evVqDRo0SAMGDHjscvZKkyaNqlSpoipVqmj06NEaNmyY+vbtq99//11Vq1ZVQECA9u7dq9jYWJur2YcOHZL0f4PXPat58+apcuXK+v77722mX7161eaRbQEBATpw4IAMw7C5mn3s2DGb5fbt26cjR45o+vTpNqHx0WBphixZsqhDhw7q0KGDLly4oJIlS2ro0KHWv+tJGdAvjj2fVenBsVK1atV407JkyRJv+qM1Z8mSxWaai4uLcuXK9djlkipt2rQaPny4KleurAkTJqh3797W2y8cHR2TtA0fHx+1bt1arVu3VlRUlCpUqKCwsDBryE6fPn2CvQYe7V2RkMf9Tp50TADAy+6l6S7+JJ06ddKmTZs0e/Zs7d27Vw0aNFD16tWf6j9Y9+/fV0xMjFxcXGymu7q6av369WaVDOAV5uHhoW+//VZhYWGqVatWou327NmT4D2fp0+f1oEDBxLssv00/P391bZtW61cuVLjx4+PNz82NlajRo3S2bNnlTZtWr3zzjtavHixTXftf/75RzNnztSbb75p2qPF4ixatMh6L6okbd26VVu2bLGGtLirZ49etRs7duwzbTehkdrjrp7G3Q//7rvv6vz58zZflty/f1/jx4+Xh4eHtfv1s0qbNm28/fvpp59s3hfpwRXYv/76y+aRT3fu3NGUKVPirU+yfc8Mw9DXX39tSr3Sgyumj3Y7z5Qpk7JmzWoznoC7u3uSuqdL9n1WX3SVKlVS2bJlNXbsWN25c0eZMmVSpUqVNHnyZJ07dy5e+4sXL1r//eij6Tw8PJQnTx6b9zV37tw6dOiQzXJ79uxJ0kjg7u7ukh58ifOwpBwTAPCye2muZD9OZGSkwsPDFRkZaX2ESY8ePbRixQqFh4dr2LBhdq3P09NT5cqV05AhQ1SwYEFlzpxZs2bN0qZNmxK8pw0AnkbLli2f2GbVqlUaOHCgateurTfeeEMeHh46ceKEpk2bpujoaIWFhcVbZt68eQk+AqlatWrWx10lZNSoUTp+/Li6dOmiBQsWqGbNmkqfPr0iIyP1008/6dChQ2rcuLEk6fPPP7c+K7dDhw5ycHDQ5MmTFR0drREjRiT9TUiiPHny6M0331T79u0VHR2tsWPHKkOGDPr0008lPbhPt0KFChoxYoTu3bunbNmyaeXKlTp58uQzbXfw4MFau3atatSooYCAAF24cEETJ05U9uzZrc/W/vDDDzV58mS1atVKO3bsUGBgoObNm6cNGzZo7NixSR6g60lq1qypwYMHq3Xr1ipfvrz27dunGTNm2Aw+J0nt2rXThAkT1KRJE3Xt2lVZsmTRjBkzrF8cx12hLFCggHLnzq0ePXror7/+kpeXl+bPn//Ee8PtcePGDWXPnl3vv/++ihcvLg8PD/3666/atm2bRo0aZW1XqlQpzZkzR5988onKlCkjDw+Px375ZM9n9UXXs2dPNWjQQBEREfroo4/0zTff6M0331TRokXVtm1b5cqVS//88482bdqks2fPWp+LXqhQIVWqVEmlSpWSj4+Ptm/fbn1UWpzQ0FCNHj1awcHB+uCDD3ThwgVNmjRJhQsXjjc44aNKlSolSerbt68aN24sR0dH1apVK0nHBAC89FJmUPPkJclYuHCh9fXSpUsNSYa7u7vNj4ODg9GwYUPDMAzj4MGDiT7aJu6nV69e1nUeO3bMqFChgiHJSJs2rVGmTBmjWbNmRoECBZ737gJ4CTz8CK/HefQRXidOnDAGDBhgvPHGG0amTJkMBwcHw9fX16hRo4bx22+/2Sz7uEd46ZFHNyXm/v37xtSpU4233nrLSJcuneHo6GgEBAQYrVu3jvfIpJ07dxrBwcGGh4eH4ebmZlSuXNnYuHFjkvY7rtZHHwPUsmVLw93d3fo67rFXI0eONEaNGmX4+/sbzs7OxltvvWXs2bPHZtmzZ88a9erVM7y9vY106dIZDRo0MP7+++94jyZKbNsPz4uzevVqo06dOkbWrFkNJycnI2vWrEaTJk2MI0eO2Cz3zz//GK1btzYyZsxoODk5GUWLFjXCw8Nt2jy8L496tMaE3Llzx+jevbuRJUsWw9XV1QgKCjI2bdqU4GOaTpw4YdSoUcNwdXU1fH19je7duxvz5883JBmbN2+2tjtw4IBRtWpVw8PDw8iYMaPRtm1b62O4Hq4/sUd4JfRoroCAAOvjsaKjo42ePXsaxYsXNzw9PQ13d3ejePHixsSJE22WiYqKMpo2bWp4e3tbH1f3JPZ8Vh+VUo/wSuj4j4mJMXLnzm3kzp3buH//vmEYhnH8+HGjRYsWhp+fn+Ho6Ghky5bNqFmzpjFv3jzrcp9//rlRtmxZw9vb23B1dTUKFChgDB061Lh7967N+n/88UcjV65chpOTk/Haa68Zv/zyS5Ie4WUYhjFkyBAjW7ZsRpo0aayP80rqMQEALzOLYTzlCDIvMIvFooULF6pu3bqSpDlz5qhZs2bav39/vAE3PDw85Ofnp7t37z5xNNMMGTLEGyX05s2bun79urJkyaJGjRopKipKy5YtM3V/AAAJO3XqlHLmzKmRI0eqR48eKV1OqjZ27Fh169ZNZ8+eZQBPAACewSvRXbxEiRKKiYnRhQsXrM8bfZSTk5N1RFJ7uLu7y93dXVeuXNEvv/ySLN0gAQAw0+3bt+M9N3zy5MnKmzcvARsAgGf00oTsqKgom5FRT548qd27d8vHx0f58uVTs2bN1KJFC40aNUolSpTQxYsXtXr1ahUrVkw1atSwe3u//PKLDMNQ/vz5dezYMfXs2VMFChRQ69atzdwtAABMV79+feXIkUOvvfaarl27ph9//FGHDh3SjBkzUro0AABSvZcmZG/fvl2VK1e2vv7kk08kPRg4KCIiQuHh4fr888/VvXt3/fXXX8qYMaPeeOMN1axZ86m2d+3aNfXp00dnz56Vj4+P3nvvPQ0dOlSOjo6m7A8AAMklODhYU6dO1YwZMxQTE6NChQpp9uzZatSoUUqXBgBAqvdS3pMNAAAAAEBKeGWekw0AAAAAQHIjZAMAAAAAYJJUfU92bGys/v77b3l6espisaR0OQAAAACAl5RhGLpx44ayZs2qNGkSv16dqkP233//LX9//5QuAwAAAADwijhz5oyyZ8+e6PxUHbI9PT0lPdhJLy+vFK4GAAAAAPCyun79uvz9/a05NDGpOmTHdRH38vIiZAMAAAAAkt2TblVm4DMAAAAAAExCyAYAAAAAwCSEbAAAAAAATJKq78kGAAAAkltMTIzu3buX0mUASGaOjo5KmzbtM6+HkA0AAAAkwDAMnT9/XlevXk3pUgA8J97e3vLz83vi4GaPQ8gGAAAAEhAXsDNlyiQ3N7dn+k83gBebYRi6deuWLly4IEnKkiXLU6+LkA0AAAA8IiYmxhqwM2TIkNLlAHgOXF1dJUkXLlxQpkyZnrrrOAOfAQAAAI+Iuwfbzc0thSsB8DzFHfPPMg4DIRsAAABIBF3EgVeLGcc8IRsAAAAAAJMQsgEAAAC8kAIDAzV27Fjra4vFokWLFqVYPWY6deqULBaLdu/ebfq6H33f8HwRsgEAAADYrVWrVrJYLLJYLHJyclKePHk0ePBg3b9/P9m2ee7cOYWEhCTb+uPE7dfmzZttpkdHRytDhgyyWCxas2ZNktfXqlUr1a1b19wi8cIiZAMAAAB4KtWrV9e5c+d09OhRde/eXWFhYRo5cmSybc/Pz0/Ozs7Jtv6H+fv7Kzw83GbawoUL5eHh8Vy2j9SLkA0AAADgqTg7O8vPz08BAQFq3769qlatqiVLlkiSrly5ohYtWih9+vRyc3NTSEiIjh49arP8/PnzVbhwYTk7OyswMFCjRo167PYe7i4e1916wYIFqly5stzc3FS8eHFt2rTJZpkpU6bI399fbm5uqlevnkaPHi1vb+8n7lvLli01e/Zs3b592zpt2rRpatmyZby2Z86cUcOGDeXt7S0fHx/VqVNHp06dkiSFhYVp+vTpWrx4sfUK+cNXwU+cOPHY+p/0Hl24cEG1atWSq6urcubMqRkzZtjMNwxDYWFhypEjh5ydnZU1a1Z16dLlifuPp0fIBgAAAGAKV1dX3b17V9KDLtLbt2/XkiVLtGnTJhmGoXfffdf6aKQdO3aoYcOGaty4sfbt26ewsDD1799fERERdm2zb9++6tGjh3bv3q18+fKpSZMm1i7rGzZs0EcffaSuXbtq9+7dqlatmoYOHZqk9ZYqVUqBgYGaP3++JCkyMlJr167Vf/7zH5t29+7dU3BwsDw9PbVu3Tpt2LBBHh4eql69uu7evasePXqoYcOG1qv+586dU/ny5ZNUf1Leo1atWunMmTP6/fffNW/ePE2cOFEXLlywzp8/f77GjBmjyZMn6+jRo1q0aJGKFi1q13sM+zikdAEAAAAAUjfDMLR69Wr98ssv6ty5s44ePaolS5Zow4YN1kA5Y8YM+fv7a9GiRWrQoIFGjx6tKlWqqH///pKkfPny6cCBAxo5cqRatWqV5G336NFDNWrUkCQNGjRIhQsX1rFjx1SgQAGNHz9eISEh6tGjh3UbGzdu1NKlS5O07tDQUE2bNk3NmzdXRESE3n33Xfn6+tq0mTNnjmJjYzV16lTr45/Cw8Pl7e2tNWvW6J133pGrq6uio6Pl5+dnV/1Peo+OHDmi5cuXa+vWrSpTpowk6fvvv1fBggWt64+MjJSfn5+qVq0qR0dH5ciRQ2XLlk3y+wv7cSUbAAAAwFNZunSpPDw85OLiopCQEDVq1EhhYWE6ePCgHBwc9Prrr1vbZsiQQfnz59fBgwclSQcPHlRQUJDN+oKCgnT06FHFxMQkuYZixYpZ/50lSxZJsl7JPXz4cLxAaU/AbN68uTZt2qQTJ04oIiJCoaGh8drs2bNHx44dk6enpzw8POTh4SEfHx/duXNHx48ff6b6n/Qexb3PpUqVss4vUKCATXf4Bg0a6Pbt28qVK5fatm2rhQsXJuvgdOBKNgAAAICnVLlyZX377bdycnJS1qxZ5eDw/OOFo6Oj9d9xV5JjY2NNWXeGDBlUs2ZNffDBB7pz545CQkJ048YNmzZRUVEqVapUvHuhJcW76p2Q5KxfejCA2+HDh/Xrr79q1apV6tChg0aOHKk//vjDZtswD1eyAQAAADwVd3d35cmTRzly5LAJ2AULFtT9+/e1ZcsW67RLly7p8OHDKlSokLXNhg0bbNa3YcMG5cuXT2nTpjWlvvz582vbtm020x59/SShoaFas2aNWrRokWBdJUuW1NGjR5UpUyblyZPH5iddunSSJCcnJ7uuzsd50ntUoEAB3b9/Xzt27LDOP3z4sK5evWqzjKurq2rVqqVx48ZpzZo12rRpk/bt22d3PUgaQjYAAAAAU+XNm1d16tRR27ZttX79eu3Zs0fNmzdXtmzZVKdOHUlS9+7dtXr1ag0ZMkRHjhzR9OnTNWHCBOv902bo3Lmzfv75Z40ePVpHjx7V5MmTtXz5cusV46SoXr26Ll68qMGDByc4v1mzZsqYMaPq1KmjdevW6eTJk1qzZo26dOmis2fPSpICAwO1d+9eHT58WP/++6918LcnedJ7lD9/flWvXl3t2rXTli1btGPHDrVp00aurq7WdUREROj777/Xn3/+qRMnTujHH3+Uq6urAgICkvwewD6EbAAAAACmCw8PV6lSpVSzZk2VK1dOhmHo559/tnZRLlmypObOnavZs2erSJEiGjBggAYPHmzXoGdPEhQUpEmTJmn06NEqXry4VqxYoW7dusnFxSXJ67BYLMqYMaOcnJwSnO/m5qa1a9cqR44cql+/vgoWLGjtXu7l5SVJatu2rfLnz6/SpUvL19c33tXpxCTlPQoPD1fWrFlVsWJF1a9fXx9++KEyZcpkne/t7a0pU6YoKChIxYoV06+//qr//e9/ypAhQ5LfA9jHYhiGkdJFPK3r168rXbp0unbtmvUDDAB49QT2XpbSJaQ6p76okdIlAC+0O3fu6OTJk8qZM6ddgQwvvrZt2+rQoUNat25dSpeCF9Djjv2k5k8GPgMA4FUUli6lK0h9wq6ldAUAnsJXX32latWqyd3dXcuXL9f06dM1ceLElC4LLzFCNgAAAICX1tatWzVixAjduHFDuXLl0rhx49SmTZuULgsvMUI2AAAAgJfW3LlzU7oEvGIY+AwAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAABAsjh8+LD8/Px048aNlC4lUWFhYcqcObMsFosWLVqU0uWYonHjxho1alRKl/HK4jnZAAAAgB0Cey97rts79UUNu9q3atVK06dPV7t27TRp0iSbeR07dtTEiRPVsmVLRURESJIuXryoAQMGaNmyZfrnn3+UPn16FS9eXAMGDFBQUJAkKTAwUKdPn463reHDh6t3796J1tKnTx917txZnp6ekqSIiAh9/PHHunr1ql37lFwOHjyoQYMGaeHChXrjjTeUPn36lC7JFP369VOFChXUpk0bpUuXLqXLeeVwJRsAAAB4yfj7+2v27Nm6ffu2ddqdO3c0c+ZM5ciRw6bte++9p127dmn69Ok6cuSIlixZokqVKunSpUs27QYPHqxz587Z/HTu3DnRGiIjI7V06VK1atXK7vrv3r1r9zJP4/jx45KkOnXqyM/PT87Ozk+1nnv37plZ1mMl5b0pUqSIcufOrR9//PE5VIRHEbIBAACAl0zJkiXl7++vBQsWWKctWLBAOXLkUIkSJazTrl69qnXr1unLL79U5cqVFRAQoLJly6pPnz6qXbu2zTo9PT3l5+dn8+Pu7p5oDXPnzlXx4sWVLVs2SdKaNWvUunVrXbt2TRaLRRaLRWFhYZIeXCkfMmSIWrRoIS8vL3344YeSpF69eilfvnxyc3NTrly51L9/f5tAGxYWptdee00//PCDAgMDlS5dOjVu3Nime/q8efNUtGhRubq6KkOGDKpatapu3rypsLAw1apVS5KUJk0aWSwWSVJsbKwGDx6s7Nmzy9nZWa+99ppWrFhhXd+pU6dksVg0Z84cVaxYUS4uLpoxY4ZatWqlunXratiwYcqcObO8vb01ePBg3b9/Xz179pSPj4+yZ8+u8PBwm/fpzJkzatiwoby9veXj46M6dero1KlT1vlx6x06dKiyZs2q/PnzS5ImTpyovHnzysXFRZkzZ9b7779vs95atWpp9uzZif5+kHwI2QAAAMBLKDQ01CbQTZs2Ta1bt7Zp4+HhIQ8PDy1atEjR0dGmbn/dunUqXbq09XX58uU1duxYeXl5Wa+E9+jRwzr/q6++UvHixbVr1y71799f0oNgHxERoQMHDujrr7/WlClTNGbMGJvtHD9+XIsWLdLSpUu1dOlS/fHHH/riiy8kSefOnVOTJk0UGhqqgwcPas2aNapfv74Mw1CPHj2s709cPZL09ddfa9SoUfrqq6+0d+9eBQcHq3bt2jp69KjNdnv37q2uXbvq4MGDCg4OliT99ttv+vvvv7V27VqNHj1aAwcOVM2aNZU+fXpt2bJFH330kdq1a6ezZ89KenAFPDg4WJ6enlq3bp02bNggDw8PVa9e3eaK9erVq3X48GGtWrVKS5cu1fbt29WlSxcNHjxYhw8f1ooVK1ShQgWb+sqWLautW7ea/nvFkxGyAQAAgJdQ8+bNtX79ep0+fVqnT5/Whg0b1Lx5c5s2Dg4OioiI0PTp0+Xt7a2goCB99tln2rt3b7z19erVyxrK437WrVuX6PZPnz6trFmzWl87OTkpXbp0slgs1ivhHh4e1vlvv/22unfvrty5cyt37tySHtxbXL58eQUGBqpWrVrq0aOH5s6da7Od2NhYRUREqEiRInrrrbf0n//8R6tXr5b0IDzfv39f9evXV2BgoIoWLaoOHTpY6/f29pYkaz3Sg7Dfq1cvNW7cWPnz59eXX36p1157TWPHjrXZ7scff6z69esrZ86cypIliyTJx8dH48aNU/78+RUaGqr8+fPr1q1b+uyzz5Q3b1716dNHTk5OWr9+vSRpzpw5io2N1dSpU1W0aFEVLFhQ4eHhioyM1Jo1a6zbcnd319SpU1W4cGEVLlxYkZGRcnd3V82aNRUQEKASJUqoS5cuNvVlzZpVd+/e1fnz5xP9HSF5MPAZAAAA8BLy9fVVjRo1FBERIcMwVKNGDWXMmDFeu/fee081atTQunXrtHnzZi1fvlwjRozQ1KlTbe6n7tmzZ7z7q+O6gifk9u3bcnFxSXK9D1/1jjNnzhyNGzdOx48fV1RUlO7fvy8vLy+bNoGBgdaB1SQpS5YsunDhgiSpePHiqlKliooWLarg4GC98847ev/99xMd4Oz69ev6+++/rQO+xQkKCtKePXueWG/hwoWVJs3/XcfMnDmzihQpYn2dNm1aZciQwVrfnj17dOzYMZv6pQf3z8fdLy5JRYsWlZOTk/V1tWrVFBAQoFy5cql69eqqXr266tWrJzc3N2sbV1dXSdKtW7cS3FckH65kAwAAAC+p0NBQ65Xq0NDQRNu5uLioWrVq6t+/vzZu3KhWrVpp4MCBNm0yZsyoPHny2PzEBbmEZMyYUVeuXElyrY/e371p0yY1a9ZM7777rpYuXapdu3apb9++8Qb+cnR0tHltsVgUGxsr6UGoXbVqlZYvX65ChQpp/Pjxyp8/v06ePJnkupJab2K1PK6+qKgolSpVSrt377b5OXLkiJo2bZrotjw9PbVz507NmjVLWbJk0YABA1S8eHGbUdsvX74s6cGXLXi+CNkAAADASyru3t64e3+TqlChQrp58+YzbbtEiRI6cOCAzTQnJyfFxMQkafmNGzcqICBAffv2VenSpZU3b94EHyP2JBaLRUFBQRo0aJB27dolJycnLVy4MMG2Xl5eypo1qzZs2GAzfcOGDSpUqJDd236SkiVL6ujRo8qUKVO8LzCe9OgtBwcHVa1aVSNGjNDevXt16tQp/fbbb9b5f/75p7Jnz55g7wUkL7qLAwAAAC+ptGnT6uDBg9Z/P+rSpUtq0KCBQkNDVaxYMXl6emr79u0aMWKE6tSpY9P2xo0b8e7vdXNzi9d9O05wcLDatGmjmJgY67YDAwMVFRWl1atXq3jx4nJzc7Pp4vywvHnzKjIyUrNnz1aZMmW0bNmyRMNxYrZs2aLVq1frnXfeUaZMmbRlyxZdvHhRBQsWTHSZnj17auDAgcqdO7dee+01hYeHa/fu3ZoxY4Zd206KZs2aaeTIkapTp451RPPTp09rwYIF+vTTT5U9e/YEl1u6dKlOnDihChUqKH369Pr5558VGxtrHXlcejDw3DvvvGN6zXgyrmQDAAAALzEvL69Eg7CHh4def/11jRkzRhUqVFCRIkXUv39/tW3bVhMmTLBpO2DAAGXJksXm59NPP010uyEhIXJwcNCvv/5qnVa+fHl99NFHatSokXx9fTVixIhEl69du7a6deumTp066bXXXtPGjRuto47bs+9r167Vu+++q3z58qlfv34aNWqUQkJCEl2mS5cu+uSTT9S9e3cVLVpUK1as0JIlS5Q3b167tp0Ubm5uWrt2rXLkyKH69eurYMGC+uCDD3Tnzp1Ef2eS5O3trQULFujtt99WwYIFNWnSJM2aNUuFCxeW9OCe7kWLFqlt27am14wnsxiGYaR0EU/r+vXrSpcuna5du/bYDyEA4OUW2HtZSpeQ6pxyafrkRrAVdi2lK8BzdOfOHZ08eVI5c+a0a/Au2Prmm2+0ZMkS/fLLLyldyivl22+/1cKFC7Vy5cqULiXVedyxn9T8SXdxAAAAAMmiXbt2unr1qm7cuBFvBG0kH0dHR40fPz6ly3hlEbIBAAAAJAsHBwf17ds3pct45bRp0yalS3ilcU82AAAAAAAmIWQDAAAAAGASQjYAAAAAACYhZAMAAAAAYBJCNgAAAAAAJiFkAwAAAABgEkI2AAAAAAAmIWQDAAAASBaHDx+Wn5+fbty4kdKlwE6LFi1Snjx5lDZtWn388ccpXY4pJk2apFq1aiX7dhySfQsAAADAyyQs3XPe3jW7mrdq1UrTp09Xu3btNGnSJJt5HTt21MSJE9WyZUtFRERIki5evKgBAwZo2bJl+ueff5Q+fXoVL15cAwYMUFBQkCQpMDBQp0+fjret4cOHq3fv3onW0qdPH3Xu3Fmenp527cOzsFgsWrhwoerWrfvctvmsTp06pZw5c2rXrl167bXXUrocSVK7du3UunVrdenS5bn+/pJTaGiohgwZonXr1umtt95Ktu0QsgEAAICXjL+/v2bPnq0xY8bI1dVVknTnzh3NnDlTOXLksGn73nvv6e7du5o+fbpy5cqlf/75R6tXr9alS5ds2g0ePFht27a1mfa48BUZGamlS5dq/PjxJu0V7t69Kycnp2TfTlRUlC5cuKDg4GBlzZr1qdfzvOqVpJiYGFksFqVJk3hnbScnJzVt2lTjxo1L1pBNd3EAAADgJVOyZEn5+/trwYIF1mkLFixQjhw5VKJECeu0q1evat26dfryyy9VuXJlBQQEqGzZsurTp49q165ts05PT0/5+fnZ/Li7uydaw9y5c1W8eHFly5bNOu306dOqVauW0qdPL3d3dxUuXFg///yzdf6ff/6pkJAQeXh4KHPmzPrPf/6jf//91zq/UqVK6tKliz799FP5+PjIz89PYWFh1vmBgYGSpHr16slisVhfS9LixYtVsmRJubi4KFeuXBo0aJDu379vnW+xWDR16lTVq1dPbm5uyps3r5YsWWKzT/v371fNmjXl5eUlT09PvfXWWzp+/Lh1/tSpU1WwYEG5uLioQIECmjhxYqLvz8Ny5swpSSpRooQsFosqVaok6UGvhLp162ro0KHKmjWr8ufPL0n64YcfVLp0aevvpGnTprpw4YJ1fWvWrJHFYtHq1atVunRpubm5qXz58jp8+LC1zZ49e1S5cmV5enrKy8tLpUqV0vbt27VmzRrrlydvv/22LBaL1qxZI0maP3++ChcuLGdnZwUGBmrUqFE2+xEYGKghQ4aoRYsW8vLy0ocffqiIiAh5e3tr6dKlyp8/v9zc3PT+++/r1q1bmj59ugIDA5U+fXp16dJFMTEx1nVFR0erR48eypYtm9zd3fX6669b65BkXe+SJUtUqFAhOTs7KzIyUmvWrFHZsmXl7u4ub29vBQUF2fTCqFWrlpYsWaLbt28n6XfzNAjZAAAAwEsoNDRU4eHh1tfTpk1T69atbdp4eHjIw8NDixYtUnR0tKnbX7dunUqXLm0zrWPHjoqOjtbatWu1b98+ffnll/Lw8JD0IPC//fbbKlGihLZv364VK1bon3/+UcOGDW3WMX36dLm7u2vLli0aMWKEBg8erFWrVkmStm3bJkkKDw/XuXPnrK/XrVunFi1aqGvXrjpw4IAmT56siIgIDR061GbdgwYNUsOGDbV37169++67atasmS5fvixJ+uuvv1ShQgU5Ozvrt99+044dOxQaGmoN6jNmzNCAAQM0dOhQHTx4UMOGDVP//v01ffr0J75XW7dulST9+uuvOnfunM2XI6tXr9bhw4e1atUqLV26VJJ07949DRkyRHv27NGiRYt06tQptWrVKt56+/btq1GjRmn79u1ycHBQaGiodV6zZs2UPXt2bdu2TTt27FDv3r3l6OhoE8bnz5+vc+fOqXz58tqxY4caNmyoxo0ba9++fQoLC1P//v2ttx3E+eqrr1S8eHHt2rVL/fv3lyTdunVL48aN0+zZs7VixQqtWbNG9erV088//6yff/5ZP/zwgyZPnqx58+ZZ19OpUydt2rRJs2fP1t69e9WgQQNVr15dR48etba5deuWvvzyS02dOlX79++Xj4+P6tatq4oVK2rv3r3atGmTPvzwQ1ksFusypUuX1v3797Vly5Yn/l6eFt3FAQAAgJdQ8+bN1adPH+tVvA0bNmj27Nk2VwMdHBwUERGhtm3batKkSSpZsqQqVqyoxo0bq1ixYjbr69Wrl/r162czbfny5Yl2uz19+nS8kB0ZGan33ntPRYsWlSTlypXLOm/ChAkqUaKEhg0bZp02bdo0+fv768iRI8qXL58kqVixYho4cKAkKW/evJowYYJWr16tatWqydfXV5Lk7e0tPz8/63oGDRqk3r17q2XLltbtDhkyRJ9++ql1XdKDK8dNmjSRJA0bNkzjxo3T1q1bVb16dX3zzTdKly6dZs+eLUdHR0my1iRJAwcO1KhRo1S/fn1JD65OxwX6uO0mJq7uDBky2NQtSe7u7po6dapNt+uHw3KuXLk0btw4lSlTRlFRUdYvLSRp6NChqlixoiSpd+/eqlGjhu7cuSMXFxdFRkaqZ8+eKlCggPW9jJMpUyZJsvYWkKTRo0erSpUq1uCcL18+HThwQCNHjrQJ+G+//ba6d+9ufb1u3Trdu3dP3377rXLnzi1Jev/99/XDDz/on3/+kYeHhwoVKqTKlSvr999/V6NGjRQZGanw8HBFRkZau6v36NFDK1asUHh4uPUzcu/ePU2cOFHFixeXJF2+fFnXrl1TzZo1rdsqWLCgzfvp5uamdOnSJTjGgFkI2QAAAMBLyNfXVzVq1FBERIQMw1CNGjWUMWPGeO3ee+891ahRQ+vWrdPmzZu1fPlyjRgxQlOnTrUJTz179ox3tfThruCPun37tlxcXGymdenSRe3bt9fKlStVtWpVvffee9Ywv2fPHv3+++82ITHO8ePHbUL2w7JkyWLTVTohe/bs0YYNG2yuXMfExOjOnTu6deuW3Nzc4q3b3d1dXl5e1nXv3r1bb731ljVgP+zmzZs6fvy4PvjgA5v71u/fv6906Z5toLyiRYvGu695x44dCgsL0549e3TlyhXFxsZKevAlRqFChaztHt6fLFmySJIuXLigHDly6JNPPlGbNm30ww8/qGrVqmrQoIE1mCbk4MGDqlOnjs20oKAgjR07VjExMUqbNq0kxftiRXoQbB9ed+bMmRUYGGjzu86cObP1vd63b59iYmJsvsSQHnQhz5Ahg/W1k5OTzT76+PioVatWCg4OVrVq1VS1alU1bNjQuu9xXF1ddevWrUT39VkRsgEAAICXVGhoqDp16iRJ+uabbxJt5+LiomrVqqlatWrq37+/2rRpo4EDB9qE6owZMypPnjxJ3nbGjBl15coVm2lt2rRRcHCwli1bppUrV2r48OEaNWqUOnfurKioKNWqVUtffvllvHU9HJIeDbkWi8UaMhMTFRWlQYMGWa8yP+zhLwIet+64AeQSW78kTZkyRa+//rrNvLjw+bQeve/95s2bCg4OVnBwsGbMmCFfX19FRkYqODhYd+/etWn78P7EdZmO25+wsDA1bdpUy5Yt0/LlyzVw4EDNnj1b9erVM7XeR+uIq+Vx73VUVJTSpk2rHTt2xHv/Hg7mrq6uNl3BpQe3CnTp0kUrVqzQnDlz1K9fP61atUpvvPGGtc3ly5etvQeSAyEbAAAAeElVr15dd+/elcViUXBwcJKXK1SokBYtWvRM2y5RooQOHDgQb7q/v78++ugjffTRR+rTp4+mTJmizp07q2TJkpo/f74CAwPl4PD0McXR0dFmAC3pwUBwhw8ftutLgkcVK1ZM06dP17179+IFxMyZMytr1qw6ceKEmjVrZve6465UP1p3Qg4dOqRLly7piy++kL+/vyRp+/btdm9TetDlO1++fOrWrZuaNGmi8PDwREN2wYIFtWHDBptpGzZsUL58+Z75i4RHlShRQjExMbpw4cJTjQJeokQJlShRQn369FG5cuU0c+ZMa8g+fvy47ty5YzMAoNkY+AwAAAB4SaVNm1YHDx7UgQMHEgxCly5d0ttvv60ff/xRe/fu1cmTJ/XTTz9pxIgR8boG37hxQ+fPn7f5uX79eqLbDg4O1qZNm2yC48cff6xffvlFJ0+e1M6dO/X7779b75nt2LGjLl++rCZNmmjbtm06fvy4fvnlF7Vu3TpJ4TNOYGCgVq9erfPnz1uvpA8YMED//e9/NWjQIO3fv18HDx7U7Nmz491j/jidOnXS9evX1bhxY23fvl1Hjx7VDz/8YB0kbNCgQRo+fLjGjRunI0eOaN++fQoPD9fo0aOfuO5MmTLJ1dXVOtjbtWuJPxs9R44ccnJy0vjx43XixAktWbJEQ4YMSfJ+SA+68nfq1Elr1qzR6dOntWHDBm3bti3e/csP6969u1avXq0hQ4boyJEjmj59uiZMmKAePXrYte2kyJcvn5o1a6YWLVpowYIFOnnypLZu3arhw4dr2bJliS538uRJ9enTR5s2bdLp06e1cuVKHT161Ga/1q1bp1y5cj22a/yzStGQHRMTo/79+ytnzpxydXVV7ty5NWTIEBmGkZJlAQAAAC8NLy8veXl5JTjPw8NDr7/+usaMGaMKFSqoSJEi6t+/v9q2basJEybYtB0wYICyZMli8/Ppp58mut2QkBA5ODjo119/tU6LiYlRx44dVbBgQVWvXl358uWzPuYqa9as2rBhg2JiYvTOO++oaNGi+vjjj+Xt7f3YZx8/atSoUVq1apX8/f2tVyuDg4O1dOlSrVy5UmXKlNEbb7yhMWPGKCAgIMnrzZAhg3777TdFRUWpYsWKKlWqlKZMmWK9qt2mTRtNnTpV4eHhKlq0qCpWrKiIiAjr47kex8HBQePGjdPkyZOVNWvWeF9wPMzX11cRERH66aefVKhQIX3xxRf66quvkrwf0oMvXy5duqQWLVooX758atiwoUJCQjRo0KBElylZsqTmzp2r2bNnq0iRIhowYIAGDx6c4KjmZggPD1eLFi3UvXt35c+fX3Xr1tW2bdviPef9YW5ubjp06JDee+895cuXTx9++KE6duyodu3aWdvMmjUr3vPezWYxUjDRDhs2TKNHj9b06dNVuHBhbd++Xa1bt9bQoUPVpUuXJy5//fp1pUuXTteuXUv0xAEAePkF9k78W20k7JRL05QuIfUJS/zKEl4+d+7c0cmTJ5UzZ854g3ch6b755hstWbJEv/zyS0qXAmj//v16++23deTIkUQHpHvcsZ/U/Jmi92Rv3LhRderUUY0aNSQ96Noxa9Ys63PiAAAAAKRe7dq109WrV3Xjxg15enqmdDl4xZ07d07//e9/n3nE9ydJ0e7i5cuX1+rVq3XkyBFJD4bWX79+vUJCQlKyLAAAAAAmcHBwUN++fV/5gD1s2DB5eHgk+EP2eX6qVq1q1wCATytFr2T37t1b169fV4ECBZQ2bVrFxMRo6NChiY7IFx0drejoaOvrxw20AAAAAAAvgo8++kgNGzZMcN7jHg2G1ClFQ/bcuXM1Y8YMzZw5U4ULF9bu3bv18ccfK2vWrGrZsmW89sOHD3/szfgAAAAA8KLx8fGRj49PSpeB5yRFu4v37NlTvXv3VuPGjVW0aFH95z//Ubdu3TR8+PAE2/fp00fXrl2z/pw5c+Y5VwwAAAAAQOJS9Er2rVu34g3HnzZtWsXGxibY3tnZWc7Ozs+jNAAAACDR/5cCeDmZccynaMiuVauWhg4dqhw5cqhw4cLatWuXRo8erdDQ0JQsCwAAAK84JycnpUmTRn///bd8fX3l5OQki8WS0mUBSCaGYeju3bu6ePGi0qRJIycnp6deV4qG7PHjx6t///7q0KGDLly4oKxZs6pdu3YaMGBASpYFAACAV1yaNGmUM2dOnTt3Tn///XdKlwPgOXFzc1OOHDni9bi2R4qGbE9PT40dO1Zjx45NyTIAAACAeJycnJQjRw7dv39fMTExKV0OgGSWNm1aOTg4PHOvlRQN2QAAAMCLzGKxyNHRUY6OjildCoBUIkVHFwcAAAAA4GXClexXUGDvZSldQqp0yqVpSpeQ+oRdS+kKAAAAgOeKK9kAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACY5JlCdnR0tFl1AAAAAACQ6tkVspcvX66WLVsqV65ccnR0lJubm7y8vFSxYkUNHTpUf//9d3LVCQAAAADACy9JIXvhwoXKly+fQkND5eDgoF69emnBggX65ZdfNHXqVFWsWFG//vqrcuXKpY8++kgXL15M7roBAAAAAHjhOCSl0YgRIzRmzBiFhIQoTZr4ubxhw4aSpL/++kvjx4/Xjz/+qG7duplbKQAAAAAAL7gkhexNmzYlaWXZsmXTF1988UwFAQAAAACQWjG6OAAAAAAAJklyyC5UqJAuX75sfd2hQwf9+++/1tcXLlyQm5ubudUBAAAAAJCKJDlkHzp0SPfv37e+/vHHH3X9+nXra8MwdOfOHXOrAwAAAAAgFXnq7uKGYcSbZrFYnqkYAAAAAABSM+7JBgAAAADAJEkO2RaLJd6Vaq5cAwAAAADwf5L0CC/pQffwKlWqyMHhwSK3b99WrVq15OTkJEk292sDAAAAAPAqSnLIHjhwoM3rOnXqxGvz3nvv2V3AX3/9pV69emn58uW6deuW8uTJo/DwcJUuXdrudQEAAAAAkJKeOmSb4cqVKwoKClLlypW1fPly+fr66ujRo0qfPr3p2wIAAAAAILklOWQn5o8//tDNmzdVrlw5u8Pxl19+KX9/f4WHh1un5cyZ81lLAgAAAAAgRSR54LMvv/xS/fv3t742DEPVq1dX5cqVVbNmTRUsWFD79++3a+NLlixR6dKl1aBBA2XKlEklSpTQlClT7FoHAAAAAAAviiSH7Dlz5qhIkSLW1/PmzdPatWu1bt06/fvvvypdurQGDRpk18ZPnDihb7/9Vnnz5tUvv/yi9u3bq0uXLpo+fXqC7aOjo3X9+nWbHwAAAAAAXhRJDtknT55UsWLFrK9//vlnvf/++woKCpKPj4/69eunTZs22bXx2NhYlSxZUsOGDVOJEiX04Ycfqm3btpo0aVKC7YcPH6506dJZf/z9/e3aHgAAAAAAySnJIfv+/ftydna2vt60aZPKly9vfZ01a1b9+++/dm08S5YsKlSokM20ggULKjIyMsH2ffr00bVr16w/Z86csWt7AAAAAAAkpyQPfJY7d26tXbtWuXLlUmRkpI4cOaIKFSpY5589e1YZMmSwa+NBQUE6fPiwzbQjR44oICAgwfbOzs42QR8AAAAAgBdJkkN2x44d1alTJ61bt06bN29WuXLlbK5C//bbbypRooRdG+/WrZvKly+vYcOGqWHDhtq6dau+++47fffdd3atBwAAAACAF0GSu4u3bdtW48aN0+XLl1WhQgXNnz/fZv7ff/+t0NBQuzZepkwZLVy4ULNmzVKRIkU0ZMgQjR07Vs2aNbNrPQAAAAAAvAgshmEYKV3E07p+/brSpUuna9euycvLK6XLSTUCey9L6RJSpVMuTVO6hNQn7FpKV4BXBOc1+3FOewqc0wDglZbU/JnkK9kAAAAAAODxknxPdtq0aZPULiYm5qmLAQAAAAAgNUtyyDYMQwEBAWrZsqXdA5wBAAAAAPAqSHLI3rp1q77//nt9/fXXypkzp0JDQ9WsWTOlT58+OesDAAAAACDVSPI92aVLl9a3336rc+fO6ZNPPtHChQuVPXt2NW7cWKtWrUrOGgEAAAAASBXsHvjMxcVFzZs31+rVq/Xnn3/qwoULql69ui5fvpwc9QEAAAAAkGokubv4w86ePauIiAhFRETo1q1b6tmzJ4/QAgAAAAC88pIcsu/evauFCxfq+++/17p16xQSEqKxY8cqJCQkySOPAwAAAADwMktyyM6SJYs8PT3VsmVLTZw4UZkyZZIk3bx506YdV7QBAAAAAK+qJIfsK1eu6MqVKxoyZIg+//zzePMNw5DFYuE52QAAAACAV1aSQ/bvv/+enHUAAAAAAJDqJTlkV6xYMTnrAAAAAAAg1UvSI7weve/a7PYAAAAAALwMkhSy8+TJoy+++ELnzp1LtI1hGFq1apVCQkI0btw40woEAAAAACC1SFJ38TVr1uizzz5TWFiYihcvrtKlSytr1qxycXHRlStXdODAAW3atEkODg7q06eP2rVrl9x1AwAAAADwwklSyM6fP7/mz5+vyMhI/fTTT1q3bp02btyo27dvK2PGjCpRooSmTJnCM7MBAAAAAK+0JA98Jkk5cuRQ9+7d1b179+SqBwAAAACAVCtJ92QDAAAAAIAnI2QDAAAAAGASQjYAAAAAACYhZAMAAAAAYBK7Qvb9+/c1ePBgnT17NrnqAQAAAAAg1bIrZDs4OGjkyJG6f/9+ctUDAAAAAECqZXd38bffflt//PFHctQCAAAAAECqZtdzsiUpJCREvXv31r59+1SqVCm5u7vbzK9du7ZpxQEAAAAAkJrYHbI7dOggSRo9enS8eRaLRTExMc9eFQAAAAAAqZDdITs2NjY56gAAAAAAINXjEV4AAAAAAJjkqUL2H3/8oVq1ailPnjzKkyePateurXXr1pldGwAAAAAAqYrdIfvHH39U1apV5ebmpi5duqhLly5ydXVVlSpVNHPmzOSoEQAAAACAVMHue7KHDh2qESNGqFu3btZpXbp00ejRozVkyBA1bdrU1AIBAAAAAEgt7L6SfeLECdWqVSve9Nq1a+vkyZOmFAUAAAAAQGpkd8j29/fX6tWr403/9ddf5e/vb0pRAAAAAACkRnZ3F+/evbu6dOmi3bt3q3z58pKkDRs2KCIiQl9//bXpBQIAAAAAkFrYHbLbt28vPz8/jRo1SnPnzpUkFSxYUHPmzFGdOnVMLxAAAAAAgNTCrpB9//59DRs2TKGhoVq/fn1y1QQAAAAAQKpk1z3ZDg4OGjFihO7fv59c9QAAAAAAkGrZPfBZlSpV9McffyRHLQAAAAAApGp235MdEhKi3r17a9++fSpVqpTc3d1t5teuXdu04gAAAAAASE3sDtkdOnSQJI0ePTrePIvFopiYmGevCgAAAACAVMjukB0bG5scdQAAAAAAkOrZdU/2vXv35ODgoD///DO56gEAAAAAINWyK2Q7OjoqR44cdAkHAAAAACABdo8u3rdvX3322We6fPlyctQDAAAAAECqZfc92RMmTNCxY8eUNWtWBQQExBtdfOfOnaYVBwAAAABAamJ3yK5bt24ylAEAAAAAQOpnd8geOHBgctQBAAAAAECql+R7srdu3frYAc+io6M1d+5cU4oCAAAAACA1SnLILleunC5dumR97eXlpRMnTlhfX716VU2aNDG3OgAAAAAAUpEkh2zDMB77OrFpAAAAAAC8Kux+hNfjWCwWM1cHAAAAAECqYmrIBgAAAADgVWbX6OIHDhzQ+fPnJT3oGn7o0CFFRUVJkv7991/zqwMAAAAAIBWxK2RXqVLF5r7rmjVrSnrQTdwwDLqLAwAAAABeaUkO2SdPnkzOOgAAAAAASPWSHLIDAgKSsw4AAAAAAFI9Bj4DAAAAAMAkhGwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJEkaXbxEiRJJfgb2zp07n6kgAAAAAABSqySF7Lp161r/fefOHU2cOFGFChVSuXLlJEmbN2/W/v371aFDh2QpEgAAAACA1CBJIXvgwIHWf7dp00ZdunTRkCFD4rU5c+aMudUBAAAAAJCK2H1P9k8//aQWLVrEm968eXPNnz/flKIAAAAAAEiN7A7Zrq6u2rBhQ7zpGzZskIuLiylFAQAAAACQGiWpu/jDPv74Y7Vv3147d+5U2bJlJUlbtmzRtGnT1L9/f9MLBAAAAAAgtbA7ZPfu3Vu5cuXS119/rR9//FGSVLBgQYWHh6thw4amFwgAAAAAQGphd8iWpIYNGxKoAQAAAAB4hN33ZEvS1atXNXXqVH322We6fPmypAfPx/7rr79MLQ4AAAAAgNTE7ivZe/fuVdWqVZUuXTqdOnVKbdq0kY+PjxYsWKDIyEj997//TY46AQAAAAB44dl9JfuTTz5Rq1atdPToUZvRxN99912tXbvW1OIAAAAAAEhN7A7Z27ZtU7t27eJNz5Ytm86fP29KUQAAAAAApEZ2h2xnZ2ddv3493vQjR47I19fXlKIAAAAAAEiN7A7ZtWvX1uDBg3Xv3j1JksViUWRkpHr16qX33nvP9AIBAAAAAEgt7A7Zo0aNUlRUlDJlyqTbt2+rYsWKypMnjzw9PTV06NDkqBEAAAAAgFTB7tHF06VLp1WrVmnDhg3as2ePoqKiVLJkSVWtWjU56gMAAAAAINWwK2Tfu3dPrq6u2r17t4KCghQUFJRcdQEAAAAAkOrY1V3c0dFROXLkUExMTHLVAwAAAABAqmX3Pdl9+/bVZ599psuXLydHPQAAAAAApFp235M9YcIEHTt2TFmzZlVAQIDc3d1t5u/cudO04gAAAAAASE3sDtl169ZNhjIAAAAAAEj97A7ZAwcOTI46AAAAAABI9ey+JxsAAAAAACTM7ivZMTExGjNmjObOnavIyEjdvXvXZj4DogEAAAAAXlV2X8keNGiQRo8erUaNGunatWv65JNPVL9+faVJk0ZhYWHJUCIAAAAAAKmD3SF7xowZmjJlirp37y4HBwc1adJEU6dO1YABA7R58+bkqBEAAAAAgFTB7pB9/vx5FS1aVJLk4eGha9euSZJq1qypZcuWmVsdAAAAAACpiN0hO3v27Dp37pwkKXfu3Fq5cqUkadu2bXJ2dja3OgAAAAAAUhG7Q3a9evW0evVqSVLnzp3Vv39/5c2bVy1atFBoaKjpBQIAAAAAkFrYPbr4F198Yf13o0aNlCNHDm3atEl58+ZVrVq1TC0OAAAAAIDUxO6Q/ahy5cqpXLlyZtQCAAAAAECqZnfI/u9///vY+S1atHjqYgAAAAAASM3sDtldu3a1eX3v3j3dunVLTk5OcnNzI2QDAAAAAF5Zdg98duXKFZufqKgoHT58WG+++aZmzZqVHDUCAAAAAJAq2B2yE5I3b1598cUX8a5yAwAAAADwKjElZEuSg4OD/v77b7NWBwAAAABAqmP3PdlLliyxeW0Yhs6dO6cJEyYoKCjItMIAAAAAAEht7A7ZdevWtXltsVjk6+urt99+W6NGjXrqQr744gv16dNHXbt21dixY596PQAAAAAApBS7Q3ZsbKzpRWzbtk2TJ09WsWLFTF83AAAAAADPi2n3ZD+tqKgoNWvWTFOmTFH69OlTuhwAAAAAAJ6a3VeyP/nkkyS3HT169BPbdOzYUTVq1FDVqlX1+eefP7ZtdHS0oqOjra+vX7+e5FoAAAAAAEhudofsXbt2adeuXbp3757y588vSTpy5IjSpk2rkiVLWttZLJYnrmv27NnauXOntm3blqRtDx8+XIMGDbK3ZAAAAAAAngu7Q3atWrXk6emp6dOnW7t3X7lyRa1bt9Zbb72l7t27J2k9Z86cUdeuXbVq1Sq5uLgkaZk+ffrYXEm/fv26/P397d0FAAAAAACShd0he9SoUVq5cqXN/dPp06fX559/rnfeeSfJIXvHjh26cOGCzdXvmJgYrV27VhMmTFB0dLTSpk1rs4yzs7OcnZ3tLRkAAAAAgOfC7pB9/fp1Xbx4Md70ixcv6saNG0leT5UqVbRv3z6baa1bt1aBAgXUq1eveAEbAAAAAIAXnd0hu169emrdurVGjRqlsmXLSpK2bNminj17qn79+klej6enp4oUKWIzzd3dXRkyZIg3HQAAAACA1MDukD1p0iT16NFDTZs21b179x6sxMFBH3zwgUaOHGl6gQAAAAAApBZ2h2w3NzdNnDhRI0eO1PHjxyVJuXPnlru7+zMXs2bNmmdeBwAAAAAAKSXN0y7o7u6uYsWKKV26dDp9+rRiY2PNrAsAAAAAgFQnySF72rRpGj16tM20Dz/8ULly5VLRokVVpEgRnTlzxvQCAQAAAABILZIcsr/77jubx3atWLFC4eHh+u9//6tt27bJ29tbgwYNSpYiAQAAAABIDZJ8T/bRo0dVunRp6+vFixerTp06atasmSRp2LBhat26tfkVAgAAAACQSiT5Svbt27fl5eVlfb1x40ZVqFDB+jpXrlw6f/68udUBAAAAAJCKJDlkBwQEaMeOHZKkf//9V/v371dQUJB1/vnz55UuXTrzKwQAAAAAIJVIcnfxli1bqmPHjtq/f79+++03FShQQKVKlbLO37hxo4oUKZIsRQIAAAAAkBokOWR/+umnunXrlhYsWCA/Pz/99NNPNvM3bNigJk2amF4gAAAAAACpRZJDdpo0aTR48GANHjw4wfmPhm4AAAAAAF41Sb4nGwAAAAAAPB4hGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADBJkkcXjxMTE6OIiAitXr1aFy5cUGxsrM383377zbTiAAAAAABITewO2V27dlVERIRq1KihIkWKyGKxJEddAAAAAACkOnaH7NmzZ2vu3Ll69913k6MeAAAAAABSLbvvyXZyclKePHmSoxYAAAAAAFI1u0N29+7d9fXXX8swjOSoBwAAAACAVMvu7uLr16/X77//ruXLl6tw4cJydHS0mb9gwQLTigMAAAAAIDWxO2R7e3urXr16yVELAAAAAACpmt0hOzw8PDnqAAAAAAAg1bP7nmwAAAAAAJAwu69kS9K8efM0d+5cRUZG6u7duzbzdu7caUphAAAAAACkNnZfyR43bpxat26tzJkza9euXSpbtqwyZMigEydOKCQkJDlqBAAAAAAgVbA7ZE+cOFHfffedxo8fLycnJ3366adatWqVunTpomvXriVHjQAAAAAApAp2h+zIyEiVL19ekuTq6qobN25Ikv7zn/9o1qxZ5lYHAAAAAEAqYnfI9vPz0+XLlyVJOXLk0ObNmyVJJ0+elGEY5lYHAAAAAEAqYnfIfvvtt7VkyRJJUuvWrdWtWzdVq1ZNjRo14vnZAAAAAIBXmt2ji3/33XeKjY2VJHXs2FEZMmTQxo0bVbt2bbVr1870AgEAAAAASC3sDtlp0qRRmjT/dwG8cePGaty4salFAQAAAACQGtndXVyS1q1bp+bNm6tcuXL666+/JEk//PCD1q9fb2pxAAAAAACkJnaH7Pnz5ys4OFiurq7atWuXoqOjJUnXrl3TsGHDTC8QAAAAAIDUwu6Q/fnnn2vSpEmaMmWKHB0drdODgoK0c+dOU4sDAAAAACA1sTtkHz58WBUqVIg3PV26dLp69aoZNQEAAAAAkCo91XOyjx07Fm/6+vXrlStXLlOKAgAAAAAgNbI7ZLdt21Zdu3bVli1bZLFY9Pfff2vGjBnq0aOH2rdvnxw1AgAAAACQKtj9CK/evXsrNjZWVapU0a1bt1ShQgU5OzurR48e6ty5c3LUCAAAAABAqmB3yLZYLOrbt6969uypY8eOKSoqSoUKFZKHh0dy1AcAAAAAQKphd8iO4+TkpEKFCplZCwAAAAAAqVqSQ3ZoaGiS2k2bNu2piwEAAAAAIDVLcsiOiIhQQECASpQoIcMwkrMmAAAAAABSpSSH7Pbt22vWrFk6efKkWrdurebNm8vHxyc5awMAAAAAIFVJ8iO8vvnmG507d06ffvqp/ve//8nf318NGzbUL7/8wpVtAAAAAABk53OynZ2d1aRJE61atUoHDhxQ4cKF1aFDBwUGBioqKiq5agQAAAAAIFWwK2TbLJgmjSwWiwzDUExMjJk1AQAAAACQKtkVsqOjozVr1ixVq1ZN+fLl0759+zRhwgRFRkbynGwAAAAAwCsvyQOfdejQQbNnz5a/v79CQ0M1a9YsZcyYMTlrAwAAAAAgVUlyyJ40aZJy5MihXLly6Y8//tAff/yRYLsFCxaYVhwAAAAAAKlJkkN2ixYtZLFYkrMWAAAAAABStSSH7IiIiGQsAwAAAACA1O+pRxcHAAAAAAC2CNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASQjZAAAAAACYhJANAAAAAIBJCNkAAAAAAJiEkA0AAAAAgEkI2QAAAAAAmISQDQAAAACASVI0ZA8fPlxlypSRp6enMmXKpLp16+rw4cMpWRIAAAAAAE8tRUP2H3/8oY4dO2rz5s1atWqV7t27p3feeUc3b95MybIAAAAAAHgqDim58RUrVti8joiIUKZMmbRjxw5VqFAhhaoCAAAAAODppGjIftS1a9ckST4+PgnOj46OVnR0tPX19evXn0tdAAAAAAAkxQsz8FlsbKw+/vhjBQUFqUiRIgm2GT58uNKlS2f98ff3f85VAgAAAACQuBcmZHfs2FF//vmnZs+enWibPn366Nq1a9afM2fOPMcKAQAAAAB4vBeiu3inTp20dOlSrV27VtmzZ0+0nbOzs5ydnZ9jZQAAAAAAJF2KhmzDMNS5c2ctXLhQa9asUc6cOVOyHAAAAAAAnkmKhuyOHTtq5syZWrx4sTw9PXX+/HlJUrp06eTq6pqSpQEAAAAAYLcUvSf722+/1bVr11SpUiVlyZLF+jNnzpyULAsAAAAAgKeS4t3FAQAAAAB4Wbwwo4sDAAAAAJDaEbIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwCSEbAAAAAACTELIBAAAAADAJIRsAAAAAAJMQsgEAAAAAMAkhGwAAAAAAkxCyAQAAAAAwiUNKFwAAAADg/wT2XpbSJaQ6p1yapnQJqU/YtZSu4KXFlWwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJIRsAAAAAABMQsgGAAAAAMAkhGwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJIRsAAAAAABMQsgGAAAAAMAkhGwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJIRsAAAAAABMQsgGAAAAAMAkhGwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJIRsAAAAAABMQsgGAAAAAMAkhGwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJIRsAAAAAABMQsgGAAAAAMAkhGwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJIRsAAAAAABMQsgGAAAAAMAkhGwAAAAAAExCyAYAAAAAwCSEbAAAAAAATELIBgAAAADAJIRsAAAAAABMQsgGAAAAAMAkL0TI/uabbxQYGCgXFxe9/vrr2rp1a0qXBAAAAACA3VI8ZM+ZM0effPKJBg4cqJ07d6p48eIKDg7WhQsXUro0AAAAAADskuIhe/To0Wrbtq1at26tQoUKadKkSXJzc9O0adNSujQAAAAAAOySoiH77t272rFjh6pWrWqdliZNGlWtWlWbNm1KwcoAAAAAALCfQ0pu/N9//1VMTIwyZ85sMz1z5sw6dOhQvPbR0dGKjo62vr527Zok6fr168lb6EsmNvpWSpeQKl23GCldQurDsYnnhPOa/TinPQXOaXhOOKfZj3PaU+CcZre43GkYj/+8pWjIttfw4cM1aNCgeNP9/f1ToBq8atKldAGp0Re8a8CLiqPzKXBOA15YHJ1PgXPaU7tx44bSpUv8/UvRkJ0xY0alTZtW//zzj830f/75R35+fvHa9+nTR5988on1dWxsrC5fvqwMGTLIYrEke714dV2/fl3+/v46c+aMvLy8UrocAHgmnNMAvEw4p+F5MQxDN27cUNasWR/bLkVDtpOTk0qVKqXVq1erbt26kh4E59WrV6tTp07x2js7O8vZ2dlmmre393OoFHjAy8uLkzeAlwbnNAAvE85peB4edwU7Top3F//kk0/UsmVLlS5dWmXLltXYsWN18+ZNtW7dOqVLAwAAAADALikeshs1aqSLFy9qwIABOn/+vF577TWtWLEi3mBoAAAAAAC86FI8ZEtSp06dEuweDrwonJ2dNXDgwHi3KwBAasQ5DcDLhHMaXjQW40njjwMAAAAAgCRJk9IFAAAAAADwsiBkAwAAAABgEkI28P+dOnVKFotFu3fvTulSAKRyKX0+sVgsWrRoUYps+2m1atXK+jhP4Fkl5fMUGBiosWPHWl8/6bhJ6eMayeNV/L0++tlPSFhYmF577TXr60ePqUqVKunjjz9OlvqeVVL2L7kRspFiWrVqJYvFYv3JkCGDqlevrr1798Zr265dO6VNm1Y//fTTY9cZHBystGnTatu2bQluL6E/uK1bt1a/fv2eej9S0vr16xUUFKQMGTLI1dVVBQoU0JgxY1K6LOC543yCxAwdOlTly5eXm5ubvL29k7TMo58ni8Wi6tWrJ2+heO62bdumDz/8MMnt/f39de7cORUpUsT0Wq5evaqOHTsqS5YscnZ2Vr58+fTzzz9b5w8fPlxlypSRp6enMmXKpLp16+rw4cMJrsswDIWEhCT6pcHp06fl6uqqqKioZPtyK6H1njp1Sh988IFy5swpV1dX5c6dWwMHDtTdu3dN3z7sk9BnpUePHlq9enWiyyxYsEBDhgxJ5spSL0I2UlT16tV17tw5nTt3TqtXr5aDg4Nq1qxp0+bWrVuaPXu2Pv30U02bNi3RdUVGRmrjxo3q1KnTY9s9LCYmRkuXLlXt2rWfaT9Siru7uzp16qS1a9fq4MGD6tevn/r166fvvvsupUsDnjvOJ0jI3bt31aBBA7Vv396u5R7+PJ07d06zZs1KpgqRUnx9feXm5pbk9mnTppWfn58cHMx9OM/du3dVrVo1nTp1SvPmzdPhw4c1ZcoUZcuWzdrmjz/+UMeOHbV582atWrVK9+7d0zvvvKObN2/GW9/YsWNlsVgS3d7ixYtVuXJleXh4mLofT3Lo0CHFxsZq8uTJ2r9/v8aMGaNJkybps88+e651IGk8PDyUIUOGROf7+PjI09PzOVaUuhCykaKcnZ3l5+cnPz8/vfbaa+rdu7fOnDmjixcvWtv89NNPKlSokHr37q21a9fqzJkzCa4rPDxcNWvWVPv27TVr1izdvn37idvfuHGjHB0dVaZMGeu0Q4cOqXz58nJxcVGRIkX0xx9/2CyzZMkS5c2bVy4uLqpcubKmT58ui8Wiq1evWtusX79eb731llxdXeXv768uXbok+IfwYRaLRZMnT1bNmjXl5uamggULatOmTTp27JgqVaokd3d3lS9fXsePH7cuU6JECTVp0kSFCxdWYGCgmjdvruDgYK1bt+6J+w68bDif2Dp37pxCQkLk6uqqXLlyad68eTbze/XqpXz58snNzU25cuVS//79de/ePev8PXv2qHLlyvL09JSXl5dKlSql7du3P3VdERER8a4OWywWhYWF2bT76quvlCVLFmXIkEEdO3a0qelh169fl6urq5YvX24zfeHChfL09NStW7ckSYMGDVK3bt1UtGjRJ75nD3v48+Tn56f06dPbtTyej3nz5qlo0aJydXVVhgwZVLVqVZvP4eM+Twl1KX3ccfNot+I1a9bIYrFo9erVKl26tNzc3FS+fPl4V5g///xzZcqUSZ6enmrTpo169+5t0w132rRpunz5shYtWqSgoCAFBgaqYsWKKl68uLXNihUr1KpVKxUuXFjFixdXRESEIiMjtWPHDptt7d69W6NGjXrsl4OLFy9W7dq1FRYWpunTp2vx4sXW43HNmjWSpDNnzqhhw4by9vaWj4+P6tSpo1OnTkl6cF5zc3PTzJkzreucO3euXF1ddeDAgUTXW716dYWHh+udd95Rrly5VLt2bfXo0UMLFiyQlPRj+nG1PfyeFi5cWM7OzsqSJUuSHhX8uPN1TEyMzVX4/Pnz6+uvv7ZZfs2aNSpbtqzc3d3l7e2toKAgnT592uZ9L1mypFxcXJQrVy4NGjRI9+/fT7SeuM/b3LlzrefaMmXK6MiRI9q2bZtKly4tDw8PhYSE2PydS6gbd926ddWqVasEtxMYGChJqlevniwWi/X1o93FH/XodgIDAzVs2DCFhobK09NTOXLkiHfRZ+PGjXrttdfk4uKi0qVLa9GiRTbHVERERLweR3Ft4hw/flx16tRR5syZ5eHhoTJlyujXX39NtM6UQsjGCyMqKko//vij8uTJY/PN2ffff6/mzZsrXbp0CgkJUURERLxlDcNQeHi4mjdvrgIFCihPnjzx/kOZkCVLlqhWrVo2B2/Pnj3VvXt37dq1S+XKlVOtWrV06dIlSdLJkyf1/vvvq27dutqzZ4/atWunvn372qzz+PHjql69ut577z3t3btXc+bM0fr165N0gh8yZIhatGih3bt3q0CBAmratKnatWunPn36aPv27TIM47Hr2bVrlzZu3KiKFSs+cVvAy4zzidS/f3+999572rNnj5o1a6bGjRvr4MGD1vmenp6KiIjQgQMH9PXXX2vKlCk2t5s0a9ZM2bNn17Zt27Rjxw717t1bjo6OT11Xo0aN4l0ZdnBwUFBQkLXN77//ruPHj+v333/X9OnTFRERkeDvSJK8vLxUs2ZNm//oS9KMGTNUt25du65QJmTNmjXKlCmT8ufPr/bt21t/b3hxnDt3Tk2aNFFoaKgOHjyoNWvWqH79+op7Oq09n6c4TzpuEtK3b1+NGjVK27dvl4ODg0JDQ63zZsyYoaFDh+rLL7/Ujh07lCNHDn377bc2yy9ZskTlypVTx44dlTlzZhUpUkTDhg1TTExMotu8du2apAdXE+PcunVLTZs21TfffCM/P78El7t69arWr19vDbgNGza06bVRvnx53bt3T8HBwfL09NS6deu0YcMGeXh4qHr16rp7964KFCigr776Sh06dFBkZKTOnj2rjz76SF9++aUKFSqU6HoT24+4fUjKMf2k2iTp22+/VceOHfXhhx9q3759WrJkifLkyZPoexnncefr2NhYZc+eXT/99JMOHDigAQMG6LPPPtPcuXMlSffv31fdunVVsWJF7d27V5s2bdKHH35o/Xuwbt06tWjRQl27dtWBAwc0efJkRUREaOjQoU+sa+DAgerXr5927twpBwcHNW3aVJ9++qm+/vprrVu3TseOHdOAAQOeuJ7ExN0SFR4ernPnziV4i1RSjRo1SqVLl9auXbvUoUMHtW/f3vql0/Xr11WrVi0VLVpUO3fu1JAhQ9SrVy+7txEVFaV3331Xq1ev1q5du1S9enXVqlVLkZGRT113sjCAFNKyZUsjbdq0hru7u+Hu7m5IMrJkyWLs2LHD2ubIkSOGo6OjcfHiRcMwDGPhwoVGzpw5jdjYWJt1rVy50vD19TXu3btnGIZhjBkzxqhYsWK87dWpU8dmWt68eY2lS5cahmEYJ0+eNCQZX3zxhXX+vXv3jOzZsxtffvmlYRiG0atXL6NIkSI26+jbt68hybhy5YphGIbxwQcfGB9++KFNm3Xr1hlp0qQxbt++nej7Icno16+f9fWmTZsMScb3339vnTZr1izDxcUl3rLZsmUznJycjDRp0hiDBw9OdBvAy4rziS1JxkcffWQz7fXXXzfat2+f6DIjR440SpUqZX3t6elpREREJNj2aeuKc+zYMcPHx8cYMWKEdVrLli2NgIAA4/79+9ZpDRo0MBo1apToehYuXGh4eHgYN2/eNAzDMK5du2a4uLgYy5cvj9c2PDzcSJcu3RNrM4wH59rFixcbe/fuNRYuXGgULFjQKFOmjE1tSHk7duwwJBmnTp2KNy8pn6eAgABjzJgx1tdPOm7ijutdu3YZhmEYv//+uyHJ+PXXX63tly1bZkiyHgevv/660bFjR5t1BgUFGcWLF7e+zp8/v+Hs7GyEhoYa27dvN2bPnm34+PgYYWFhCe53TEyMUaNGDSMoKMhm+ocffmh88MEHNvuzcOFCmzYzZswwSpcubfM+PXou++GHH4z8+fPbnBujo6MNV1dX45dffrFOq1GjhvHWW28ZVapUMd555x2b9gmt91FHjx41vLy8jO+++8467UnHdFJqy5o1q9G3b9/HbvthSTlfJ6Rjx47Ge++9ZxiGYVy6dMmQZKxZsybBtlWqVDGGDRtmM+2HH34wsmTJ8sS6pk6dap02a9YsQ5KxevVq67Thw4cb+fPnt76uWLGi0bVrV5t11alTx2jZsqX1dUKf/Uc/KwMHDrT5nD76O310OwEBAUbz5s2tr2NjY41MmTIZ3377rWEYhvHtt98aGTJksPkbMWXKFJtjKqHz9MKFC40nRdbChQsb48ePT3T/UgJXspGiKleurN27d2v37t3aunWrgoODFRISYu1eM23aNAUHBytjxoySpHfffVfXrl3Tb7/9ZrOeadOmqVGjRtb7pJo0aaINGzbYdK1+1MGDB/X333+rSpUqNtPLlStn/beDg4NKly5t/Rb78OHDNl1BJals2bI2r/fs2aOIiAh5eHhYf4KDgxUbG6uTJ09q2LBhNvMe/uatWLFi1n9nzpxZkmy6OGbOnFl37tzR9evXbba5bt06bd++XZMmTdLYsWO5dxCvJM4ntueTh7cd9/rhK3Jz5sxRUFCQ/Pz85OHhoX79+tks/8knn6hNmzaqWrWqvvjiC5v9f5a6rl27ppo1a6pGjRrq2bOnTY2FCxdW2rRpra+zZMmiCxcuSFKC63z33Xfl6OioJUuWSJLmz58vLy8vVa1aNd7vyB6NGzdW7dq1VbRoUdWtW1dLly7Vtm3brF1p8WIoXry4qlSpoqJFi6pBgwaaMmWKrly5Yp3/uM9TYp503CTk4b/dWbJkkSTrdg4fPhzvuH70dWxsrDJlyqTvvvtOpUqVUqNGjdS3b19NmjQpwe117NhRf/75p2bPnm2dtmTJEv32229PHFE5rqv44+zZs0fHjh2Tp6en9Xjz8fHRnTt3bM4D06ZN0969e7Vz507r7SBJ9ddff6l69epq0KCB2rZta53+pGP6SbVduHAhwXNxnI8++sjmPPKwx52vJembb75RqVKl5OvrKw8PD3333XfWc5uPj49atWql4OBg1apVS19//bXOnTtn854OHjzYZttt27bVuXPndOvWrcfWlZT/Gz7pc/28PFyrxWKRn5+fzbFQrFgxubi4WNs8eiwkRVRUlHr06KGCBQvK29tbHh4eOnjw4At3JdvckRsAO7m7u9t04Zk6darSpUunKVOmaNCgQZo+fbrOnz9vM8hITEyMpk2bZj2BXr58WQsXLtS9e/dsumDFtUusK86SJUtUrVo1m4PdDFFRUWrXrp26dOkSb16OHDn00UcfqWHDhtZpWbNmtf47riumJOsfq4SmxcbG2qw3Z86ckh6cdP/55x+FhYWpSZMmJuwNkHpwPrE9nzzOpk2b1KxZMw0aNEjBwcFKly6dZs+erVGjRlnbhIWFqWnTplq2bJmWL1+ugQMHavbs2apXr95T1xUTE6NGjRrJy8srwQEaHz7fSQ/OeXHnu4TW6eDgoPfff18zZ85U48aNNXPmTJsvSMySK1cuZcyYUceOHUv0P+94/tKmTatVq1Zp48aNWrlypcaPH6++fftqy5Ytkh7/eTJTUv5OP06WLFnk6Oho84VAwYIFdf78ed29e1dOTk7W6Z06ddLSpUu1du1aZc+e3Tr9t99+0/Hjx+Pdz/ree+/prbfe0po1a3T37l2tWLHiiQONRUVFqVSpUpoxY0a8eb6+vtZ/79mzRzdv3lSaNGl07tw56xcMT/L333+rcuXKKl++fLzzgJOT02OP6SfVlibN468fDh48WD169EhSnQ+bPXu2evTooVGjRqlcuXLy9PTUyJEjrZ816UF36y5dumjFihWaM2eO+vXrp1WrVumNN95QVFSUBg0apPr168dbt4uLy2PrSsr/DR/+vKVJk8Z6y0ScxMa2MNuzHnNJqb1Hjx5atWqVvvrqK+XJk0eurq56//33X7hR6gnZeKFYLBalSZNGt2/f1s8//6wbN25o165dNn94/vzzT7Vu3VpXr16Vt7e3ZsyYoezZs8d79MDKlSs1atQoDR482Gb5OIsXL07w0R2bN29WhQoVJD24x2bHjh3W+wzz589v80gNSfHuXSlZsqQOHDiQ6P0/Pj4+NvdQmS02NlbR0dHJtn4gtXjVzyebN29WixYtbF6XKFFC0oPBZwICAmzuAX94gJ44+fLlU758+dStWzc1adJE4eHhqlev3lPX1a1bN+3bt0/bt2+3+wuJxNbZrFkzVatWTfv379dvv/2mzz//3K71JsXZs2d16dKlJIcIPD8Wi0VBQUEKCgrSgAEDFBAQoIULFz71+h533DyN/Pnza9u2bTbrfPQ4DwoK0syZMxUbG2sNiUeOHFGWLFmsAdswDHXu3FkLFy7UmjVrrF+ux+ndu7fatGljM61o0aIaM2aMatWqJenBOAPp06e3GVDNyckp3r3fJUuW1Jw5c5QpUyZ5eXkluF+XL19Wq1at1LdvX507d07NmjXTzp075erqmuh6pQdXsCtXrqxSpUopPDw8wVD8uGM6KbUFBgZq9erVqly5crx5mTJlUqZMmRJc7nHn6w0bNqh8+fLq0KGDtX1CvZtKlCihEiVKqE+fPipXrpxmzpypN954QyVLltThw4cTPWc+ri57+fr62lxFj4mJ0Z9//png+xHH0dHxsWMAmCF//vz68ccfFR0dLWdnZ0nxjwVfX1/duHFDN2/elLu7uyTFe375hg0b1KpVK9WrV0/Sgy9eHh347kVAd3GkqOjoaJ0/f17nz5/XwYMH1blzZ0VFRalWrVr6/vvvVaNGDRUvXlxFihSx/sSNKBn3Leb333+v999/36ZNkSJF9MEHH+jff//VihUr4m33woUL2r59e7zH+0gPugMtXLhQhw4dUseOHXXlyhXrICbt2rXToUOH1KtXLx05ckRz5861DqIS9+1ir169rI/+2b17t44eParFixcnaaAie33zzTf63//+p6NHj+ro0aP6/vvv9dVXX6l58+ambwt40XE+sfXTTz9p2rRpOnLkiAYOHKitW7dal8ubN68iIyM1e/ZsHT9+XOPGjbMJJrdv31anTp20Zs0anT59Whs2bNC2bdtUsGDBp64rPDxcEydO1KRJk2SxWKy/q6ioqCfuy+NUqFBBfn5+atasmXLmzKnXX3/dZn5kZKR2796tyMhIxcTEWG8peHi7BQoUsO5/VFSUevbsqc2bN+vUqVNavXq16tSpozx58ig4OPiZaoW5tmzZomHDhmn79u2KjIzUggULdPHiRevn9Gk87rh5Gp07d9b333+v6dOn6+jRo/r888+1d+9em67V7du31+XLl9W1a1cdOXJEy5Yt07Bhw9SxY0drm44dO+rHH3/UzJkz5enpaT1+4p584OfnF++8JT3oWRIXyJcsWRKvq3hgYKD27t2rw4cP699//9W9e/fUrFkzZcyYUXXq1NG6det08uRJrVmzRl26dNHZs2clPehZ4u/vr379+mn06NGKiYmxuRKb0Hr/+usvVapUSTly5NBXX32lixcvWvfjYY87ppNSW1hYmEaNGqVx48bp6NGj2rlzp8aPH//E39Xjztd58+bV9u3b9csvv+jIkSPq37+/TUA8efKk+vTpo02bNun06dNauXKljh49av0sDhgwQP/97381aNAg7d+/XwcPHtTs2bPVr1+/J9Zlr7ffflvLli3TsmXLdOjQIbVv397miRUJifti4vz58za3XJipadOmio2N1YcffqiDBw/ql19+0VdffSXp//7mvf7663Jzc9Nnn32m48ePa+bMmfEGK8ybN68WLFig3bt3a8+ePdb1vnBS9I5wvNJatmxpSLL+eHp6GmXKlDHmzZtnnD9/3nBwcDDmzp2b4LLt27c3SpQoYWzfvt2QZGzdujXBdiEhIUa9evWs24sbsGHq1KnxBgyJG2Bi5syZRtmyZQ0nJyejUKFCxm+//WbTbvHixUaePHkMZ2dno1KlSsa3335rM8iJYRjG1q1bjWrVqhkeHh6Gu7u7UaxYMWPo0KGPfT/0yKATjw6wYhj/N8hK3KBI48aNMwoXLmy4ubkZXl5eRokSJYyJEycaMTExj90W8LLhfGJLkvHNN98Y1apVM5ydnY3AwEBjzpw5Nm169uxpZMiQwfDw8DAaNWpkjBkzxjrgTHR0tNG4cWPD39/fcHJyMrJmzWp06tTpmep69HcU9zNw4MB472mcrl27xht0LiGffvqpIckYMGBAkrf7+++/27xf4eHhhmEYxq1bt4x33nnH8PX1NRwdHY2AgACjbdu2xvnz559YB56vAwcOGMHBwYavr6/h7Oxs5MuXzzr4UVI+TwkN/vS44yaxgc/i/iYbhmHs2rXLkGScPHnSOm3w4MFGxowZDQ8PDyM0NNTo0qWL8cYbb9jUtnHjRuP11183nJ2djVy5chlDhw61GbQtoc/ww5/bhDz6/wp/f39j1apVNm0uXLhgPY4fPi7OnTtntGjRwsiYMaO1prZt2xrXrl0zpk+fbri7uxtHjhyxrmfLli2Go6Oj8fPPPye63vDw8ET341GPO6YfV1ucSZMmGfnz5zccHR2NLFmyGJ07d070fUrK+frOnTtGq1atjHTp0hne3t5G+/btjd69e1sHBjt//rxRt25dI0uWLIaTk5MREBBgDBgwwOb/YytWrDDKly9vuLq6Gl5eXkbZsmVtBn1LrK7H/T/QMOIPFnb37l2jffv2ho+Pj5EpUyZj+PDhTxz4bMmSJUaePHkMBwcHIyAgwDCMpxv47NHBxooXL249xxuGYWzYsMEoVqyY4eTkZJQqVcqYOXOmIck4dOiQtc3ChQuNPHnyGK6urkbNmjWN7777zuYzcvLkSaNy5cqGq6ur4e/vb0yYMCFJtTxvFsN4pOM78AqoXbu23nzzTX366afPvK6hQ4dq0qRJiT5vF8DLjfMJAHtUq1ZNfn5++uGHH57bNnfu3Km3335bFy9ejHffLJBSZsyYodatW+vatWvWWw1eFtyTjVfSm2+++dQDg02cOFFlypRRhgwZtGHDBo0cOTJZuoIDSB04nwBIzK1btzRp0iQFBwcrbdq0mjVrln799VetWrXqudZx//59jR8/noCNFPXf//5XuXLlUrZs2bRnzx716vX/2rv3oKjKPg7g3+W6LFcrdJFZYLxAS6nDRRxCRmMwMGDWyRkyhdggFIvQEryUOWZKDcqt0a4zgjXIxUBjJsqxxggwSRO0YrlI7NgUaV7AEJEVnvcPx/O6Lupq6+vMvt/PDH88l33O75ydYfY35zm/swaJiYlWl2ADAO9kE92lV199FZWVlTh//jx8fHyQnJyMdevWWbyaLRFZP/4/IbJuly9fRkJCAlpaWjA0NISAgACsX79+zCrTRNYuLy8P77//Pv766y94eXlhwYIF2LJlCxQKxYMOzeKYZBMRERERERFZCKuLExEREREREVkIk2wiIiIiIiIiC2GSTURERERERGQhTLKJiIiIiIiILIRJNhEREREREZGFMMkmIiK6B9999x1kMhn6+vrM/oyfnx+KioruW0x3a+PGjZgwYQJkMhn27dsHrVaLBQsWPOiwbuterjsREdH/EpNsIiKyOlqtFjKZDBkZGSZjL7/8MmQyGbRa7f8+MDNcvHgRb7zxBh599FHI5XIolUpER0ejpqYGlnzrpk6nw1tvvYWPPvoIvb29mD9/PoqLi1FaWmqxY/xbc+fOxcqVK436nnjiCfT29sLd3f3BBEVERHQHdg86ACIiovtBpVKhoqIChYWFcHJyAgAMDQ1h9+7d8PHxecDRja2vrw+zZ89Gf38/Nm/ejJkzZ8LOzg719fVYvXo1oqKi4OHhYZFjdXd3AwA0Gg1kMhkAwNHR0SJr34nBYIC9vf09fdbBwQFKpdLCEREREVkO72QTEZFVCg4OhkqlQk1NjdRXU1MDHx8fBAUFGc29cuUKsrKyMH78eMjlcsyePRtHjhwxmlNXVwd/f384OTnhySefhF6vNzlmY2MjIiMj4eTkBJVKhaysLFy6dMnsmF9//XXo9Xo0NzcjJSUFgYGB8Pf3R3p6OlpbW+Hi4gIAuHDhAp5//nmMGzcOCoUC8+fPR1dXl7ROaWkpPDw8sH//fqjVari4uCA2Nha9vb0Arm0TT0hIAADY2NhISfbN28X/+ecfLFmyBM7OzvDy8kJhYaHJ3eXrW81v5OHhId0R1+v1kMlkqKysxJw5cyCXy1FWVoZz587hueeeg7e3NxQKBaZNm4by8nJpDa1Wi/r6ehQXF0Mmk0Emk0Gv14+5Xby6uhqPPfYYHB0d4efnh/z8fKN4/Pz8kJubi9TUVLi6usLHxwcff/yxND48PIzMzEx4eXlBLpfD19cX77zzjtnfGxER0Y2YZBMRkdVKTU1FSUmJ1N65cydeeOEFk3mrV69GdXU1du3ahWPHjmHKlCmIiYnB+fPnAQC///47nnnmGSQkJKC1tRUvvvgi1q5da7RGd3c3YmNjsXDhQpw4cQKVlZVobGxEZmamWbGOjo6ioqICS5YswcSJE03GXVxcYGd3bQOaVqvF0aNHUVtbix9++AFCCDz99NMwGAzS/MHBQWzbtg2fffYZvv/+e5w6dQrZ2dkAgOzsbOm69Pb2Ssn3zV577TU0NTWhtrYWBw4cQENDA44dO2bW+dxs7dq1WLFiBXQ6HWJiYjA0NISQkBB8+eWX+OWXX7B06VIkJyfjxx9/BAAUFxcjPDwc6enpUowqlcpk3Z9++gmJiYlYtGgRfv75Z2zcuBFvvvmmybb3/Px8hIaGoqWlBS+99BKWL1+Ojo4OAMB7772H2tpaVFVVoaOjA2VlZfDz87un8yQiIoIgIiKyMikpKUKj0YgzZ84IR0dHodfrhV6vF3K5XPz9999Co9GIlJQUIYQQAwMDwt7eXpSVlUmfHx4eFhMnThR5eXlCCCHWrVsnAgMDjY6xZs0aAUBcuHBBCCFEWlqaWLp0qdGchoYGYWNjIy5fviyEEMLX11cUFhaOGfPp06cFAFFQUHDbc+vs7BQARFNTk9R39uxZ4eTkJKqqqoQQQpSUlAgA4uTJk9KcHTt2iAkTJkjtvXv3ipt/Bly/bkIIcfHiRWFvby/27Nkjjff19QmFQiFWrFgh9QEQe/fuNVrH3d1dlJSUCCGE6OnpEQBEUVHRbc9LCCHi4uLEqlWrpPacOXOMjiWEEAcPHjS67osXLxbz5s0zmpOTk2P0ffn6+oqkpCSpPTo6KsaPHy8++OADIYQQr7zyioiKihKjo6N3jJGIiOhO+Ew2ERFZLU9PT8TFxaG0tBRCCMTFxeGRRx4xmtPd3Q2DwYCIiAipz97eHmFhYdDpdACuFQmbNWuW0efCw8ON2sePH8eJEydQVlYm9QkhMDo6ip6eHqjV6tvGKswsaqbT6WBnZ2cUz8MPP4yAgAApXgBQKBSYPHmy1Pby8sKZM2fMOgYA/PbbbzAYDAgLC5P63N3dERAQYPYaNwoNDTVqj4yMIDc3F1VVVfjjjz8wPDyMK1euQKFQ3NW6Op0OGo3GqC8iIgJFRUUYGRmBra0tAGD69OnSuEwmg1KplK6HVqvFvHnzEBAQgNjYWMTHx+Opp566l9MkIiJi4TMiIrJuqamp0pbtHTt23LfjDAwMYNmyZcjKyjIZM6fQmqenJzw8PNDe3m6ReG4uLCaTySxanfx26964bf06Z2dno/bWrVtRXFyMoqIiTJs2Dc7Ozli5ciWGh4ctHiMw9vUYHR0FcO35/Z6eHnz11Vf45ptvkJiYiOjoaHz++ef3JRYiIrJufCabiIisWmxsLIaHh2EwGBATE2MyPnnyZDg4OKCpqUnqMxgMOHLkCAIDAwEAarVaelb4usOHDxu1g4OD0dbWhilTppj8OTg43DFOGxsbLFq0CGVlZfjzzz9NxgcGBnD16lWo1WpcvXoVzc3N0ti5c+fQ0dEhxWsJkyZNgr29vVEBuP7+fnR2dhrN8/T0NHqmu6urC4ODg3dcv6mpCRqNBklJSZgxYwYmTZpksraDgwNGRkZuu45arTb67q6v7e/vL93FNoebmxueffZZfPLJJ6isrER1dbX0TD4REdHdYJJNRERWzdbWFjqdDm1tbWMmXc7Ozli+fDlycnLw9ddfo62tDenp6RgcHERaWhoAICMjA11dXcjJyUFHRwd2795tUlhrzZo1OHToEDIzM9Ha2oquri588cUXZhc+A4AtW7ZApVJh1qxZ+PTTT9HW1oauri7s3LkTQUFBGBgYwNSpU6HRaJCeno7GxkYcP34cSUlJ8Pb2Ntk2/W+4uroiJSUFOTk5OHjwIH799VekpaUZVSMHgKioKGzfvh0tLS04evQoMjIyzHo919SpU3HgwAEcOnQIOp0Oy5Ytw+nTp43m+Pn5obm5GXq9HmfPnpXuPN9o1apV+Pbbb/H222+js7MTu3btwvbt26Uib+YoKChAeXk52tvb0dnZiT179kCpVFrsdWlERPT/hUk2ERFZPTc3N7i5ud1y/N1338XChQuRnJyM4OBgnDx5Evv378e4ceMAXNvuXV1djX379mHGjBn48MMPkZuba7TG9OnTUV9fj87OTkRGRiIoKAgbNmwYs1L4rTz00EM4fPgwkpKSsHnzZgQFBSEyMhLl5eXYunUr3N3dAQAlJSUICQlBfHw8wsPDIYRAXV3dPb97+lYKCgoQHh6O+Ph4REdHIyIiAmq1GnK5XJqTn58PlUqFyMhILF68GNnZ2WY9V71+/XoEBwcjJiYGc+fOhVKpNHp9GHCtCrqtrS0CAwPh6emJU6dOmawTHByMqqoqVFRU4PHHH8eGDRuwadMmaLVas8/T1dUVeXl5CA0NxcyZM6HX61FXVwcbG/5MIiKiuycT9+MBLSIiIrI6ly5dgre3N/Lz86W7/ERERGSMhc+IiIhoTC0tLWhvb0dYWBj6+/uxadMmALDotnQiIiJrwySbiIiIbmnbtm3o6OiAg4MDQkJC0NDQYPIaNCIiIvovbhcnIiIiIiIishBW9CAiIiIiIiKyECbZRERERERERBbCJJuIiIiIiIjIQphkExEREREREVkIk2wiIiIiIiIiC2GSTURERERERGQhTLKJiIiIiIiILIRJNhEREREREZGFMMkmIiIiIiIispD/AD0HWc3YAfV0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cpp as baseline\n",
    "mse_results = []\n",
    "for res in results:\n",
    "    res_py, res_cpp, res_sp = res\n",
    "    mse_py = np.mean((res_py - res_cpp) ** 2)\n",
    "    mse_sp = np.mean((res_sp - res_cpp) ** 2)\n",
    "    mse_results.append((mse_py, mse_sp))\n",
    "\n",
    "mse_df = pd.DataFrame(mse_results, columns=['MSE (transformers)', 'MSE (sentence_transformers)'], index=repos)\n",
    "\n",
    "print(mse_df)\n",
    "\n",
    "mse_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('MSE Comparison against C++ Results')\n",
    "plt.xlabel('Model Configurations')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Pooling Methods')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potasms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
