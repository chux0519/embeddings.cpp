{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7af4a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chuxd\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from gguf import GGUFWriter, GGMLQuantizationType\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:2080\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:2080\"\n",
    "\n",
    "def convert_hf(repo_id, output_path, float_type='f16'):\n",
    "    # convert to ggml quantization type\n",
    "    if float_type not in ['f16', 'f32']:\n",
    "        print(f'Float type must be f16 or f32, got: {float_type}')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        qtype = GGMLQuantizationType[float_type.upper()]\n",
    "        dtype0 = {'f16': torch.float16, 'f32': torch.float32}[float_type]\n",
    "\n",
    "    # load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "    tokenizer_json = os.path.join(os.path.dirname(output_path), os.path.basename(repo_id) + \".tokenizer.json\")\n",
    "    # tokenizer.save_pretrained(tokenizer_json)\n",
    "    tokenizer._tokenizer.save(tokenizer_json, False)\n",
    "    model = AutoModel.from_pretrained(repo_id, add_pooling_layer=False, trust_remote_code=True)\n",
    "\n",
    "    config = model.config\n",
    "    print(config)\n",
    "    \n",
    "    # print model\n",
    "    param_keys = [\n",
    "        'vocab_size', 'hidden_size', 'num_hidden_layers',\n",
    "        'num_attention_heads', 'intermediate_size', 'type_vocab_size', 'pad_token_id'\n",
    "    ]\n",
    "    print('PARAMS')\n",
    "    for k in param_keys:\n",
    "        v = getattr(config, k)\n",
    "        print(f'{k:<24s} = {v}')\n",
    "    print()\n",
    "\n",
    "    # print vocab\n",
    "    vocab_keys = [\n",
    "        'vocab_size', 'pad_token_id', 'unk_token_id', 'cls_token_id', 'sep_token_id'\n",
    "    ]\n",
    "    print('VOCAB')\n",
    "    for k in vocab_keys:\n",
    "        v = getattr(tokenizer, k)\n",
    "        print(f'{k:24s} = {v}')\n",
    "\n",
    "\n",
    "    # start to write GGUF file\n",
    "    gguf_writer = GGUFWriter(output_path, \"JinaBert\")\n",
    "\n",
    "    # write metadata\n",
    "    gguf_writer.add_name(repo_id)\n",
    "    gguf_writer.add_description('gguf model for embeddings.cpp')\n",
    "    gguf_writer.add_file_type(qtype)\n",
    "\n",
    "    # write model params\n",
    "    gguf_writer.add_uint32('vocab_size', config.vocab_size)\n",
    "    gguf_writer.add_uint32('hidden_size', config.hidden_size)\n",
    "    gguf_writer.add_uint32('intermediate_size', config.intermediate_size)\n",
    "    gguf_writer.add_uint32('num_attention_heads', config.num_attention_heads)\n",
    "    gguf_writer.add_uint32('num_hidden_layers', config.num_hidden_layers)\n",
    "    gguf_writer.add_uint32('type_vocab_size', config.type_vocab_size)\n",
    "    gguf_writer.add_uint32('pad_token_id', config.pad_token_id)\n",
    "    gguf_writer.add_float32('layer_norm_eps', config.layer_norm_eps)\n",
    "    gguf_writer.add_float32('rope_theta', config.rope_theta)\n",
    "\n",
    "\n",
    "    # write the tokenizer special token(we only need to know [PAD])\n",
    "    KEY_PAD_ID = 'tokenizer.ggml.padding_token_id'\n",
    "    gguf_writer.add_int32(KEY_PAD_ID, tokenizer.pad_token_id)\n",
    "\n",
    "    # write tensors\n",
    "    print('TENSORS')\n",
    "    hidden_size = config.hidden_size\n",
    "    for name, data in model.state_dict().items():\n",
    "        # get correct dtype\n",
    "        if 'emb_ln' in name or 'norm1' in name or 'norm2' in name or 'bias' in name:\n",
    "            dtype = torch.float32\n",
    "        else:\n",
    "            dtype = dtype0\n",
    "        shape_str = str(list(data.shape))\n",
    "        print(f'{name:64s} = {shape_str:16s} {data.dtype} → {dtype}')\n",
    "\n",
    "        # do conversion\n",
    "        data = data.to(dtype)\n",
    "\n",
    "        # add to gguf output\n",
    "        gguf_writer.add_tensor(name, data.numpy())\n",
    "\n",
    "    # execute and close writer\n",
    "    gguf_writer.write_header_to_file()\n",
    "    gguf_writer.write_kv_data_to_file()\n",
    "    gguf_writer.write_tensors_to_file()\n",
    "    gguf_writer.close()\n",
    "\n",
    "    # print success\n",
    "    print()\n",
    "    print(f'GGML model written to {output_path}')\n",
    "\n",
    "repo_id = 'Snowflake/snowflake-arctic-embed-m-v2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e875382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Override attn_implementation='sdpa' to 'eager' as use_memory_efficient_attention='true'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GteConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"GteModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"Snowflake/snowflake-arctic-embed-m-v2.0--configuration_hf_alibaba_nlp_gte.GteConfig\",\n",
      "    \"AutoModel\": \"Snowflake/snowflake-arctic-embed-m-v2.0--modeling_hf_alibaba_nlp_gte.GteModel\"\n",
      "  },\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"layer_norm_type\": \"layer_norm\",\n",
      "  \"logn_attention_clip1\": false,\n",
      "  \"logn_attention_scale\": false,\n",
      "  \"matryoshka_dimensions\": [\n",
      "    256\n",
      "  ],\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gte\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pack_qkv\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"rope\",\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 160000,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"unpad_inputs\": \"true\",\n",
      "  \"use_memory_efficient_attention\": \"true\",\n",
      "  \"vocab_size\": 250048\n",
      "}\n",
      "\n",
      "PARAMS\n",
      "vocab_size               = 250048\n",
      "hidden_size              = 768\n",
      "num_hidden_layers        = 12\n",
      "num_attention_heads      = 12\n",
      "intermediate_size        = 3072\n",
      "type_vocab_size          = 1\n",
      "pad_token_id             = 1\n",
      "\n",
      "VOCAB\n",
      "vocab_size               = 250002\n",
      "pad_token_id             = 1\n",
      "unk_token_id             = 3\n",
      "cls_token_id             = 0\n",
      "sep_token_id             = 2\n",
      "TENSORS\n",
      "embeddings.word_embeddings.weight                                = [250048, 768]    torch.float32 → torch.float16\n",
      "embeddings.token_type_embeddings.weight                          = [1, 768]         torch.float32 → torch.float16\n",
      "embeddings.LayerNorm.weight                                      = [768]            torch.float32 → torch.float16\n",
      "embeddings.LayerNorm.bias                                        = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.0.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.0.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.0.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.0.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.0.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.0.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.0.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.0.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.0.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.0.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.0.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.1.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.1.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.1.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.1.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.1.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.1.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.1.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.1.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.1.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.1.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.1.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.2.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.2.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.2.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.2.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.2.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.2.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.2.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.2.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.2.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.2.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.2.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.3.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.3.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.3.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.3.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.3.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.3.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.3.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.3.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.3.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.3.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.3.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.4.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.4.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.4.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.4.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.4.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.4.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.4.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.4.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.4.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.4.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.4.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.5.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.5.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.5.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.5.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.5.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.5.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.5.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.5.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.5.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.5.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.5.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.6.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.6.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.6.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.6.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.6.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.6.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.6.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.6.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.6.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.6.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.6.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.7.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.7.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.7.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.7.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.7.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.7.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.7.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.7.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.7.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.7.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.7.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.8.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.8.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.8.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.8.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.8.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.8.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.8.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.8.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.8.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.8.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.8.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.9.attention.qkv_proj.weight                        = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.9.attention.qkv_proj.bias                          = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.9.attention.o_proj.weight                          = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.9.attention.o_proj.bias                            = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.9.mlp.up_gate_proj.weight                          = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.9.mlp.down_proj.weight                             = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.9.mlp.down_proj.bias                               = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.9.attn_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.9.attn_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.9.mlp_ln.weight                                    = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.9.mlp_ln.bias                                      = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.10.attention.qkv_proj.weight                       = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.10.attention.qkv_proj.bias                         = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.10.attention.o_proj.weight                         = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.10.attention.o_proj.bias                           = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.10.mlp.up_gate_proj.weight                         = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.10.mlp.down_proj.weight                            = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.10.mlp.down_proj.bias                              = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.10.attn_ln.weight                                  = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.10.attn_ln.bias                                    = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.10.mlp_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.10.mlp_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.11.attention.qkv_proj.weight                       = [2304, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.11.attention.qkv_proj.bias                         = [2304]           torch.float32 → torch.float32\n",
      "encoder.layer.11.attention.o_proj.weight                         = [768, 768]       torch.float32 → torch.float16\n",
      "encoder.layer.11.attention.o_proj.bias                           = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.11.mlp.up_gate_proj.weight                         = [6144, 768]      torch.float32 → torch.float16\n",
      "encoder.layer.11.mlp.down_proj.weight                            = [768, 3072]      torch.float32 → torch.float16\n",
      "encoder.layer.11.mlp.down_proj.bias                              = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.11.attn_ln.weight                                  = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.11.attn_ln.bias                                    = [768]            torch.float32 → torch.float32\n",
      "encoder.layer.11.mlp_ln.weight                                   = [768]            torch.float32 → torch.float16\n",
      "encoder.layer.11.mlp_ln.bias                                     = [768]            torch.float32 → torch.float32\n",
      "\n",
      "GGML model written to ../models/snowflake-arctic-embed-m-v2.0.fp16.gguf\n"
     ]
    }
   ],
   "source": [
    "convert_hf(repo_id, \"../models/snowflake-arctic-embed-m-v2.0.fp16.gguf\", float_type=\"f16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
