From ce0b67de180a5b2203585372e608db65493d01b7 Mon Sep 17 00:00:00 2001
From: Yongsheng Xu <chuxdesign@hotmail.com>
Date: Mon, 9 Jun 2025 14:42:28 +0800
Subject: [PATCH] feat: add debug support (for only cpu backend)

---
 src/ggml-cpu/ggml-cpu.c | 78 +++++++++++++++++++++++++++++++++++++++++
 1 file changed, 78 insertions(+)

diff --git a/src/ggml-cpu/ggml-cpu.c b/src/ggml-cpu/ggml-cpu.c
index 0d23669..b7eb234 100644
--- a/src/ggml-cpu/ggml-cpu.c
+++ b/src/ggml-cpu/ggml-cpu.c
@@ -12296,6 +12296,74 @@ static void ggml_compute_forward_opt_step_adamw(
     }
 }
 /////////////////////////////////
+static void print_t_f16(const char* title, struct ggml_tensor * t, int n) {
+    printf("%s\n", title);
+
+    const ggml_fp16_t * data = (ggml_fp16_t *) t->data;
+
+    printf("dims: %jd %jd %jd %jd f16\n", t->ne[0], t->ne[1], t->ne[2], t->ne[3]);
+    printf("First & Last %d elements:\n", n);
+    for (int i = 0; i < MIN((int) (t->ne[0]*t->ne[1]), n); i++) {
+        printf("%.5f ", (double)GGML_FP16_TO_FP32(data[i]));
+        if (i != 0 && i % t->ne[0] == 0) {
+            printf("\n");
+        }
+    }
+    printf("\n");
+    for (int i = 0; i < MIN((int) (t->ne[0]*t->ne[1]), n); i++) {
+        printf("%.5f ", (double)GGML_FP16_TO_FP32(data[ggml_nelements(t) - n + i]));
+        if ((ggml_nelements(t) - n + i) % t->ne[0] == 0) {
+            printf("\n");
+        }
+    }
+    printf("\n");
+    double sum = 0.0;
+    for (int i = 0; i < ggml_nelements(t); i++) {
+        float d = GGML_FP16_TO_FP32(data[i]);
+        if (!isnan(d) && !isinf(d)) {
+            sum += (double)d;
+        }
+    }
+    printf("sum:  %f\n\n", sum);
+}
+
+static void print_t_f32(const char* title, struct ggml_tensor * t, int n) {
+    printf("%s\n", title);
+
+    const float * data = (const float *) t->data;
+
+    printf("dims: %jd %jd %jd %jd f32\n", t->ne[0], t->ne[1], t->ne[2], t->ne[3]);
+    printf("First & Last %d elements:\n", n);
+
+    // 打印前 n 个元素
+    for (int i = 0; i < MIN((int)(t->ne[0] * t->ne[1]), n); i++) {
+        printf("%.5f ", data[i]);
+        if (i != 0 && i % t->ne[0] == 0) {
+            printf("\n");
+        }
+    }
+    printf("\n");
+
+    // 打印最后 n 个元素
+    for (int i = 0; i < MIN((int)(t->ne[0] * t->ne[1]), n); i++) {
+        int idx = ggml_nelements(t) - n + i;
+        printf("%.5f ", data[idx]);
+        if (idx % t->ne[0] == 0) {
+            printf("\n");
+        }
+    }
+    printf("\n");
+
+    // 求和
+    double sum = 0.0;
+    for (int i = 0; i < ggml_nelements(t); i++) {
+        float d = data[i];
+        if (!isnan(d) && !isinf(d)) {
+            sum += (double)d;
+        }
+    }
+    printf("sum:  %f\n\n", sum);
+}
 
 static void ggml_compute_forward(struct ggml_compute_params * params, struct ggml_tensor * tensor) {
     GGML_ASSERT(params);
@@ -12658,6 +12726,16 @@ static void ggml_compute_forward(struct ggml_compute_params * params, struct ggm
                 GGML_ABORT("fatal error");
             }
     }
+
+    if (strstr(tensor->name, "debug") != NULL && params->ith + 1 == params->nth) {
+        if (tensor->type == GGML_TYPE_F16) {
+            print_t_f16(tensor->name, tensor, 10);
+        } else if (tensor->type == GGML_TYPE_F32) {
+            print_t_f32(tensor->name, tensor, 10);
+        }else {
+            fprintf(stderr, "%s: error: unsupported type %d\n", __func__, tensor->type);
+        }
+    }
 }
 
 // Android's libc implementation "bionic" does not support setting affinity
-- 
2.49.0.windows.1

